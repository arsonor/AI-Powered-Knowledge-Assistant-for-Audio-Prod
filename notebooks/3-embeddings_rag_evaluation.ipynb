{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fbd7bbe-145f-4e58-a874-b005dbed225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454e399-424c-422e-9c60-8a83cf54b729",
   "metadata": {},
   "source": [
    "# Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21c60918-87b5-4156-88b7-291eb26ed85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/arsonor_chunks_300_50.json', 'r', encoding='utf-8') as file:\n",
    "    documents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95eeaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7a23bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_name = \"arsonor_chunks_300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efbf5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if es.indices.exists(index=index_name):\n",
    "#     es.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "869defd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index if not already created\n",
    "# if not es.indices.exists(index=index_name):\n",
    "#     es.indices.create(index=index_name, body={\n",
    "#         \"mappings\": {\n",
    "#             \"properties\": {\n",
    "#                 \"article_id\": {\"type\": \"keyword\"},\n",
    "#                 \"title\": {\"type\": \"text\"},\n",
    "#                 \"url\": {\"type\": \"keyword\"},\n",
    "#                 \"category\": {\"type\": \"keyword\"},\n",
    "#                 \"tags\": {\"type\": \"text\"},\n",
    "#                 \"chunk_id\": {\"type\": \"keyword\"},\n",
    "#                 \"chunk_text\": {\"type\": \"text\"},\n",
    "#                 \"embedding\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"}\n",
    "#             }\n",
    "#         }\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2513aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti.MARTIN\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load CamemBERT model for French content\n",
    "camembert_tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")\n",
    "camembert_model = AutoModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Load mBERT model for technical fine-tuning\n",
    "mbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "mbert_model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "# Load paraphrase-multilingual-mpnet-base-v2 for semantic search\n",
    "paraphrase_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6e46951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text, embedding_model):\n",
    "    if embedding_model == \"camembert\":\n",
    "        inputs = camembert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = camembert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "    \n",
    "    elif embedding_model == \"mbert\":\n",
    "        inputs = mbert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = mbert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "    \n",
    "    elif embedding_model == \"paraphrase\":\n",
    "        embeddings = paraphrase_model.encode(text)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Choose 'camembert', 'mbert', or 'paraphrase'.\")\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2774e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti.MARTIN\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e0a81",
   "metadata": {},
   "source": [
    "Test indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee5d67f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'chunks_300_mpnet'})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"article_id\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"url\": {\"type\": \"keyword\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"tags\": {\"type\": \"text\"},\n",
    "            \"chunk_id\": {\"type\": \"keyword\"},\n",
    "            \"chunk_text\": {\"type\": \"text\"},\n",
    "            \"chunk_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"title_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"tags_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"chunk_title_tag_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"chunks_300_mpnet\"\n",
    "\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es.indices.create(index=index_name, body=index_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36bf41b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a61a499d5c5474fb7ae6c6f5cc67391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    chunk = doc['chunk_text']\n",
    "    title = doc['title']\n",
    "    tags = doc['tags']\n",
    "    ctt = chunk + ' ' + title + ' ' + tags\n",
    "\n",
    "    doc['chunk_vector'] = model.encode(chunk)\n",
    "    doc['title_vector'] = model.encode(title)\n",
    "    doc['tags_vector'] = model.encode(tags)\n",
    "    doc['chunk_title_tag_vector'] = model.encode(ctt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d2afe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab5438eacd54d23ad761c4d3e19a0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3dda8a",
   "metadata": {},
   "source": [
    "Fin Test indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e16761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_documents_for_indexing(docs, embedding_model):\n",
    "#     for doc in docs:\n",
    "#         embedding_vector = generate_embedding(doc['chunk_text'], embedding_model)\n",
    "        \n",
    "#         yield {\n",
    "#             \"_index\": index_name,\n",
    "#             \"_id\": doc['chunk_id'],\n",
    "#             \"_source\": {\n",
    "#                 \"article_id\": doc['article_id'],\n",
    "#                 \"title\": doc['title'],\n",
    "#                 \"url\": doc['url'],\n",
    "#                 \"category\": doc['category'],\n",
    "#                 \"tags\": doc['tags'],\n",
    "#                 \"chunk_id\": doc['chunk_id'],\n",
    "#                 \"chunk_text\": doc['chunk_text'],\n",
    "#                 \"embedding\": embedding_vector\n",
    "#             }\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52fcbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the documents in bulk\n",
    "# bulk(es, tqdm(prepare_documents_for_indexing(documents, 'paraphrase')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4c969-765d-4ad2-b773-30cd5a790bf9",
   "metadata": {},
   "source": [
    "# RAG flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b4a59",
   "metadata": {},
   "source": [
    "knn vector search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c62a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(query, embedding_model, category=None):\n",
    "    vector = generate_embedding(query, embedding_model)\n",
    "    \n",
    "    # If category is provided, add the filter condition\n",
    "    filter_conditions = []\n",
    "    if category:\n",
    "        filter_conditions.append({\"term\": {\"category\": category}})\n",
    "\n",
    "    search_query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": [\"chunk_id\", \"title\", \"tags\", \"chunk_text\", \"url\"],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title\", \"tags\", \"chunk_text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": filter_conditions\n",
    "            }\n",
    "        },\n",
    "        \"knn\": {\n",
    "            \"field\": \"embedding\",\n",
    "            \"query_vector\": vector.tolist(),\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 10000\n",
    "        }\n",
    "    }\n",
    "\n",
    "    es_results = es.search(index=index_name, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73305f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn_test(field, vector, category):\n",
    "    \n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"category\": category\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"chunk_id\", \"title\", \"tags\", \"chunk_text\", \"url\", \"category\"]\n",
    "    }\n",
    "\n",
    "    es_results = es.search(index=index_name, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3288f",
   "metadata": {},
   "source": [
    "hybrid search with script_score query that combines text search with vector similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d0f70570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid(query, embedding_model, category=None):\n",
    "    vector = generate_embedding(query, embedding_model)\n",
    "    \n",
    "    # If category is provided, add the filter condition\n",
    "    filter_conditions = []\n",
    "    if category:\n",
    "        filter_conditions.append({\"term\": {\"category\": category}})\n",
    "    \n",
    "    # Hybrid search query with BM25 and kNN (semantic search)\n",
    "    search_query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": [\"chunk_id\", \"title\", \"tags\", \"chunk_text\", \"url\"],\n",
    "        \"query\": {\n",
    "            \"function_score\": {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\n",
    "                                \"multi_match\": {\n",
    "                                    \"query\": query,\n",
    "                                    \"fields\": [\"title\", \"tags\", \"chunk_text\"],\n",
    "                                    \"type\": \"best_fields\"\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"filter\": filter_conditions\n",
    "                    }\n",
    "                },\n",
    "                \"functions\": [\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"script\": {\n",
    "                                # Combines BM25 score and kNN similarity score\n",
    "                                \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1 + _score\",\n",
    "                                \"params\": {\n",
    "                                    \"query_vector\": vector.tolist()\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"boost_mode\": \"replace\"  # Replace BM25 score with the combined score\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    es_results = es.search(index=index_name, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3b25a",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "460e2c4b-d2b5-416a-aeb8-b2a503f8c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're an audio engineer and sound designer instructor for beginners.\n",
    "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
    "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "Finally, recommend the top 3 Arsonor articles that are the best to read for answering this question.\n",
    "For each recommended article, include both its title and URL.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "ARTICLE: {title}\n",
    "KEYWORDS: {tags}\n",
    "CONTENT: {chunk_text}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c330b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf18ede",
   "metadata": {},
   "source": [
    "### Test prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ca3d363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're an audio engineer and sound designer instructor for beginners.\n",
      "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
      "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "Finally, recommend the top 3 Arsonor articles that are the best to read for answering this question.\n",
      "For each recommended article, include both its title and URL.\n",
      "\n",
      "QUESTION: Comment obtenir une musique de haute qualit√© au m√™me niveau sonore que les autres?\n",
      "\n",
      "CONTEXT:\n",
      "ARTICLE: La gestion des niveaux sonores (3): Variations du loudness\n",
      "KEYWORDS: balance tonale, dBA, dBC, loudness, LUFS, masquage, sonie, transitoire, volume sonore\n",
      "CONTENT: ‚Äì A haut niveau, plus de perception des basses donc risque d‚Äôen mettre pas assez. Ces consid√©rations d√©pendent bien s√ªr de l‚Äôexp√©rience individuelle de chacun en mixage. Cependant, les consid√©rations suivantes, g√©n√©ralement admises, sont une bonne mani√®re de proc√©der: * Un mixage bon √† bas niveau a de grandes chances d'√™tre bon √† fort niveau L‚Äôinverse n‚Äô√©tant pas toujours vrai! * Le niveau d'√©coute de r√©f√©rence doit √™tre aussi proche que possible du niveau final pour lequel la musique est susceptible d'√™tre jou√©e Par exemple, une musique de style ¬´ dance ¬ª s‚Äô√©coutera plus fort qu‚Äôun morceau d‚Äôambient. Il est donc judicieux de pr√©voir le volume de travail du mixage en cons√©quence. * Le mixage des fr√©quences m√©diums pour tous les √©l√©ments est la cl√© Pour donner un exemple clair, si le son d‚Äôune basse n‚Äôest pr√©sent que dans les basses fr√©quences, la basse est susceptible d‚Äô√™tre faiblement entendue (voire plus du tout!) √† faibles niveaux. Mais si on fait en sorte de faire un traitement EQ de la basse dans les hauts-m√©diums, l‚Äô√©quilibre de l‚Äôinstrument sera respect√© quelque soit le niveau sonore. Il est donc recommand√© de travailler les √©l√©ments pr√©dominants dans les basses ou les aigu√´s comme une extension aux fr√©quences m√©diums. Ces derni√®res variant peu avec le volume sont la cl√© d‚Äôun mixage √©quilibr√©. Ce n‚Äôest pas un hasard si on retrouve dans quasi tous les studios professionnels une paire d‚Äôenceintes annexe Yamaha NS10 ! Elles sont connues pour leur courbe en fr√©quence pas du tout neutre (gros boost dans les m√©diums). Mais si elles sont tr√®s pris√©es, c‚Äôest parce que les ing√©nieurs savent que si le mixage sonne bien √† l‚Äô√©coute sur ces enceintes alors c‚Äôest qu‚Äôil est bon üòâ 3.\n",
      "\n",
      "ARTICLE: Comment g√©rer l‚Äô√©quilibre dynamique de la musique?\n",
      "KEYWORDS: arrangement, automation de volume, macro-dynamique, micro-dynamique, mise √† plat, niveau absolu, niveau relatif, podcast\n",
      "CONTENT: Entra√Æne-toi √† le faire avant de penser √† tout traitement avec des EQ ou autres compresseurs. Sois toujours fid√®le au contenu musical d‚Äôorigine. Pense toujours √† cela et √† l‚Äôauditeur. Utilise la dynamique comme un moyen de faire voyager l‚Äôauditeur √† travers le mixage, et fais-le se concentrer sur l‚Äô√©l√©ment le plus important √† tout moment. Bien s√ªr, si tu veux r√©gler par la suite la sonorit√© per√ßue des instruments de mani√®re plus sophistiqu√©e, le seul mouvement des faders ne suffira pas. Il te faudra ma√Ætriser la science des EQ et de la compression. Je te rappelle que tu peux t√©l√©charger l‚Äô√©pisode du podcast correspondant √† cet article en qualit√© audio optimale, non compress√©e (voir lien en d√©but d‚Äôarticle). Voil√†, je te dis √† tr√®s bient√¥t, d‚Äôici l√†, bonne √©coute et bonne prod!\n",
      "\n",
      "ARTICLE: La gestion des niveaux (6): Ma√Ætriser la dynamique sonore\n",
      "KEYWORDS: 32 bits float, bruit de quantification, compresseur/limiteur, dithering, DR, gain staging, headroom\n",
      "CONTENT: Elle apporte une r√©serve de headroom presque illimit√©e et un bruit de fond extr√™mement bas (tant que l‚Äôon ne repasse pas par un convertisseur, voir plus loin). Repr√©sentation et correspondance des niveaux nominaux et pics en analogique et num√©rique C‚Äôest pourquoi un niveau d‚Äôenregistrement √† -18 ou -20 dB en moyenne , avec des pics ne d√©passant jamais les -6 ou -8 dB , permet de conserver une tr√®s bonne qualit√© audio √† posteriori. Tout en gardant une bonne r√©serve de niveau, les pistes seront alors plus facile √† mixer! Calibration des convertisseurs √† -18 dBFS Quand le signal est toujours analogique, au niveau du pr√©ampli, tu peux pousser le gain de celui-ci afin de l‚Äôattaquer en saturation et profiter de sa ¬´ couleur analogique ¬ª. C‚Äôest pourquoi le standard de calibration des convertos se fait autour des -18 dBFS. On a alors le niveau nominal du pr√©ampli (0 VU) qui correspond au niveau nominal num√©rique d‚Äôenregistrement √† -18 dBFS. Tu peux te demander pourquoi ne pas simplement effectuer un traitement limiteur brickwall √† la prise pour √™tre s√ªr de ne pas d√©passer le 0 dBFS? Mais ce proc√©d√© reviendrait alors √† ¬´ √©craser ¬ª les niveaux les plus forts et donc √† r√©duire la plage dynamique du morceau! C‚Äôest au mastering que l‚Äôon s‚Äôoccupera de la plage dynamique (voir plus loin). Un limiteur brickwall est id√©alement utilis√© lors de cette derni√®re √©tape seulement. La dynamique sonore √† 32 bits float pendant la production Une fois tous les signaux audio convertis en num√©rique, on entre dans le monde ¬´ 32 bits float ¬ª de la DAW . Comme on l‚Äôa vu , on poss√®de maintenant une plage dynamique de travail presque infini! On pourrait alors se laisser tenter √† compl√®tement ignorer les niveaux audio des diff√©rentes pistes.\n",
      "\n",
      "ARTICLE: 10 logiciels incontournables pour le sound design\n",
      "KEYWORDS: plugin, sound design\n",
      "CONTENT: Alors tu me diras, wow c‚Äôest super pour le son √† l‚Äôimage, mais pour le sound design en cr√©ation musicale? Eh bien c‚Äôest pareil! Les banques de sons peuvent aussi r√©agir √† l‚Äôaudio enregistr√© sur ta DAW (pour des percussions ou autre) mais √©galement √™tre contr√¥l√©es par Midi. Dans la cr√©ation musicale moderne, beaucoup d‚Äôeffets sonores (Foley ou FX) s‚Äôadaptent magnifiquement dans un contexte rythmique ou musical. La richesse spectrale et la complexit√© rythmique inh√©rente √† ces sons est souvent sous-estim√©e. En plus de Reformer pro, Krotos a √©galement dans sa palette les outils Dehumanizer et Weaponizer qui sont dans la m√™me veine et valent aussi le coup. Demo: Autres recommandations: Sous le terme ‚Äútransformation vocale‚Äù, on peut y retrouver d‚Äôautres types de technologie audio: ‚Äì AudioEase Speakerphone : Comment ne pas penser aux ma√Ætres de la convolution avec la soci√©t√© hollandaise AudioEase . Tr√®s connus pour leur reverb phare Altiverb , Speakerphone est aussi un outil tr√®s utile pour transformer une voix ‚Äúnormale‚Äù en une voix sortant de n‚Äôimporte quel endroit (appareils √©lectroniques, m√©gaphone, etc, etc‚Ä¶) ‚Äì Zynaptiq Wormhole : Gr√¢ce √† une combinaison de ‚Äúwarping‚Äù spectral, d‚Äôalgorithmes de reverb riche, de pitch-shifting et de morphing , Zynaptiq (encore eux) permet avec Wormhole d‚Äôobtenir rapidement des ambiences surr√©alistes ou des voix d‚Äôaliens, monstres et robots en tout genre. ‚Äì Celemony Melodyne : voir plus haut ‚Äì Flux Ircam Trax : Ce plugin est absolument √©poustouflant! Il permet, par exemple, de passer d‚Äôune voix d‚Äôhomme (ou femme) √† une voix d‚Äôenfant ou de personne √¢g√©e avec un r√©alisme rare! ‚Äì Izotope Vocalsynth : Izotope n‚Äôest aussi pas en reste avec son vocoder du futur.\n",
      "\n",
      "ARTICLE: Par o√π commencer dans l‚Äôapprentissage d‚Äôune DAW pour produire sa musique?\n",
      "KEYWORDS: apprentissage, Audio, composition, DAW, home-studio, MIDI, production musicale\n",
      "CONTENT: Partir d‚Äôun son avec d√©j√† trop de modulations et un timbre fou ne va pas forc√©ment t‚Äôaider √† obtenir ce que tu recherches. L'apprentissage de l'√©coute √† travers la manipulation des effets audio Les traitements audio c‚Äôest aussi l‚Äôemploi des processeurs et effets utilis√©s par les ing√©nieurs du son pour mixer et masteriser un morceau. Ces m√™mes outils (compresseur, EQ, delay, reverb, etc..) peuvent √™tre aussi avantageusement utilis√©s en phase de cr√©ation musicale. La compr√©hension des param√®tres de tous ces effets audio et leurs cons√©quences sur le signal audio est primordiale. C‚Äôest l‚Äôoccasion de t‚Äôinitier au travail ult√©rieur de l‚Äôing√©nieur en mixage. Cela implique le d√©veloppement de ton premier outil de travail: l‚Äôoreille. L‚Äôapprentissage d‚Äôune DAW devient alors l‚Äôapprentissage de l‚Äô√©coute du son dans ses trois dimensions: sa dynamique (compression, gate, limiteur‚Ä¶), son spectre fr√©quentiel (EQ) et sa temporalit√© (reverb, delay‚Ä¶). Conclusion Maintenant que tu sais un peu mieux le r√¥le de producteur (en home-studio), par quoi commencer et les quelques trucs √† savoir, il est temps de passer √† l‚Äôaction! T√©l√©charge la d√©mo d‚Äôune DAW et commence ton apprentissage d√®s maintenant. Compl√®tement novice en production musicale? Commence par consulter les articles dont les liens figurent √† cette page . Pour aller plus loin: Seconde phase d'apprentissage de sa DAW (ou en parall√®le) Bien √©videmment suivant les cas, tu peux avoir d‚Äôautres pr√©occupations de d√©butant quand tu commences avec une DAW comme savoir s‚Äôenregistrer . Dans ce cas-l√†, les autres axes d‚Äôapprentissage (en parall√®le) concernent tout le travail ¬´ Out of the Box ¬ª , c‚Äôest-√†-dire tout ce qui concerne les outils du home-studio en-dehors du logiciel audio √† savoir: L‚Äôinterface audio (ou carte son) et les configs audio Comment choisir et utiliser un micro? Comment enregistrer un instrument (Voix, ‚Ä¶) ?\n"
     ]
    }
   ],
   "source": [
    "query = 'Comment obtenir une musique de haute qualit√© au m√™me niveau sonore que les autres?'\n",
    "search_results = elastic_search_knn_test(query, 'paraphrase', 'LA POST-PROD')\n",
    "prompt = build_prompt(query, search_results)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508d1be",
   "metadata": {},
   "source": [
    "### Final RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a54c74a-78fa-4684-b19b-f6bba6273cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "200a1d40-a113-4737-99ec-ac7e1c6114d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, embedding_model, category):\n",
    "    search_results = elastic_search_knn(query, embedding_model, category)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a3357",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58469b47-a3ee-4941-9466-d944c82d7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour obtenir une musique de haute qualit√© au m√™me niveau sonore que les autres, il est essentiel de porter attention √† plusieurs √©l√©ments cl√©s lors du processus de mixage et de mastering :\n",
      "\n",
      "1. **Mixage des Fr√©quences M√©diums** : Un √©quilibre correct des fr√©quences m√©diums est crucial, car ces fr√©quences ne varient gu√®re avec le volume et permettent de maintenir la perception des instruments √† diff√©rents niveaux d'√©coute. Par exemple, il est conseill√© de traiter les sons de basse dans les hautes m√©diums pour s'assurer qu'ils soient per√ßus m√™me √† faible volume.\n",
      "\n",
      "2. **G√©rer la Dynamique** : Utiliser la dynamique de mani√®re r√©fl√©chie pendant le mixage permet de diriger l‚Äôattention de l‚Äôauditeur sur les √©l√©ments les plus importants de la musique, tandis que la compression peut aider √† stabiliser les niveaux per√ßus.\n",
      "\n",
      "3. **Mastering et Loudness** : En phase de mastering, il est crucial de travailler sur la plage dynamique et le loudness pour que le morceau soit comp√©titif par rapport aux autres dans le m√™me genre musical. Cela implique d‚Äôoptimiser √† la fois les pics de volume et le volume moyen per√ßu.\n",
      "\n",
      "4. **Calibrage Correct des Niveaux** : Il est recommand√© de calibrer les niveaux d'enregistrement √† -18 dBFS pour garantir une bonne qualit√© audio. Cela donne √©galement de la headroom pour √©viter la saturation.\n",
      "\n",
      "En combinant ces techniques et en utilisant des outils comme des √©galiseurs et des limiteurs de mani√®re strat√©gique, vous serez en mesure d'atteindre un niveau sonore satisfaisant tout en pr√©servant la qualit√© de votre musique.\n",
      "\n",
      "Voici les trois articles d'Arsonor les plus pertinents pour approfondir ce sujet :\n",
      "\n",
      "1. **La gestion des niveaux sonores (3): Variations du loudness**  \n",
      "   URL: [La gestion des niveaux sonores (3)](https://arsonor.com/articles/loudness)\n",
      "\n",
      "2. **Comment g√©rer l‚Äô√©quilibre dynamique de la musique?**  \n",
      "   URL: [Comment g√©rer l‚Äô√©quilibre dynamique de la musique?](https://arsonor.com/articles/equilibre-dynamique)\n",
      "\n",
      "3. **Le Mastering: 6 diff√©rences fondamentales qui le s√©parent du mixage**  \n",
      "   URL: [Le Mastering: 6 diff√©rences fondamentales](https://arsonor.com/articles/mastering-6-differences)\n"
     ]
    }
   ],
   "source": [
    "category = 'LA POST_PROD'\n",
    "query = 'Comment obtenir une musique de haute qualit√© au m√™me niveau sonore que les autres?'\n",
    "embedding_model = 'paraphrase'\n",
    "response = rag(query, embedding_model, category)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be4d02-5d0f-465b-9b75-26dac1b1cbb7",
   "metadata": {},
   "source": [
    "# Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286045b2-a6a9-4120-9d75-8bdf4318f18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>chunk</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quel est l'impact de l'IA sur la post-producti...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment les outils IA simplifient-ils le trava...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels avantages l'IA apporte-t-elle aux artist...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment un d√©butant peut-il am√©liorer ses prod...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quelle est l'√©volution des outils audio pour l...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      category  \\\n",
       "0  Quel est l'impact de l'IA sur la post-producti...  LA POST-PROD   \n",
       "1  Comment les outils IA simplifient-ils le trava...  LA POST-PROD   \n",
       "2  Quels avantages l'IA apporte-t-elle aux artist...  LA POST-PROD   \n",
       "3  Comment un d√©butant peut-il am√©liorer ses prod...  LA POST-PROD   \n",
       "4  Quelle est l'√©volution des outils audio pour l...  LA POST-PROD   \n",
       "\n",
       "        chunk   article  \n",
       "0  4615db39-1  4615db39  \n",
       "1  4615db39-1  4615db39  \n",
       "2  4615db39-1  4615db39  \n",
       "3  4615db39-1  4615db39  \n",
       "4  4615db39-1  4615db39  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question = pd.read_csv('../data/ground-truth-300.csv')\n",
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0a4048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Quel est l'impact de l'IA sur la post-production audio et musicale\",\n",
       " 'category': 'LA POST-PROD',\n",
       " 'chunk': '4615db39-1',\n",
       " 'article': '4615db39'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bd63de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['chunk']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['chunk_id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055795b",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'camembert':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2916c7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0c4855cefb4e8382a814ba036abdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8748251748251749, 'mrr': 0.6097562160062151}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'camembert', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9bef9",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'mbert':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7df1b090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e5950dddf24f4b812a90d918ef863b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.877972027972028, 'mrr': 0.6076655289155277}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'mbert', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9d67a",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'paraphrase', k=10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "425699e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70776d9aced04a4686d2d8561a2b5a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8867132867132868, 'mrr': 0.6172445609945602}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d26afd",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'paraphrase', k=30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cf664d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85625969193f4a7fb002ee2e7ce15132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8895104895104895, 'mrr': 0.6158666333666325}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa9bb0",
   "metadata": {},
   "source": [
    "Chunks 350_30, model 'paraphrase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2bbc3088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1af6f95bace4c4983d3fdb4f3e6b3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.87313769751693, 'mrr': 0.6015434089361857}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b128e35",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'paraphrase', hybrid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5f2ff269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2c2bfc9631457f9dafa5d298c8424c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8846153846153846, 'mrr': 0.6128640803640799}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_hybrid(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da30e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_paraphrase_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = paraphrase_model.encode(question)\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbb9e43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f9c6cb2afd4c279b8c2e9683ad50b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.49965034965034966, 'mrr': 0.28753357753357806}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_paraphrase_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42f25c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_title_tag_paraphrase_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = generate_embedding(question, 'paraphrase')\n",
    "\n",
    "    return elastic_search_knn_test('chunk_title_tag_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06886672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291e18f1a0c64ea8844ed7809634061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.49965034965034966, 'mrr': 0.28753357753357806}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_title_tag_paraphrase_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8fff833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_camembert_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = generate_embedding(question, 'camembert')\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08a2c4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc1dc76de74469793841e5a2a3541b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.1618881118881119, 'mrr': 0.05634254634254627}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_camembert_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40d96a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_multiqa_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "22e69bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140636574b1f4acb9e963834e54f0856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6814685314685315, 'mrr': 0.3852813852813858}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_multiqa_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87bab586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_mpnet_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bfb073a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2996b358bac649008c1ceadb5f5b3a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6391608391608392, 'mrr': 0.36160631035631086}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_mpnet_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
