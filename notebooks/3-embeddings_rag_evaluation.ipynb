{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fbd7bbe-145f-4e58-a874-b005dbed225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454e399-424c-422e-9c60-8a83cf54b729",
   "metadata": {},
   "source": [
    "# Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21c60918-87b5-4156-88b7-291eb26ed85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/arsonor_chunks_300_50.json', 'r', encoding='utf-8') as file:\n",
    "    documents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95eeaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7a23bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_name = \"arsonor_chunks_300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efbf5441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if es.indices.exists(index=index_name):\n",
    "#     es.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "869defd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index if not already created\n",
    "# if not es.indices.exists(index=index_name):\n",
    "#     es.indices.create(index=index_name, body={\n",
    "#         \"mappings\": {\n",
    "#             \"properties\": {\n",
    "#                 \"article_id\": {\"type\": \"keyword\"},\n",
    "#                 \"title\": {\"type\": \"text\"},\n",
    "#                 \"url\": {\"type\": \"keyword\"},\n",
    "#                 \"category\": {\"type\": \"keyword\"},\n",
    "#                 \"tags\": {\"type\": \"text\"},\n",
    "#                 \"chunk_id\": {\"type\": \"keyword\"},\n",
    "#                 \"chunk_text\": {\"type\": \"text\"},\n",
    "#                 \"embedding\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"}\n",
    "#             }\n",
    "#         }\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2513aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti.MARTIN\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load CamemBERT model for French content\n",
    "camembert_tokenizer = AutoTokenizer.from_pretrained(\"camembert-base\")\n",
    "camembert_model = AutoModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# Load mBERT model for technical fine-tuning\n",
    "mbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "mbert_model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "# Load paraphrase-multilingual-mpnet-base-v2 for semantic search\n",
    "paraphrase_model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6e46951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text, embedding_model):\n",
    "    if embedding_model == \"camembert\":\n",
    "        inputs = camembert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = camembert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "    \n",
    "    elif embedding_model == \"mbert\":\n",
    "        inputs = mbert_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = mbert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "    \n",
    "    elif embedding_model == \"paraphrase\":\n",
    "        embeddings = paraphrase_model.encode(text)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Choose 'camembert', 'mbert', or 'paraphrase'.\")\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2774e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti.MARTIN\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e0a81",
   "metadata": {},
   "source": [
    "Test indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee5d67f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'chunks_300_mpnet'})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"article_id\": {\"type\": \"keyword\"},\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"url\": {\"type\": \"keyword\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"tags\": {\"type\": \"text\"},\n",
    "            \"chunk_id\": {\"type\": \"keyword\"},\n",
    "            \"chunk_text\": {\"type\": \"text\"},\n",
    "            \"chunk_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"title_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"tags_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "            \"chunk_title_tag_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 768,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"chunks_300_mpnet\"\n",
    "\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es.indices.create(index=index_name, body=index_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36bf41b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a61a499d5c5474fb7ae6c6f5cc67391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    chunk = doc['chunk_text']\n",
    "    title = doc['title']\n",
    "    tags = doc['tags']\n",
    "    ctt = chunk + ' ' + title + ' ' + tags\n",
    "\n",
    "    doc['chunk_vector'] = model.encode(chunk)\n",
    "    doc['title_vector'] = model.encode(title)\n",
    "    doc['tags_vector'] = model.encode(tags)\n",
    "    doc['chunk_title_tag_vector'] = model.encode(ctt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3d2afe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab5438eacd54d23ad761c4d3e19a0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3dda8a",
   "metadata": {},
   "source": [
    "Fin Test indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e16761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_documents_for_indexing(docs, embedding_model):\n",
    "#     for doc in docs:\n",
    "#         embedding_vector = generate_embedding(doc['chunk_text'], embedding_model)\n",
    "        \n",
    "#         yield {\n",
    "#             \"_index\": index_name,\n",
    "#             \"_id\": doc['chunk_id'],\n",
    "#             \"_source\": {\n",
    "#                 \"article_id\": doc['article_id'],\n",
    "#                 \"title\": doc['title'],\n",
    "#                 \"url\": doc['url'],\n",
    "#                 \"category\": doc['category'],\n",
    "#                 \"tags\": doc['tags'],\n",
    "#                 \"chunk_id\": doc['chunk_id'],\n",
    "#                 \"chunk_text\": doc['chunk_text'],\n",
    "#                 \"embedding\": embedding_vector\n",
    "#             }\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52fcbb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the documents in bulk\n",
    "# bulk(es, tqdm(prepare_documents_for_indexing(documents, 'paraphrase')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4c969-765d-4ad2-b773-30cd5a790bf9",
   "metadata": {},
   "source": [
    "# RAG flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b4a59",
   "metadata": {},
   "source": [
    "knn vector search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c62a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(query, embedding_model, category=None):\n",
    "    vector = generate_embedding(query, embedding_model)\n",
    "    \n",
    "    # If category is provided, add the filter condition\n",
    "    filter_conditions = []\n",
    "    if category:\n",
    "        filter_conditions.append({\"term\": {\"category\": category}})\n",
    "\n",
    "    search_query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": [\"chunk_id\", \"title\", \"tags\", \"chunk_text\", \"url\"],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title\", \"tags\", \"chunk_text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": filter_conditions\n",
    "            }\n",
    "        },\n",
    "        \"knn\": {\n",
    "            \"field\": \"embedding\",\n",
    "            \"query_vector\": vector.tolist(),\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 10000\n",
    "        }\n",
    "    }\n",
    "\n",
    "    es_results = es.search(index=index_name, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73305f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn_test(field, vector, category):\n",
    "    \n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 10,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"category\": category\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"chunk_id\", \"title\", \"tags\", \"chunk_text\", \"url\", \"category\"]\n",
    "    }\n",
    "\n",
    "    es_results = es.search(index=index_name, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3288f",
   "metadata": {},
   "source": [
    "hybrid search with script_score query that combines text search with vector similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d0f70570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_hybrid(query, embedding_model, category=None):\n",
    "    vector = generate_embedding(query, embedding_model)\n",
    "    \n",
    "    # If category is provided, add the filter condition\n",
    "    filter_conditions = []\n",
    "    if category:\n",
    "        filter_conditions.append({\"term\": {\"category\": category}})\n",
    "    \n",
    "    # Hybrid search query with BM25 and kNN (semantic search)\n",
    "    search_query = {\n",
    "        \"size\": 10,\n",
    "        \"_source\": [\"chunk_id\", \"title\", \"tags\", \"chunk_text\", \"url\"],\n",
    "        \"query\": {\n",
    "            \"function_score\": {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\n",
    "                                \"multi_match\": {\n",
    "                                    \"query\": query,\n",
    "                                    \"fields\": [\"title\", \"tags\", \"chunk_text\"],\n",
    "                                    \"type\": \"best_fields\"\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"filter\": filter_conditions\n",
    "                    }\n",
    "                },\n",
    "                \"functions\": [\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"script\": {\n",
    "                                # Combines BM25 score and kNN similarity score\n",
    "                                \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1 + _score\",\n",
    "                                \"params\": {\n",
    "                                    \"query_vector\": vector.tolist()\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"boost_mode\": \"replace\"  # Replace BM25 score with the combined score\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    es_results = es.search(index=index_name, body=search_query)\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3b25a",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "460e2c4b-d2b5-416a-aeb8-b2a503f8c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're an audio engineer and sound designer instructor for beginners.\n",
    "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
    "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "Finally, recommend the top 3 Arsonor articles that are the best to read for answering this question.\n",
    "For each recommended article, include both its title and URL.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "ARTICLE: {title}\n",
    "KEYWORDS: {tags}\n",
    "CONTENT: {chunk_text}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c330b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf18ede",
   "metadata": {},
   "source": [
    "### Test prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ca3d363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're an audio engineer and sound designer instructor for beginners.\n",
      "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
      "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "Finally, recommend the top 3 Arsonor articles that are the best to read for answering this question.\n",
      "For each recommended article, include both its title and URL.\n",
      "\n",
      "QUESTION: Comment obtenir une musique de haute qualité au même niveau sonore que les autres?\n",
      "\n",
      "CONTEXT:\n",
      "ARTICLE: La gestion des niveaux sonores (3): Variations du loudness\n",
      "KEYWORDS: balance tonale, dBA, dBC, loudness, LUFS, masquage, sonie, transitoire, volume sonore\n",
      "CONTENT: – A haut niveau, plus de perception des basses donc risque d’en mettre pas assez. Ces considérations dépendent bien sûr de l’expérience individuelle de chacun en mixage. Cependant, les considérations suivantes, généralement admises, sont une bonne manière de procéder: * Un mixage bon à bas niveau a de grandes chances d'être bon à fort niveau L’inverse n’étant pas toujours vrai! * Le niveau d'écoute de référence doit être aussi proche que possible du niveau final pour lequel la musique est susceptible d'être jouée Par exemple, une musique de style « dance » s’écoutera plus fort qu’un morceau d’ambient. Il est donc judicieux de prévoir le volume de travail du mixage en conséquence. * Le mixage des fréquences médiums pour tous les éléments est la clé Pour donner un exemple clair, si le son d’une basse n’est présent que dans les basses fréquences, la basse est susceptible d’être faiblement entendue (voire plus du tout!) à faibles niveaux. Mais si on fait en sorte de faire un traitement EQ de la basse dans les hauts-médiums, l’équilibre de l’instrument sera respecté quelque soit le niveau sonore. Il est donc recommandé de travailler les éléments prédominants dans les basses ou les aiguës comme une extension aux fréquences médiums. Ces dernières variant peu avec le volume sont la clé d’un mixage équilibré. Ce n’est pas un hasard si on retrouve dans quasi tous les studios professionnels une paire d’enceintes annexe Yamaha NS10 ! Elles sont connues pour leur courbe en fréquence pas du tout neutre (gros boost dans les médiums). Mais si elles sont très prisées, c’est parce que les ingénieurs savent que si le mixage sonne bien à l’écoute sur ces enceintes alors c’est qu’il est bon 😉 3.\n",
      "\n",
      "ARTICLE: Comment gérer l’équilibre dynamique de la musique?\n",
      "KEYWORDS: arrangement, automation de volume, macro-dynamique, micro-dynamique, mise à plat, niveau absolu, niveau relatif, podcast\n",
      "CONTENT: Entraîne-toi à le faire avant de penser à tout traitement avec des EQ ou autres compresseurs. Sois toujours fidèle au contenu musical d’origine. Pense toujours à cela et à l’auditeur. Utilise la dynamique comme un moyen de faire voyager l’auditeur à travers le mixage, et fais-le se concentrer sur l’élément le plus important à tout moment. Bien sûr, si tu veux régler par la suite la sonorité perçue des instruments de manière plus sophistiquée, le seul mouvement des faders ne suffira pas. Il te faudra maîtriser la science des EQ et de la compression. Je te rappelle que tu peux télécharger l’épisode du podcast correspondant à cet article en qualité audio optimale, non compressée (voir lien en début d’article). Voilà, je te dis à très bientôt, d’ici là, bonne écoute et bonne prod!\n",
      "\n",
      "ARTICLE: La gestion des niveaux (6): Maîtriser la dynamique sonore\n",
      "KEYWORDS: 32 bits float, bruit de quantification, compresseur/limiteur, dithering, DR, gain staging, headroom\n",
      "CONTENT: Elle apporte une réserve de headroom presque illimitée et un bruit de fond extrêmement bas (tant que l’on ne repasse pas par un convertisseur, voir plus loin). Représentation et correspondance des niveaux nominaux et pics en analogique et numérique C’est pourquoi un niveau d’enregistrement à -18 ou -20 dB en moyenne , avec des pics ne dépassant jamais les -6 ou -8 dB , permet de conserver une très bonne qualité audio à posteriori. Tout en gardant une bonne réserve de niveau, les pistes seront alors plus facile à mixer! Calibration des convertisseurs à -18 dBFS Quand le signal est toujours analogique, au niveau du préampli, tu peux pousser le gain de celui-ci afin de l’attaquer en saturation et profiter de sa « couleur analogique ». C’est pourquoi le standard de calibration des convertos se fait autour des -18 dBFS. On a alors le niveau nominal du préampli (0 VU) qui correspond au niveau nominal numérique d’enregistrement à -18 dBFS. Tu peux te demander pourquoi ne pas simplement effectuer un traitement limiteur brickwall à la prise pour être sûr de ne pas dépasser le 0 dBFS? Mais ce procédé reviendrait alors à « écraser » les niveaux les plus forts et donc à réduire la plage dynamique du morceau! C’est au mastering que l’on s’occupera de la plage dynamique (voir plus loin). Un limiteur brickwall est idéalement utilisé lors de cette dernière étape seulement. La dynamique sonore à 32 bits float pendant la production Une fois tous les signaux audio convertis en numérique, on entre dans le monde « 32 bits float » de la DAW . Comme on l’a vu , on possède maintenant une plage dynamique de travail presque infini! On pourrait alors se laisser tenter à complètement ignorer les niveaux audio des différentes pistes.\n",
      "\n",
      "ARTICLE: 10 logiciels incontournables pour le sound design\n",
      "KEYWORDS: plugin, sound design\n",
      "CONTENT: Alors tu me diras, wow c’est super pour le son à l’image, mais pour le sound design en création musicale? Eh bien c’est pareil! Les banques de sons peuvent aussi réagir à l’audio enregistré sur ta DAW (pour des percussions ou autre) mais également être contrôlées par Midi. Dans la création musicale moderne, beaucoup d’effets sonores (Foley ou FX) s’adaptent magnifiquement dans un contexte rythmique ou musical. La richesse spectrale et la complexité rythmique inhérente à ces sons est souvent sous-estimée. En plus de Reformer pro, Krotos a également dans sa palette les outils Dehumanizer et Weaponizer qui sont dans la même veine et valent aussi le coup. Demo: Autres recommandations: Sous le terme “transformation vocale”, on peut y retrouver d’autres types de technologie audio: – AudioEase Speakerphone : Comment ne pas penser aux maîtres de la convolution avec la société hollandaise AudioEase . Très connus pour leur reverb phare Altiverb , Speakerphone est aussi un outil très utile pour transformer une voix “normale” en une voix sortant de n’importe quel endroit (appareils électroniques, mégaphone, etc, etc…) – Zynaptiq Wormhole : Grâce à une combinaison de “warping” spectral, d’algorithmes de reverb riche, de pitch-shifting et de morphing , Zynaptiq (encore eux) permet avec Wormhole d’obtenir rapidement des ambiences surréalistes ou des voix d’aliens, monstres et robots en tout genre. – Celemony Melodyne : voir plus haut – Flux Ircam Trax : Ce plugin est absolument époustouflant! Il permet, par exemple, de passer d’une voix d’homme (ou femme) à une voix d’enfant ou de personne âgée avec un réalisme rare! – Izotope Vocalsynth : Izotope n’est aussi pas en reste avec son vocoder du futur.\n",
      "\n",
      "ARTICLE: Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?\n",
      "KEYWORDS: apprentissage, Audio, composition, DAW, home-studio, MIDI, production musicale\n",
      "CONTENT: Partir d’un son avec déjà trop de modulations et un timbre fou ne va pas forcément t’aider à obtenir ce que tu recherches. L'apprentissage de l'écoute à travers la manipulation des effets audio Les traitements audio c’est aussi l’emploi des processeurs et effets utilisés par les ingénieurs du son pour mixer et masteriser un morceau. Ces mêmes outils (compresseur, EQ, delay, reverb, etc..) peuvent être aussi avantageusement utilisés en phase de création musicale. La compréhension des paramètres de tous ces effets audio et leurs conséquences sur le signal audio est primordiale. C’est l’occasion de t’initier au travail ultérieur de l’ingénieur en mixage. Cela implique le développement de ton premier outil de travail: l’oreille. L’apprentissage d’une DAW devient alors l’apprentissage de l’écoute du son dans ses trois dimensions: sa dynamique (compression, gate, limiteur…), son spectre fréquentiel (EQ) et sa temporalité (reverb, delay…). Conclusion Maintenant que tu sais un peu mieux le rôle de producteur (en home-studio), par quoi commencer et les quelques trucs à savoir, il est temps de passer à l’action! Télécharge la démo d’une DAW et commence ton apprentissage dès maintenant. Complètement novice en production musicale? Commence par consulter les articles dont les liens figurent à cette page . Pour aller plus loin: Seconde phase d'apprentissage de sa DAW (ou en parallèle) Bien évidemment suivant les cas, tu peux avoir d’autres préoccupations de débutant quand tu commences avec une DAW comme savoir s’enregistrer . Dans ce cas-là, les autres axes d’apprentissage (en parallèle) concernent tout le travail « Out of the Box » , c’est-à-dire tout ce qui concerne les outils du home-studio en-dehors du logiciel audio à savoir: L’interface audio (ou carte son) et les configs audio Comment choisir et utiliser un micro? Comment enregistrer un instrument (Voix, …) ?\n"
     ]
    }
   ],
   "source": [
    "query = 'Comment obtenir une musique de haute qualité au même niveau sonore que les autres?'\n",
    "search_results = elastic_search_knn_test(query, 'paraphrase', 'LA POST-PROD')\n",
    "prompt = build_prompt(query, search_results)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508d1be",
   "metadata": {},
   "source": [
    "### Final RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a54c74a-78fa-4684-b19b-f6bba6273cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "200a1d40-a113-4737-99ec-ac7e1c6114d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, embedding_model, category):\n",
    "    search_results = elastic_search_knn(query, embedding_model, category)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a3357",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58469b47-a3ee-4941-9466-d944c82d7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour obtenir une musique de haute qualité au même niveau sonore que les autres, il est essentiel de porter attention à plusieurs éléments clés lors du processus de mixage et de mastering :\n",
      "\n",
      "1. **Mixage des Fréquences Médiums** : Un équilibre correct des fréquences médiums est crucial, car ces fréquences ne varient guère avec le volume et permettent de maintenir la perception des instruments à différents niveaux d'écoute. Par exemple, il est conseillé de traiter les sons de basse dans les hautes médiums pour s'assurer qu'ils soient perçus même à faible volume.\n",
      "\n",
      "2. **Gérer la Dynamique** : Utiliser la dynamique de manière réfléchie pendant le mixage permet de diriger l’attention de l’auditeur sur les éléments les plus importants de la musique, tandis que la compression peut aider à stabiliser les niveaux perçus.\n",
      "\n",
      "3. **Mastering et Loudness** : En phase de mastering, il est crucial de travailler sur la plage dynamique et le loudness pour que le morceau soit compétitif par rapport aux autres dans le même genre musical. Cela implique d’optimiser à la fois les pics de volume et le volume moyen perçu.\n",
      "\n",
      "4. **Calibrage Correct des Niveaux** : Il est recommandé de calibrer les niveaux d'enregistrement à -18 dBFS pour garantir une bonne qualité audio. Cela donne également de la headroom pour éviter la saturation.\n",
      "\n",
      "En combinant ces techniques et en utilisant des outils comme des égaliseurs et des limiteurs de manière stratégique, vous serez en mesure d'atteindre un niveau sonore satisfaisant tout en préservant la qualité de votre musique.\n",
      "\n",
      "Voici les trois articles d'Arsonor les plus pertinents pour approfondir ce sujet :\n",
      "\n",
      "1. **La gestion des niveaux sonores (3): Variations du loudness**  \n",
      "   URL: [La gestion des niveaux sonores (3)](https://arsonor.com/articles/loudness)\n",
      "\n",
      "2. **Comment gérer l’équilibre dynamique de la musique?**  \n",
      "   URL: [Comment gérer l’équilibre dynamique de la musique?](https://arsonor.com/articles/equilibre-dynamique)\n",
      "\n",
      "3. **Le Mastering: 6 différences fondamentales qui le séparent du mixage**  \n",
      "   URL: [Le Mastering: 6 différences fondamentales](https://arsonor.com/articles/mastering-6-differences)\n"
     ]
    }
   ],
   "source": [
    "category = 'LA POST_PROD'\n",
    "query = 'Comment obtenir une musique de haute qualité au même niveau sonore que les autres?'\n",
    "embedding_model = 'paraphrase'\n",
    "response = rag(query, embedding_model, category)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be4d02-5d0f-465b-9b75-26dac1b1cbb7",
   "metadata": {},
   "source": [
    "# Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286045b2-a6a9-4120-9d75-8bdf4318f18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>chunk</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quel est l'impact de l'IA sur la post-producti...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment les outils IA simplifient-ils le trava...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels avantages l'IA apporte-t-elle aux artist...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment un débutant peut-il améliorer ses prod...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quelle est l'évolution des outils audio pour l...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      category  \\\n",
       "0  Quel est l'impact de l'IA sur la post-producti...  LA POST-PROD   \n",
       "1  Comment les outils IA simplifient-ils le trava...  LA POST-PROD   \n",
       "2  Quels avantages l'IA apporte-t-elle aux artist...  LA POST-PROD   \n",
       "3  Comment un débutant peut-il améliorer ses prod...  LA POST-PROD   \n",
       "4  Quelle est l'évolution des outils audio pour l...  LA POST-PROD   \n",
       "\n",
       "        chunk   article  \n",
       "0  4615db39-1  4615db39  \n",
       "1  4615db39-1  4615db39  \n",
       "2  4615db39-1  4615db39  \n",
       "3  4615db39-1  4615db39  \n",
       "4  4615db39-1  4615db39  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question = pd.read_csv('../data/ground-truth-300.csv')\n",
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0a4048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Quel est l'impact de l'IA sur la post-production audio et musicale\",\n",
       " 'category': 'LA POST-PROD',\n",
       " 'chunk': '4615db39-1',\n",
       " 'article': '4615db39'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bd63de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['chunk']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['chunk_id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055795b",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'camembert':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2916c7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0c4855cefb4e8382a814ba036abdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8748251748251749, 'mrr': 0.6097562160062151}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'camembert', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9bef9",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'mbert':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7df1b090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e5950dddf24f4b812a90d918ef863b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.877972027972028, 'mrr': 0.6076655289155277}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'mbert', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9d67a",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'paraphrase', k=10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "425699e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70776d9aced04a4686d2d8561a2b5a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8867132867132868, 'mrr': 0.6172445609945602}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d26afd",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'paraphrase', k=30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "cf664d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85625969193f4a7fb002ee2e7ce15132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8895104895104895, 'mrr': 0.6158666333666325}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa9bb0",
   "metadata": {},
   "source": [
    "Chunks 350_30, model 'paraphrase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2bbc3088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1af6f95bace4c4983d3fdb4f3e6b3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.87313769751693, 'mrr': 0.6015434089361857}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_knn(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b128e35",
   "metadata": {},
   "source": [
    "Chunks 300_50, model 'paraphrase', hybrid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5f2ff269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2c2bfc9631457f9dafa5d298c8424c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8846153846153846, 'mrr': 0.6128640803640799}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search_hybrid(q['question'], 'paraphrase', q['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da30e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_paraphrase_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = paraphrase_model.encode(question)\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bbb9e43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f9c6cb2afd4c279b8c2e9683ad50b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.49965034965034966, 'mrr': 0.28753357753357806}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_paraphrase_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42f25c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_title_tag_paraphrase_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = generate_embedding(question, 'paraphrase')\n",
    "\n",
    "    return elastic_search_knn_test('chunk_title_tag_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06886672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291e18f1a0c64ea8844ed7809634061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.49965034965034966, 'mrr': 0.28753357753357806}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_title_tag_paraphrase_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8fff833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_camembert_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = generate_embedding(question, 'camembert')\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08a2c4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc1dc76de74469793841e5a2a3541b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.1618881118881119, 'mrr': 0.05634254634254627}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_camembert_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40d96a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_multiqa_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "22e69bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140636574b1f4acb9e963834e54f0856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6814685314685315, 'mrr': 0.3852813852813858}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_multiqa_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87bab586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_mpnet_knn(q):\n",
    "    question = q['question']\n",
    "    category = q['category']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn_test('chunk_vector', v_q, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bfb073a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2996b358bac649008c1ceadb5f5b3a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6391608391608392, 'mrr': 0.36160631035631086}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, chunk_mpnet_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
