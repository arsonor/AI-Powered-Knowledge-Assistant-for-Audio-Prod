{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fbd7bbe-145f-4e58-a874-b005dbed225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import minsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454e399-424c-422e-9c60-8a83cf54b729",
   "metadata": {},
   "source": [
    "# Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "21c60918-87b5-4156-88b7-291eb26ed85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/arsonor_chunks_300_50.json', 'r', encoding='utf-8') as file:\n",
    "    documents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "11b71249-d25b-4100-b256-98e07092ebe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_id': '3632a3b4',\n",
       " 'url': 'https://arsonor.com/lintelligence-artificielle-ia-dans-le-studio-de-production-audio-5-6/',\n",
       " 'title': 'L’intelligence artificielle (IA) dans le studio de production audio (5/6)',\n",
       " 'category': 'LA POST-PROD',\n",
       " 'tags': 'dé-mixage, de-noise, de-reverb, deep learning, plug-in audio, restauration audio, stems',\n",
       " 'chunk_id': '3632a3b4-11',\n",
       " 'chunk_text': \"Ce plugin, de part sa simplicité d’utilisation (un ou deux potards à régler) est vite devenu une référence absolue, un « must-have » auprès de tout les ingénieurs du son d’un studio de musique. Plug-in Drumatom de Accusonus Accusonus Regroover pour séparer les éléments d'une boucle de batterie Un autre de leurs logiciels remarquables est Regroover . Celui-ci permet de décomposer efficacement une boucle audio complexe (souvent rythmique, de batterie) en plusieurs boucles contenant chacune un élément/instrument séparé de la boucle principale! Très utile par exemple pour isoler le kick, la snare, les high hats, etc… de n’importe quel fichier audio de drums. C’est la porte ouverte à plus de liberté et de créativité dans la manipulation des boucles audio au-delà de leur forme originale. A sa sortie en 2016, Regroover reçut plusieurs prix d’innovation et fut considéré comme le futur du sampling. Enfin, le bundle ERA , sorti en 2018, est la gamme de produits d’Accusonus qui connaît la croissance la plus rapide. Avec des plugins, comme le « Noise Remover » ou le « Voice leveler » , toujours plus nombreux et rassemblés en une seule interface, le « Audio Clean-up Assistant » , l’ERA Bundle s’impose peu à peu comme un sérieux concurrent à iZotope RX dans le domaine des logiciels de nettoyage et restauration sonore. La simplicité d’utilisation des plugins (souvent munis d’un simple potard à tourner), permet aux créateurs débutants et professionnels d’améliorer instantanément leurs enregistrements audio, pour une réparation audio rapide et efficace. Le bundle ERA de Accusonus Les Zynaptiq Un-Series: Unfilter, Unveil, Unchirp, Unmix Drums Spécialiste dans les algorithmes audio IA avancés, il est logique que Zynaptiq propose une série de plugins performants dans la réparation et restauration sonore.\"}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5a7a7",
   "metadata": {},
   "source": [
    "### With Minsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "46d3d15f-2c46-47ed-a0ac-1df6d3f56159",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['title', 'tags', 'chunk_text'],\n",
    "    keyword_fields=['article_id', 'category', 'chunk_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "376cc4c0-efd8-4437-ba79-2de0a7a02265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x12c01d78770>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a32ed",
   "metadata": {},
   "source": [
    "### With Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ccde57f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "95eeaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "869defd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"arsonor_chunks_300\"\n",
    "\n",
    "# Create index if not already created\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body={\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"article_id\": {\"type\": \"keyword\"},\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"url\": {\"type\": \"keyword\"},\n",
    "                \"category\": {\"type\": \"keyword\"},\n",
    "                \"tags\": {\"type\": \"text\"},\n",
    "                \"chunk_id\": {\"type\": \"keyword\"},\n",
    "                \"chunk_text\": {\"type\": \"text\"},\n",
    "                # \"embedding\": {\"type\": \"dense_vector\", \"dims\": 768}  # assuming 768-dim embeddings\n",
    "            }\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0e16761c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(572, [])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepare_documents_for_indexing(docs):\n",
    "    for doc in docs:\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": doc['chunk_id'],\n",
    "            \"_source\": {\n",
    "                \"article_id\": doc['article_id'],\n",
    "                \"title\": doc['title'],\n",
    "                \"url\": doc['url'],\n",
    "                \"category\": doc['category'],\n",
    "                \"tags\": doc['tags'],\n",
    "                \"chunk_id\": doc['chunk_id'],\n",
    "                \"chunk_text\": doc['chunk_text'],\n",
    "                # \"embedding\": generate_embedding(doc['chunk_text'])  # Add embedding here\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Index the documents in bulk\n",
    "bulk(es, prepare_documents_for_indexing(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4c969-765d-4ad2-b773-30cd5a790bf9",
   "metadata": {},
   "source": [
    "# RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2371fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0dd6789d-dbcd-4bb8-a19c-70213e286f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'De quel matériel ai-je besoin pour créer ma musique dans mon home-studio?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c73c08c8-ce03-43ec-ad67-f9cad23e0d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Pour créer de la musique dans un home-studio, voici une liste du matériel nécessaire :\\n\\n### 1. **Ordinateur**\\n   - Un ordinateur performant (PC ou Mac) avec une bonne quantité de RAM et un processeur rapide pour faire tourner des logiciels de production musicale.\\n\\n### 2. **Logiciel de Production Musicale (DAW)**\\n   - Logiciels tels que Ableton Live, FL Studio, Logic Pro, Pro Tools, ou Reaper pour l'enregistrement, l'édition et la production de musique.\\n\\n### 3. **Interfaces Audio**\\n   - Une interface audio pour connecter vos instruments et microphones à votre ordinateur avec une meilleure qualité sonore.\\n\\n### 4. **Moniteurs de Studio**\\n   - Des enceintes de monitoring pour écouter votre musique avec précision. Choisissez des modèles adaptés à la taille de votre pièce.\\n\\n### 5. **Casque Audio**\\n   - Un bon casque de studio pour le mixage et l'enregistrement, offrant une isolation phonique et une réponse plate.\\n\\n### 6. **Clavier MIDI**\\n   - Un clavier MIDI pour jouer des instruments virtuels et contrôler des plugins.\\n\\n### 7. **Microphone**\\n   - Un microphone de bonne qualité pour l'enregistrement vocal ou d'instruments. Considérez un microphone dynamique ou à condensateur selon vos besoins.\\n\\n### 8. **Support de Microphone**\\n   - Un pied de micro et éventuellement un filtre anti-pop pour les enregistrements vocaux.\\n\\n### 9. **Câbles**\\n   - Des câbles XLR pour connecter le microphone, des câbles TRS ou TS pour les moniteurs et les autres instruments.\\n\\n### 10. **Acoustic treatment (optionnel)**\\n   - Des panneaux acoustiques pour traiter le son de votre pièce et minimiser les résonances et les échos.\\n\\n### 11. **Contrôleur MIDI (optionnel)**\\n   - Pour un contrôle plus élaboré de votre DAW et des instruments virtuels.\\n\\n### 12. **Échantillons et Boucles**\\n   - Bibliothèques d'échantillons et de boucles pour enrichir vos compositions.\\n\\n### 13. **Plugins VST**\\n   - Instruments virtuels et effets audio pour élargir vos possibilités sonores.\\n\\n### 14. **Station de travail ergonomique**\\n   - Un bureau et une chaise confortables pour travailler de manière productive.\\n\\n### Autres accessoires :\\n- **Une bonne connexion Internet** pour télécharger des plugins, des mises à jour, et des tutoriels.\\n- **Un système de sauvegarde** pour protéger vos projets musicaux.\\n\\nEn fonction de votre budget et de votre style musical, vous pouvez ajuster cette liste et investir dans du matériel de meilleure qualité ou dans des éléments spécifiques à vos besoins.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": query}]\n",
    "    )\n",
    "    \n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674dc18",
   "metadata": {},
   "source": [
    "### Search results with Minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "297ea691-22dd-4982-abd3-4104f6467a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a998c0",
   "metadata": {},
   "source": [
    "### Search results with Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2b089124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query, category):\n",
    "    search_query = {\n",
    "        \"size\": 10,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title\", \"tags\", \"chunk_text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"category\": category\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606af0fc",
   "metadata": {},
   "source": [
    "### Search results with Elasticsearch and Two-level retrieval mechanism (article-level followed by chunk-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c62a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search2(query, category=None, min_score=0.1):\n",
    "    # First-level: Article search with diversity\n",
    "    article_filter = {\n",
    "        \"bool\": {\n",
    "            \"should\": [\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"title^3\", \"tags^2\", \"category\"],\n",
    "                        \"type\": \"cross_fields\",\n",
    "                        \"operator\": \"or\",\n",
    "                        \"tie_breaker\": 0.3\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"filter\": []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if category:\n",
    "        article_filter['bool']['filter'].append({\"term\": {\"category\": category}})\n",
    "\n",
    "    article_search_body = {\n",
    "        \"query\": article_filter,\n",
    "        \"size\": 20,  # Increased size for more diversity\n",
    "        \"_source\": [\"article_id\", \"title\", \"category\", \"tags\"],\n",
    "        \"collapse\": {\n",
    "            \"field\": \"article_id\",  # Collapse results by article_id\n",
    "            \"inner_hits\": {\n",
    "                \"name\": \"most_relevant_chunk\",\n",
    "                \"size\": 1,\n",
    "                \"sort\": [{\"_score\": \"desc\"}]\n",
    "            },\n",
    "            \"max_concurrent_group_searches\": 4\n",
    "        },\n",
    "        \"min_score\": min_score\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        article_search_results = es.search(index=index_name, body=article_search_body)['hits']['hits']\n",
    "    except Exception as e:\n",
    "        print(f\"Error in article search: {e}\")\n",
    "        return [], []\n",
    "\n",
    "    if not article_search_results:\n",
    "        return [], []\n",
    "\n",
    "    # Extract unique article IDs\n",
    "    top_article_ids = list(set(hit['_source']['article_id'] for hit in article_search_results))\n",
    "\n",
    "    # Second-level: Diverse chunk-level search\n",
    "    chunk_filter = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"terms\": {\"article_id\": top_article_ids}},\n",
    "                {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"chunk_text^2\", \"title\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                        \"operator\": \"or\",\n",
    "                        \"fuzziness\": \"AUTO\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    chunk_search_body = {\n",
    "        \"query\": chunk_filter,\n",
    "        \"size\": 20,  # Increased size\n",
    "        \"_source\": [\"article_id\", \"chunk_id\", \"chunk_text\", \"title\"],\n",
    "        \"collapse\": {\n",
    "            \"field\": \"article_id\",  # Ensure chunks from different articles\n",
    "            \"inner_hits\": {\n",
    "                \"name\": \"alternative_chunks\",\n",
    "                \"size\": 2  # Get 2 best chunks per article\n",
    "            }\n",
    "        },\n",
    "        \"min_score\": min_score\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        chunk_search_results = es.search(index=index_name, body=chunk_search_body)['hits']['hits']\n",
    "    except Exception as e:\n",
    "        print(f\"Error in chunk search: {e}\")\n",
    "        return article_search_results, []\n",
    "\n",
    "    return article_search_results, chunk_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c172e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_search_results(article_results, chunk_results):\n",
    "    processed_results = []\n",
    "    \n",
    "    # Create a mapping of article_id to article details\n",
    "    article_map = {hit['_source']['article_id']: hit['_source'] for hit in article_results}\n",
    "    \n",
    "    # Process chunk results and combine with article information\n",
    "    for chunk_hit in chunk_results:\n",
    "        article_id = chunk_hit['_source']['article_id']\n",
    "        if article_id in article_map:\n",
    "            article_info = article_map[article_id]\n",
    "            \n",
    "            # Get inner hits (alternative chunks)\n",
    "            alternative_chunks = chunk_hit['inner_hits']['alternative_chunks']['hits']['hits']\n",
    "            \n",
    "            processed_result = {\n",
    "                'article_id': article_id,\n",
    "                'title': article_info['title'],\n",
    "                'category': article_info.get('category', ''),\n",
    "                'tags': article_info.get('tags', []),\n",
    "                'chunks': [\n",
    "                    {\n",
    "                        'chunk_id': alt_chunk['_source']['chunk_id'],\n",
    "                        'chunk_text': alt_chunk['_source']['chunk_text'],\n",
    "                        'score': alt_chunk['_score']\n",
    "                    }\n",
    "                    for alt_chunk in alternative_chunks\n",
    "                ],\n",
    "                'overall_score': chunk_hit['_score']\n",
    "            }\n",
    "            processed_results.append(processed_result)\n",
    "    \n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ceeb7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_diversity(query, category=None):\n",
    "    article_results, chunk_results = elastic_search2(query, category)\n",
    "    processed_results = process_search_results(article_results, chunk_results)\n",
    "    \n",
    "    return processed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc3b25a",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "460e2c4b-d2b5-416a-aeb8-b2a503f8c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're an audio engineer and sound designer instructor for beginners.\n",
    "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
    "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "Finally, recommend the top 3 Arsonor articles (refer to their 'title') that are the best to read for answering this question.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "article title: {title}\n",
    "article keywords: {tags}\n",
    "content: {chunk_text}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c874bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += entry_template.format(**doc) + \"\\n\\n\"\n",
    "    \n",
    "    # Recommend top 3 articles\n",
    "    recommended_articles = [(doc['title'], doc['url']) for doc in search_results[:3]]\n",
    "    recommended_articles_str = \"\\n\".join(f\"- {title}\" for title in recommended_articles)\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ce9d435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt2(query, chunk_search_results, article_search_results):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in chunk_search_results:\n",
    "        context += entry_template.format(**doc['_source']) + \"\\n\\n\"\n",
    "\n",
    "    # Recommend top 3 articles\n",
    "    recommended_articles = [doc['_source']['title'] for doc in article_search_results[:3]]\n",
    "    recommended_articles_str = \"\\n\".join(f\"- {title}\" for title in recommended_articles)\n",
    "\n",
    "    # Build the full prompt\n",
    "    prompt = prompt_template.format(question=query, context=context + \"\\nRecommended articles:\\n\" + recommended_articles_str)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6383065f-7541-4718-8c05-b577ade7d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = elastic_search(query, category='LE HOME STUDIO')\n",
    "prompt = build_prompt(query, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "135d764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_search_results, chunk_search_results = elastic_search2(query, category=None)\n",
    "prompt = build_prompt2(query, chunk_search_results, article_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5da68f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article_id': 'df6d71b8',\n",
       "  'title': 'Comment bien débuter en MAO: le home-studio démystifié',\n",
       "  'category': 'LE HOME STUDIO',\n",
       "  'tags': 'DAW, hardware, home-studio, MAO, matériel audio, plugin, software',\n",
       "  'chunks': [{'chunk_id': 'df6d71b8-1',\n",
       "    'chunk_text': \"La MAO (Musique Assistée par Ordinateur) est en vogue depuis l’ère du numérique. Un ordinateur peut devenir facilement un centre de production musicale et audiovisuelle. Si en plus c’est un portable, te voilà à la tête d’un studio d’enregistrement mobile! Il est néanmoins nécessaire de comprendre le cheminement du signal audio et les divers éléments constituant un véritable petit studio. Un ordinateur c’est déjà pas mal mais il ne reste qu’un support. Il faut ensuite les éléments qui vont permettre de faire rentrer l’audio si on veut enregistrer des sons extérieurs, les manipuler puis les ressortir pour finalement pouvoir écouter du mieux possible. Dans l’univers de la MAO, tu découvriras vite une jungle de matériels et de fabricants divers où il sera facile de s’y perdre ou de se décourager. Aussi, je n’aborderai pas ici le détail des marques, prix et caractéristiques de chaque élément, le but de l’article étant surtout de présenter un aperçu global de ce qui constitue un home-studio avant qu’on entre dans le vif du sujet. Le home studio, de l'audio professionnel à domicile Je sais que pour la plupart des novices cet univers de l’audio peut paraître effrayant, surtout à la vue de certains studios suréquipés ou à la lecture d’un article sur la dernière machine en vogue dans un journal spécialisé. C’est sûr tu trouveras toujours quelqu’un pour te montrer ses 50 synthétiseurs analogiques, ses 10 boîtes à rythmes, ses 3 ordinateurs et quelques interfaces audio multi-pistes avec leurs micros, le tout pour plus de 10000€. La vérité : Pour commencer, tu n’as besoin d’aucune machine autre qu’un simple ordinateur. L’autre vérité : Pour créer du grand art, tu n’as toujours pas besoin d’appareil en plus.\",\n",
       "    'score': 39.05181},\n",
       "   {'chunk_id': 'df6d71b8-2',\n",
       "    'chunk_text': \"C’est sûr tu trouveras toujours quelqu’un pour te montrer ses 50 synthétiseurs analogiques, ses 10 boîtes à rythmes, ses 3 ordinateurs et quelques interfaces audio multi-pistes avec leurs micros, le tout pour plus de 10000€. La vérité : Pour commencer, tu n’as besoin d’aucune machine autre qu’un simple ordinateur. L’autre vérité : Pour créer du grand art, tu n’as toujours pas besoin d’appareil en plus. I - Ce qu'il te faut dans ton home studio 1) L'ordinateur Oui celui que tu utilises en ce moment fera sûrement l’affaire. Outre l’éternel débat Mac ou PC, aujourd’hui, si ton ordinateur, quel qu’il soit, est relativement récent, tu ne devrais pas avoir trop de problèmes pour travailler de l’audio au départ. Voici tout de même quelques recommandations importantes : – S’assurer d’avoir un processeur rapide et fiable et une carte mère qui possède suffisamment de place pour y ajouter de la RAM (mémoire vive). Anticipes l’avenir, tes besoins iront crescendo au fur et à mesure que tu seras impliqué dans la musique numérique. – Suivant tes objectifs, il sera préférable de garder ton ordinateur uniquement pour la musique et donc de le configurer spécifiquement pour cela. Sois réaliste et vérifies si ta machine sera capable de supporter tous tes logiciels musicaux en plus d’autres applications que tu possèdes déjà. Attention avec les PC avec notamment l’antivirus qui prend beaucoup de ressources. Personnellement j’ai un macbook avec le strict minimum, par exemple aucun jeu ou autre application gourmande en énergie n’y est installée (à part tout ce qui est lié à la musique bien sûr).\",\n",
       "    'score': 32.601364}],\n",
       "  'overall_score': 39.05181},\n",
       " {'article_id': '150211e1',\n",
       "  'title': 'Deviens toi aussi producteur musical depuis ton home studio',\n",
       "  'category': 'LE HOME STUDIO',\n",
       "  'tags': 'home-studio, ingénieur du son, MAO, production musicale',\n",
       "  'chunks': [{'chunk_id': '150211e1-1',\n",
       "    'chunk_text': 'Avis à tous les passionnés de musique, c’est avec grand plaisir que j’ouvre ce blog afin de partager ma passion de la MAO (Musique Assistée par Ordinateur) et du home studio , de la création au mixage audio. Alors tu te demandes sûrement… … Qu’est-ce que Arsonor? Contexte De nos jours, la musique est omniprésente. Les médias traditionnels (radio, télé) et surtout maintenant Internet et les réseaux sociaux nous font découvrir de nouveaux artistes tous les jours. Des sites comme Soundcloud ou Bandcamp sont absolument remplis de création de tout bords de façon continue. Quant à Youtube , c’est devenu la plus grande plateforme d’écoute de musique en ligne où il est devenu très facile d’écouter et de publier. Depuis quelques années, le monde de la création et de la production musicale s’est considérablement ouvert grâce à l’évolution ininterrompue et considérable de l’informatique, l’émergence d’internet à haut débit et le développement des échanges de fichier à grande échelle. Par le passé, les premiers home studio pouvaient ressembler à un véritable arsenal où s’enchevêtraient câbles, patchs et racks remplis de matériel, et le tout à un coût exorbitant! Aujourd’hui tout commence avec un simple ordinateur et un casque car le matériel a été remplacé par son équivalent logiciel. De plus en plus d’artistes émergent en composant chez eux, depuis leur home studio avant de finaliser leurs projets dans un studio professionnel (voire toujours depuis chez soi) . On parle alors de plus en plus de création DIY (“Do It Yourself”) et d’un nouveau rôle des amateurs qui sont en mesure de travailler avec des moyens équivalents aux professionnels.',\n",
       "    'score': 36.084103},\n",
       "   {'chunk_id': '150211e1-2',\n",
       "    'chunk_text': \"De plus en plus d’artistes émergent en composant chez eux, depuis leur home studio avant de finaliser leurs projets dans un studio professionnel (voire toujours depuis chez soi) . On parle alors de plus en plus de création DIY (“Do It Yourself”) et d’un nouveau rôle des amateurs qui sont en mesure de travailler avec des moyens équivalents aux professionnels. Exemple de home studio à ses débuts plus minimaliste et actuel Souvent téléchargés de manière illégale, les développeurs de logiciels ont rapidement saisi le potentiel grand public de ces outils qui existaient pour la plupart depuis des années. Le logiciel Logic Pro d’Apple passe autour de 200 Euros en téléchargement direct (il coûtait près de 1000 Euros à l’origine). Et Ableton Live , un des logiciels les plus dynamiques du marché, se pare de nouvelles interfaces colorées et mise avant tout sur une plus grande accessibilité (pour 600 Euros la version complète). A côté de ces logiciels, un véritable écosystème se crée de lui-même: communauté et forums s’échangent des conseils et des “tips” pour mieux produire, tandis que des milliers de tutoriels pour débutant ou niveau plus avancé sont disponibles sur des plateformes de vidéos. Cette nouvelle ère du monde de la musique post-crise du disque remplace peu à peu notre rôle de simple auditeur à un rôle de créateur: avec l’accessibilité de la musique moderne, n’importe quel passionné de musique devient créateur! Développes l'artiste qui est en toi! Mais est-ce suffisant pour obtenir des résultats en home studio? Non! Encore faut-il acquérir les connaissances théoriques et pratiques du musicien/ingénieur du son. Pour cela, plusieurs obstacles viendront entraver ta route. En voici deux exemples: 1) Technologie VS Créativité En tant qu’artiste, tu te rendras compte que la créativité l’emporte toujours sur la technologie .\",\n",
       "    'score': 21.740608}],\n",
       "  'overall_score': 36.084103},\n",
       " {'article_id': 'afc9b1b1',\n",
       "  'title': 'L’intelligence artificielle (IA) dans le studio de production audio (2/6)',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'écosystème IA, IA, mastering, services en ligne',\n",
       "  'chunks': [{'chunk_id': 'afc9b1b1-3',\n",
       "    'chunk_text': 'Ils revisitent et dirigent le son global du mix – et cela, pour moi, c’est produire. Et c’est génial. Je suis vraiment heureux que les ingénieurs mastering agissent en tant que coproducteurs, dans la mesure où nous ne faisons qu’apporter de la productivité aux artistes, nous ne prenons pas d’emplois. Je ne pense donc pas qu’il y aura moins d’opportunités de carrière avec LANDR. Je pense qu’il y aura simplement plus de musique. » * * https://www.soundonsound.com/music-business/ai-music , article datant de 2018, donc le constat et les chiffres avancés ont encore dû évoluer. Remplacer le studio de Mastering par un algorithme IA, comment cela a été rendu possible? Plusieurs raisons expliquent le succès et la confirmation de LANDR: 1) LANDR répond à une demande spécifique Les règles du jeu ont changé. L’objectif du mastering est de rendre l’expérience d’écoute cohérente dans tous les formats. Le processus varie selon les différents formats (Spotify, CD, films, etc.) car chacun a des contraintes de volume différentes, ce qui rend le mastering extrêmement technique et potentiellement coûteux. On ne va pas se mentir: de très bons ingénieurs mastering qualifiés et bon marché ne courent pas les rues. On est d’accord que pour des cas bien spécifiques, l’IA n’est pas prête de remplacer la finesse d’un expert humain. Mais la demande aujourd’hui se dirige énormément vers les plateformes de streaming en ligne (Spotify, Youtube, Soundcloud, etc, …) . Cela requiert donc moins de compétences techniques que pour d’autres supports plus classiques (vinyles, CD). 2) Le mixage en home-studio, préalable au mastering, se démocratise de plus en plus Une condition sine qua non pour que l’algorithme IA sorte un résultat satisfaisant est qu’en amont le mixage soit irréprochable .',\n",
       "    'score': 25.671091},\n",
       "   {'chunk_id': 'afc9b1b1-4',\n",
       "    'chunk_text': 'Cela requiert donc moins de compétences techniques que pour d’autres supports plus classiques (vinyles, CD). 2) Le mixage en home-studio, préalable au mastering, se démocratise de plus en plus Une condition sine qua non pour que l’algorithme IA sorte un résultat satisfaisant est qu’en amont le mixage soit irréprochable . Pour cela, les outils MAO et logiciels de mixage audio sont en constante évolution (voir les prochains articles). Leur accessibilité et facilité de prise en main fait que de plus en plus de producteurs parviennent à obtenir en toute autonomie un mixage préalable de leur morceau de haute qualité. 3) L’algorithme IA s’améliore avec le temps C’est la définition même d’un algorithme à intelligence artificielle (voir premier article ). Plus il va y avoir d’utilisateurs et de contenus (styles musicaux) différents à analyser, plus l’IA va se perfectionner avec le temps. Le moteur alimenté par l’IA de LANDR «écoute» votre chanson non masterisée, identifie le genre et applique l’égalisation de mastering, la compression multibande et d’autres traitements pertinents, le tout sans intervention humaine. Le traitement est adaptatif, répondant aux besoins de la chanson en ajustant continuellement l’égaliseur, la compression et d’autres outils de traitement tout au long de la piste. Chaque fois que LANDR masterise une track et écoute de la nouvelle musique, mieux il s’améliore, grâce à des algorithmes de « deep learning » (auto-apprentissage) . Des services de mastering automatique… L’exemple de LANDR a fini par convaincre une multitude d’autres concurrents qui croient en ce modèle. On ne compte plus ces dernières années des services en ligne de mastering musical ou d’audio en général qui fleurissent sur le web. Après LANDR, on peut citer entre autres: Cloudbounce eMastered Moises iMusician même SoundCloud s’y est mis de son service pour que les morceaux soient optimisés sur sa propre plateforme.',\n",
       "    'score': 18.275568}],\n",
       "  'overall_score': 25.671091},\n",
       " {'article_id': '173567a9',\n",
       "  'title': 'Amen Break Beatmaking: mise en pratique dans Ableton Live',\n",
       "  'category': 'LE SOUND DESIGN',\n",
       "  'tags': 'ableton live, amen break, boucle audio, breakbeat, pitch, sampling, time-stretch, warp',\n",
       "  'chunks': [{'chunk_id': '173567a9-5',\n",
       "    'chunk_text': 'Inconvénients de la méthode 1 Tempo du projet fixé définitivement Comme la boucle change de longueur avec le tempo, je suis obligé de fixer le tempo de mon projet dès le départ et ne plus y toucher. Avec cette méthode, je fais de ma boucle le maître de la rythmique. Mais si je veux qu’elle joue plus lentement et donc plus grave, je change en conséquence le tempo de mon projet. Suppose de connaître son tempo d’origine Je savais que le Amen Break original joue à 138 BPM, ce qui m’a permis de caler immédiatement la boucle à la grille en indiquant le même tempo pour le projet. Editing complexe et chronophage pour changer le groove Si jamais, je veux changer ce groove et recaler certaines transitoires, je dois passer par de l’editing fastidieux dans la vue arrangement. Voilà pour la première option de ce qu’on peut faire avec une boucle rythmique dans un projet musical. Maintenant on va voir une autre manière de travailler avec cette boucle pour pouvoir l’utiliser autrement: – Cela peut être parce que j’ai déjà une rythmique en place, basée sur d’autres parties MIDI programmées. Auquel cas je veux parfaitement synchroniser ma boucle avec le reste et pas l’inverse. – C’est aussi dans le cas fréquent où je veux modifier complètement la rythmique et créer d’autres modèles plus personnalisés. Ceci dit, rien n’interdit aussi de tirer parti du meilleur des deux mondes en quantifiant ma boucle à la rythmique imposée puis de la laisser libre et intacte dans des parties du morceau plus épurées, lorsqu’elle joue seule par exemple. Méthode 2: Calage de la boucle et détermination de son tempo (mode Warp enclenché) Dans cette deuxième méthode, je vais vouloir dès le départ synchroniser et quantifier ma boucle à une grille bien précise.',\n",
       "    'score': 24.145088},\n",
       "   {'chunk_id': '173567a9-6',\n",
       "    'chunk_text': 'Ceci dit, rien n’interdit aussi de tirer parti du meilleur des deux mondes en quantifiant ma boucle à la rythmique imposée puis de la laisser libre et intacte dans des parties du morceau plus épurées, lorsqu’elle joue seule par exemple. Méthode 2: Calage de la boucle et détermination de son tempo (mode Warp enclenché) Dans cette deuxième méthode, je vais vouloir dès le départ synchroniser et quantifier ma boucle à une grille bien précise. Donc en gros je fais l’inverse: j’adapte la boucle à une grille existante plutôt que d’adapter la grille à ma boucle. Admettons aussi que je ne connaisse pas le tempo de mon échantillon. Mon audio joue à un certain BPM (qui est en fait 138) mais je commence avec le tempo du projet à 120 par défaut. Maintenant, j’enclenche le mode Warp du clip audio. Cela aura un autre nom si vous utilisez un autre DAW qu’Ableton mais le principe est le même: c’est de synchroniser l’audio à un tempo maître par l’intermédiaire d’un algorithme de time-stretch permettant de modifier le moins possible le timbre de l’audio d’origine quelque soit le tempo maître choisi. On remarque tout de suite que le clip audio ne change plus de longueur et la lecture s’adapte parfaitement aux changements de tempo. La deuxième chose c’est que maintenant, dans la vue du clip audio, Ableton a analysé automatiquement où se trouvent les transitoires (chaque coup de percussion). En double-cliquant dessus, je crée un marqueur Warp . Cela me permet de déplacer l’audio exactement à partir de ce point-là. Faites-vous l’image de la forme d’onde audio comme un élastique et le marqueur Warp comme une épingle que l’on vient planter dans l’élastique pour le fixer exactement à ce point là.',\n",
       "    'score': 23.242739}],\n",
       "  'overall_score': 24.145088},\n",
       " {'article_id': '3fe10ebc',\n",
       "  'title': 'Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?',\n",
       "  'category': 'LE HOME STUDIO',\n",
       "  'tags': 'apprentissage, Audio, composition, DAW, home-studio, MIDI, production musicale',\n",
       "  'chunks': [{'chunk_id': '3fe10ebc-2',\n",
       "    'chunk_text': \"On retrouve même la DAW dans tout studio de production musicale professionnel actuel. Elle permet en effet à un seul ordinateur polyvalent d’émuler toutes les fonctions à la fois de routage, d’enregistrement, de traitement et de mixage de l’audio. Toutes ces fonctions étaient autrefois assurées par des unités matérielles ‘hardware’. La constante amélioration dans la fiabilité et les fonctionnalités des traitements numériques et du stockage des données informatiques au cours des 20 dernières années a permis à la DAW de largement les remplacer. Si nécessaire, la connexion au monde analogique intervient via une interface audio : un appareil comportant des prises d’entrée/sortie (E/S) audio et les convertisseurs du signal analogique vers numérique (ADC) et vice-versa (DAC). Tout cela conjugué aux prix en baisse, la production musicale est devenue beaucoup plus accessible . Une musique de qualité peut se créer sur un ordinateur portable standard, sans hardware coûteux. Vue de la DAW Protools sur lécran d'ordinateur Rôle(s) du producteur musical moderne Mais cette tendance vers une « simplification » des traitements audio a en même temps engendré un effet pervers: la polyvalence nécessaire dans les tâches à accomplir. Selon la définition traditionnelle, le producteur supervise, gère et guide le processus d’enregistrement et de production d’une chanson. Pour des productions de haut calibre (pense Top 40, musique commerciale…), on retrouve normalement un certains nombres de personnes à la production en plus de l’artiste et du producteur. Un manager, un coach, d’autres musiciens, plusieurs ingénieurs du son à l’enregistrement, au mixage puis au mastering, etc… Les musiques électroniques pionnières du home-studio La réalité du home-studiste est qu’il fait généralement tout cela! C’est ce que j’appelle le producteur musical moderne: son rôle est polyvalent, de la proposition d’idées musicales à leur organisation, finalisation puis distribution.\",\n",
       "    'score': 24.008411},\n",
       "   {'chunk_id': '3fe10ebc-3',\n",
       "    'chunk_text': \"Un manager, un coach, d’autres musiciens, plusieurs ingénieurs du son à l’enregistrement, au mixage puis au mastering, etc… Les musiques électroniques pionnières du home-studio La réalité du home-studiste est qu’il fait généralement tout cela! C’est ce que j’appelle le producteur musical moderne: son rôle est polyvalent, de la proposition d’idées musicales à leur organisation, finalisation puis distribution. Ce rôle multi-casquettes et du DIY (« Do It Yourself », fais tout par toi-même) s’est d’ailleurs initialement développé avec l’avènement des musiques électroniques. Le travail énorme que représentait la production d’un morceau de house, techno, etc…, fut au début largement incompris par les médias de masse et les musiciens traditionnels. Ce sont tous ces producteurs qui ont pourtant contribué à l’émergence du home-studio et la démocratisation de la production musicale. Voir d’ailleurs cet excellent documentaire à ce sujet: Aujourd’hui, on ne compte plus toutes les productions à succès et hits commerciaux qui se sont conçus de A à Z dans une chambre à coucher ou une cave aménagée. Et ceci plus seulement pour des musiques électroniques mais pour tout autre style, du jazz au rock, en passant par le son à l’image et les musiques de film! Obstacles à l'apprentissage d'une DAW Alors rempli d’enthousiasme et de motivation, comme toute personne normale, tu vas sur Google pour savoir comment commencer et ce dont tu as besoin. Malheureusement, cela ne se passe pas comme prévu, tu finis par télécharger un programme obscur sans aucune idée de ce que c’est ni comment l’utiliser. La confusion s’installe… Et comme moi, tu t’es peut être aperçu rapidement à quel point le chemin allait être long et tortueux avant d’arriver à quelque chose de potable. Jusqu’à même se décourager et passer finalement à autre chose tellement la montagne que représente le vaste monde de l’audio-numérique semblait insurmontable.\",\n",
       "    'score': 23.521116}],\n",
       "  'overall_score': 24.008411},\n",
       " {'article_id': 'aca8c7fe',\n",
       "  'title': 'L’intelligence artificielle (IA) dans le studio de production audio (1/6)',\n",
       "  'category': 'LE HOME STUDIO',\n",
       "  'tags': 'algorithme, deep learning, IA, logiciel audio, machine learning, plugin, post-production',\n",
       "  'chunks': [{'chunk_id': 'aca8c7fe-5',\n",
       "    'chunk_text': 'A la fin des années 90’s, le DAW (Digital Audio Workstation) , devient le centre névralgique numérique du studio. Le nombre de pistes et de traitements illimités permet alors à l’ingénieur de mix de prendre de plus en plus de pouvoir et agir directement sur la performance de l’artiste. Puis les années 2000 et 2010 verront la tendance croissante à réduire les machines au simple ordinateur. L’ère du home-studio, du « mix in the box » et de la démocratisation des outils à tout un chacun interrogent déjà sur le véritable rôle de l’ingénieur du son aujourd’hui. En quoi l’IA diffère-t’elle d’un simple algorithme: l’exemple du compresseur de la dynamique Si on prend l’exemple du compresseur , son invention a d’abord permis l’automatisation mécanique pour le contrôle des volumes . Avec cet outil, l’ingénieur du son n’avait plus besoin de suivre et régler manuellement le volume d’une source audio à la dynamique trop changeante. Depuis, l’évolution du compresseur en plugin numérique lui permet d’être un outil omniprésent et démocratisé dans le traitement de la dynamique, de l’enregistrement jusqu’au mastering audio. Pourtant, encore aujourd’hui, son utilisation reste complexe et largement incomprise par tout amateur ou novice des traitements audio. Par exemple, lorsque nous utilisons un plug-in de compression pour traiter un enregistrement vocal, le plug-in répond à nos réglages et à la dynamique du matériau de manière prévisible. Cela peut être très utile, mais son efficacité dépend entièrement de la façon dont nous configurons les paramètres de compression et notre capacité à écouter finement les différences. Un enregistrement vocal différent peut nécessiter un ratio de compression différent, voire une chaîne de traitement complètement différente. Au-delà des presets fournis que nous pouvons essayer, les plugins conventionnels ne peuvent pas nous aider à prendre cette décision.',\n",
       "    'score': 22.911173},\n",
       "   {'chunk_id': 'aca8c7fe-1',\n",
       "    'chunk_text': \"Qu'est-ce que la technologie IA dans les outils de production audio? L’intelligence artificielle (IA ou AI en anglais) n’est plus une caractéristique spéculative de la science-fiction. Elle a un effet transformateur sur une vaste gamme d’industries* et l’audio ne fait pas exception. * Selon une étude (Source: Mckinsey Global Institute), l’IA devrait générer 13 billions (mille milliards!) de dollars supplémentaires de revenus d’ici 2030. Cette technologie révolutionnaire devrait créer 58 millions de nouveaux emplois d’ici 2022 (dont la grande majorité sont des emplois que l’on ne connaît pas à l’heure actuelle) (Source: https://www.forbes.com/sites/amitchowdhry/2018/09/18/artificial-intelligence-to-create-58-million-new-jobs-by-2022-says-report/?sh=3f393ff74d4b) J’ai repéré trois grands domaines de l’audio où l’IA s’est bien implantée et fait déjà ses preuves: 1) L’IA au service de l’écoute personnalisée Cela inclut tout le domaine de la reconnaissance musicale et la recommandation personnelle (Smart Speaker, Droits d’auteur, MIR: Music Information Retrieval…) en plein boom sous l’impulsion des diverses plateformes de streaming . C’est aussi le domaine de la synthèse vocale (TTS: Text To Speech recognition) et du traitement de la parole, de dialecte ou de langue. Et enfin, cela inclut aussi le choix individuel d’un mode d’écoute au casque (émulation de sources ou d’espaces réels et spatialisation 3D). 2) L’IA comme assistant de composition et de sound design On retrouve ici tout ce qui concerne les services ou outils de génération de musique automatique (Generative Music) . Cela concerne aussi tous les nouveaux plugins d’assistance au Beatmaking (Beats machine, Générateur automatique de pattern MIDI, d’accords dans la tonalité…) , à la synthèse sonore et au son à l’image. 3) L’IA comme assistant en post-production audio On y retrouve tous ces nouveaux plugins « intelligents » dans le mixage assisté , ainsi que dans la réparation, nettoyage et séparation des sources audio.\",\n",
       "    'score': 18.713852}],\n",
       "  'overall_score': 22.911173},\n",
       " {'article_id': '3632a3b4',\n",
       "  'title': 'L’intelligence artificielle (IA) dans le studio de production audio (5/6)',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'dé-mixage, de-noise, de-reverb, deep learning, plug-in audio, restauration audio, stems',\n",
       "  'chunks': [{'chunk_id': '3632a3b4-2',\n",
       "    'chunk_text': 'De Cedar à iZotope RX: le besoin croissant en logiciel de restauration audio Depuis, conjointement au développement du numérique, la production de médias (vidéos, podcasts…) s’est démocratisé. Et paradoxalement, le numérique et les progrès dans les méthodes d’enregistrement n’ont pas supprimé le besoin en restauration audio, bien au contraire! Souvent, l’enregistrement n’a pas pu se faire dans des conditions optimales. Une voix off, des dialogues ou une prise de chant/instrument se doivent d’être propres et intelligibles. Les types de problèmes rencontrés peuvent être nombreux et divers: bruits ambiants intempestifs (bruit de fond, souffle, sifflement, bourdonnement, vent, téléphone, moteur, oiseaux, circulation automobile, etc … ) bruits liés à de mauvais réglages ou manipulations (clics et craquements, distorsion/saturation du son) bruits liés à la parole (bouche, salive, sibilances, plosives, pops, …) ambiance liée à une mauvaise acoustique (échos, réverbération) mauvaise qualité due à l’utilisation de matériel « cheap » (micro, interface audio bas de gamme, faible débit numérique des communications en streaming) Ces temps de communication et d’enregistrements par Zoom/Skype ou avec son smartphone sont particulièrement propices au recours à des logiciels de restauration audio. Il y a aussi tout le secteur de l’archivage et la restauration de vieux enregistrements analogiques, vintages (suppression du wow & flutter notamment) , et des « re-mastering » aux goûts du jour. La règle d’or en audio: « Shit In, Shit Out » Il ne faut pas s’y méprendre, le traitement audio en post-production n’a rien de magique! Une règle d’or dans le milieu professionnel est l’expression « Shit In, Shit Out » . Et le fameux « on verra ça en post-production » souvent déclamé lors de la prise de son est la hantise de tout ingénieur du son.',\n",
       "    'score': 20.917606},\n",
       "   {'chunk_id': '3632a3b4-9',\n",
       "    'chunk_text': \"En effet, quoi de mieux qu’un service de streaming avec des chercheurs spécialisés en recommendation et analyse musicale (Music Information Retrieval) et ayant accès à un immense catalogue de musique, pour développer une IA spécialisée en dé-mixage? C’est ainsi que naît Spleeter en 2019. Il se présente sous la forme d’un « package en open source » , avec le code accessible sur Github à tout un chacun pour être téléchargé et utilisé! Séparation des sources audio en 4 stems: Vocals, Drums, Bass et Autre. Le code promet à priori un dé-mixage en 2, 4 ou 5 stems, de façon tout à fait correcte (et du coup révolutionnaire!). Si bien que bon nombre de marques et éditeurs de plug-ins audio s’en servent allègrement aujourd’hui. Voici une liste non exhaustive des logiciels utilisant le code Spleeter: – Dans les dernières versions d’iZotope RX (depuis RX8) et notamment sa fonction de « Music Rebalance »; – le SpectralLayers dans sa fonction « Unmix » chez Steinberg; – le Acon Digital au sein de Acoustica 7; – VirtualDJ avec leur fonction d’isolation de Stems; – Algoriddim dans leur suite d’applications NeuralMix et djayPRO; – Moises AI Music Platform , une application simplissime pour séparer les stems d’une chanson. La fonction Music Rebalance dans RX qui permet de séparer l'audio en 4 stems comme Spleeter Toutefois, comment faire pour que tout-un-chacun puisse utiliser le code pour ses propres besoins? Car le code en « open source » nécessite d’être exécuter localement en installant un tas de bibliothèques et d’outils python… Spleeter en plug-in VST3 dans Ableton Live Heureusement, la communauté a réagi et un certain Azuki l’a mis à disposition sous la forme d’un plug-in VST3 !\",\n",
       "    'score': 19.64189}],\n",
       "  'overall_score': 20.917606},\n",
       " {'article_id': 'f8fc084e',\n",
       "  'title': 'Masteriser sa musique VS. Déléguer à un professionnel',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'déléguer, environnement de travail, masteriser, studio de mastering',\n",
       "  'chunks': [{'chunk_id': 'f8fc084e-1',\n",
       "    'chunk_text': 'Voilà le dilemne auquel tout producteur musical est confronté à un moment donné de son évolution. Masteriser sa musique relève du challenge. Je t’invite à jeter un coup d’œil à l’article précédent qui montre à quels niveaux le mastering diffère tant du mixage. Déléguer ce travail à un professionnel, avec une paire d’oreilles nouvelles sur ta musique, se révèle souvent la recette du succès. Cependant, il n’est automatique pour personne de remettre sa création dans des mains étrangères pour finir le boulot. Et il n’est pas toujours aussi simple de t rouver la bonne personne, en qui tu peux faire confiance. Je te donne des pistes dans la deuxième partie de l’article pour arriver à tes fins dans l’art de déléguer. Mais d’abord voyons si c’est une si mauvaise idée de mixer et masteriser sa musique soi-même. Mixer et Masteriser sa musique Parfois, des obstacles techniques et financiers entravent l’accès de tous à des studios professionnels, mais ce n’est pas grave. Tout le monde n’a pas le budget ou les outils pour obtenir un Master dans les règles de l’art. Ces choses arrivent. Beaucoup de producteurs mixent et masterisent leur propre musique. Certains le font exceptionnellement bien, d’autres pas. Parmi ces derniers, la déception des résultats obtenus provient souvent des attentes irréalistes de ce que l’on peut accomplir sans les traitements acoustiques et système d’écoute requis. Grosso-modo, il est très difficile de prendre les bonnes décisions sans un environnement d’écoute le plus neutre possible . Il est assez incroyable de réaliser à quel point la configuration de ta salle de travail peut avoir comme effet sur la façon dont tu perçois le son de ton mixage. Il te semble que la basse de ton morceau sonne parfaitement équilibrée dans ton home-studio.',\n",
       "    'score': 19.581648},\n",
       "   {'chunk_id': 'f8fc084e-2',\n",
       "    'chunk_text': \"Grosso-modo, il est très difficile de prendre les bonnes décisions sans un environnement d’écoute le plus neutre possible . Il est assez incroyable de réaliser à quel point la configuration de ta salle de travail peut avoir comme effet sur la façon dont tu perçois le son de ton mixage. Il te semble que la basse de ton morceau sonne parfaitement équilibrée dans ton home-studio. Jusqu’à ce que tu te rendes compte qu’elle est floue et mal définie en écoutant ailleurs. Dans ton home studio, tu te sens comme le roi des producteurs, puis quand vient le moment d’écouter ton travail dans la voiture (ou pire… en public), les différences perçues sont parfois choquantes. Préparer au mieux son environnement de travail et d'écoute C’est pourquoi, même si tu ne disposes pas du meilleur endroit, il est indispensable de définir à quoi doit ressembler l’environnement idéal afin de t’aider à identifier les problèmes dans ta propre salle et y apporter des améliorations: Choisir un endroit le plus calme possible pour que ce que tu écoutes provienne directement de tes HP (enceintes de monitoring), et pas de la pollution sonore environnante; La salle doit être suffisamment grande (tout en évitant les parois parallèles) pour permettre aux informations basses fréquences d’être entendues correctement; La paire d’enceintes doit avoir une courbe de fréquence relativement neutre et descendre assez bas en fréquence, précise en phase et à faible distorsion; Le positionnement des enceintes (idéalement sur des pieds) forme un triangle équilatéral avec ta position, les tweeters pointés vers tes oreilles. Tu peux donc le faire depuis chez toi si tu prépares bien l’emplacement. Assures-toi ensuite d’écouter beaucoup de choses que tu connais et aimes. Prêtes attention à la façon dont cela sonne dans ton environnement d’écoute.\",\n",
       "    'score': 13.408953}],\n",
       "  'overall_score': 19.581648},\n",
       " {'article_id': '70be07f7',\n",
       "  'title': 'Les morceaux de référence (2): Comment les choisir?',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'ear training, écoute critique, liste de références',\n",
       "  'chunks': [{'chunk_id': '70be07f7-2',\n",
       "    'chunk_text': 'Il y a une infinité de choses à écouter lors de l’analyse d’un morceau, et celles-ci peuvent couvrir tous les aspects du mixage. Je parlerai de cet exercice en particulier dans d’autres articles à venir. Le plus de temps tu t’exerceras à analyser des mix, le plus tu développeras ton écoute critique, essentielle au métier du mixeur audio. Comment choisir un (ou plusieurs) morceau de référence? L’analyse d’un mixage fini est une chose, mais s’en servir comme référence pour son propre mixage en est une autre. Il est alors nécessaire de se concentrer sur quelques morceaux sélectionnés, de les apprendre à fond, de les analyser dans les moindres détails de chaque aspect du mixage et de se les rendre facilement accessibles en cas de besoin. Se confectionner une liste personnelle La première chose, si tu travailles pour un client ou une autre personne, c’est de s’en remettre au choix de ce dernier. Il est toujours important d’être le plus clair possible avec le client sur le type de son qu’il recherche. Pour cela, s’il ne te la pas déjà proposé, demandes lui quel morceau/chanson se rapproche le plus du son qu’il recherche. Dans un deuxième temps, ce sont les morceaux de ta liste. Il est bon d’avoir quelques références sous la main à chaque début de mixage. Sur une clé USB si tu es en déplacement ou dans un dossier dédié de ton disque dur si tu travailles de ton home studio. Voici quelques caractéristiques d’un morceau de référence pour t’aider à faire des choix: - du même genre musical Ton choix de référence peut ne pas convenir à tous les mixages. Si tu travailles sur un morceau comprenant des instruments à cordes, et qu’aucune de tes références n’en comporte, il serait sage de rechercher une autre référence.',\n",
       "    'score': 19.45109},\n",
       "   {'chunk_id': '70be07f7-8',\n",
       "    'chunk_text': 'De plus, il est avantageux de faire référence à un mixage non masterisé (et on verra pourquoi dans le prochain article ). Une référence que tu connais sur le bout des doigts sera d’autant plus efficace. Alors écoutes et écoutes les encore, partout, sur tous les supports possibles. A terme, tu seras en possession d’une liste éclectique et variée. Ma propre liste contient des morceaux qui vont de « La flûte enchantée » de Mozart à Michael Jackson « Liberian Girl », en passant par du rock, de la techno ou du jazz. N’hésites pas écrire dans les commentaires quel morceau tu penses constituerait l’idéal pour une référence en mixage.',\n",
       "    'score': 12.455209}],\n",
       "  'overall_score': 19.45109},\n",
       " {'article_id': '813dc16d',\n",
       "  'title': 'L’intelligence artificielle (IA) dans le studio de production audio (4/6)',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'assistant intelligent, deep learning, mixage, plug-in audio, smart plug-in',\n",
       "  'chunks': [{'chunk_id': '813dc16d-2',\n",
       "    'chunk_text': 'Neutron venait donc compléter le panel dans le domaine du mixage audio. Et par la même, iZotope devenait l’un des pionniers de la technologie IA dans le monde des plug-ins audio. Car à ma connaissance, c’est la première fois (hors services en ligne) qu’un plug-in audio grand public exploitait le potentiel de l’intelligence artificielle. Et comme pour Landr, cela fit grand bruit à sa sortie parce qu’encore une fois, on s’interrogeait sur la capacité d’un algorithme à supplanter le travail d’un ingénieur du son humain … Neutron: une assistance fiable pour votre mixage? La nouveauté est de taille: un simple bouton « Mix Assistant » permet au logiciel d’analyser votre piste audio, puis de proposer automatiquement en retour les réglages des plug-ins Neutron (EQ, Compresseur, Transient Shaper, etc…) adaptés au contenu audio. Le \"Mix Assistant\" de Neutron \"écoute\" votre audio et vous créera un preset approprié de mixage. Une fonction \"Balance\" permet aussi de ré-équilibrer les volumes entre différents éléments. Personnellement, je n’ai jamais été très fan du résultat apporté par la seule action du bouton « Mix Assistant » . Evidemment, tout est loin d’être parfait. Et d’ailleurs l’objectif de Neutron n’a jamais été de remplacer complètement le travail d’un ingénieur du son. Néanmoins, l’IA intégrée dans ce plug-in de mixage assisté apporte un certain nombre d’avantages: Tout d’abord, à défaut de résultats pertinents, beaucoup d’utilisateurs reconnaissent que « l’assistant intelligent » fournit au moins un bon point de départ . On est ensuite libre de modifier légèrement à notre goût tel ou tel paramètre. Pour un utilisateur novice en mixage, c’est une aubaine de pouvoir profiter d’un exemple de traitement et ainsi ne pas partir de zéro. Une autre fonction efficace est le bouton « Masking » .',\n",
       "    'score': 17.576962},\n",
       "   {'chunk_id': '813dc16d-9',\n",
       "    'chunk_text': 'Malgré les calculs complexes en temps réel sous le capot, Smart:Comp est conçu pour ressembler et fonctionner comme un compresseur mono-bande standard. On peut tout à fait prendre le contrôle manuel du compresseur avec des commandes familières sur l\\'interface. Un mode « spectral ducking » automatique détecte les zones de fréquences en conflit pour les atténuer dynamiquement. La Smart:Reverb promet une approche différente: au lieu de chercher un preset, le moteur intelligent « écoute » votre son, puis crée une reverb sur mesure, sans résonance désagréable ou queue de reverb envahissante. On peut alors ajuster la couleur sonore entre 4 propriétés explicites (naturelle, artificielle, intime ou riche). Sonible ouvre la voie des plug-ins à intelligence artificielle, plus seulement dans les EQ, mais également dans les compresseurs et les reverbs. Comme iZotope, Sonible continue d’innover puisque, dans sa dernière version, le Smart:EQ 3 se présente comme « le premier égaliseur multi-piste au monde » . Avec la vue de groupe, vous pouvez organiser les pistes analysées dans une hiérarchie à trois niveaux pour décider lesquelles se démarqueront au premier plan et lesquelles joueront un rôle de soutien. Par exemple, vous pouvez placer les voix au sommet de la hiérarchie, ce qui est facilement réalisé à l\\'aide de la fonction glisser-déposer. En analysant les informations spectrales de toutes les pistes (jusqu’à 6) que vous avez ajoutés à votre groupe, les algorithmes s’assurent que chaque piste obtient son espace assigné dans votre mixage. Il vous suffit de déterminer la hiérarchie sonore en fonction de votre vision. Un paramètre \"Dynamic\" dans le filtre intelligent de Smart:EQ 3 permet au filtre de s\\'adapter dynamiquement au matériel source entrant.',\n",
       "    'score': 15.632147}],\n",
       "  'overall_score': 17.576962},\n",
       " {'article_id': 'c5c2d81d',\n",
       "  'title': 'Ecouter les sons du quotidien pour améliorer vos productions',\n",
       "  'category': 'LE SOUND DESIGN',\n",
       "  'tags': 'écoute analytique, podcast, riser',\n",
       "  'chunks': [{'chunk_id': 'c5c2d81d-1',\n",
       "    'chunk_text': \"Voici le premier épisode du podcast Arsonor! Je t ‘y explique notamment: l’importance de savoir écouter les subtilités du son pour améliorer tes compétences en sound design et mixage audio. en quoi consiste l’écoute analytique/active et les bonnes questions qu’il faut se poser quand on écoute une musique. la relation entre ces questions et le processing audio pour retranscrire au mieux nos intentions de production, le tout avec un exemple concret. Pour écouter cet épisode, lance tout simplement le lecteur ci-dessus. Tu peux aussi accéder à la page officielle du podcast . Et bien sûr le télécharger en qualité audio optimale par le lien suivant . Contenu de l'épisode #1: Pour ceux qui tomberaient ici par hasard, ce blog parle de création et de production musicale, de A à Z depuis son home-studio, et plus particulièrement « in the box », c’est-à-dire tous les processing directement dans son ordinateur. C’est un gros programme tout ça, qui exige beaucoup de savoir-faire, d’expérience engrangée jour après jour, voire année après année. On en apprend tous les jours! Il faut se mettre à la fois dans la peau d’un compositeur et d’un ingénieur du son . C’est ce que j’appelle le producteur moderne , qui fait tout depuis chez lui. De l’idée du morceau jusqu’à sa diffusion. Alors, l’une des clés de l’apprentissage, ça va être d’ apprendre à écouter les sons . Cela a l’air trivial dis comme ça, mais en fait, quand par exemple tu écoutes de la musique, tu ne fais pas que ça. Tu ne l’écoutes pas forcément de manière très attentive, à faire attention jusqu’aux moindres détails. Mais si tu veux devenir producteur musical, l’un des savoir-faire les plus importants, c’est de savoir écouter les sons, se concentrer uniquement sur le son, pour ce qu’il est.\",\n",
       "    'score': 17.52722},\n",
       "   {'chunk_id': 'c5c2d81d-10',\n",
       "    'chunk_text': 'On entend mieux les sons à la fin. Application en contexte musical sur le \"Riser\" Maintenant je vais te montrer ce que cela donne sur un exemple plus musical. Il me suffit alors de remplacer le son de voiture par mon bruit blanc, le riser écouté tout à l’heure (ils font la même longueur). Du coup, en appliquant exactement tous les traitements précédents, mais cette fois ci sur ce riser à la place du bruit de voiture, voilà ce que cela donne: {SON} Ecoute la différence lorsque je bypass les traitements (désactivation): {SON} Et en activant les traitements, {SON} , le son devient déjà bien plus intéressant, il commence bas et lent, devient plus grand et plus proche, jusqu’à occuper tout l’espace des haut-parleurs. Ecoutons maintenant en contexte avec un rythme House: Sans les effets: {SON} .Et Avec: {SON} En mettant toutes ces considérations en pratique, je t’ai montré à quel point ces techniques peuvent grandement améliorer un son. Bon il existe beaucoup d’autres techniques de production et je pourrais encore largement améliorer tout ça, mais c’est pas le sujet de cet épisode aujourd’hui! Conclusion de l\\'épisode S’l y a une chose à retenir de cet épisode, l’équipement le plus important, c’est tes oreilles. Prends-en soin. N’oublie pas d’écouter. Toujours. Écoute le monde, écoute le film, écoute ton interlocuteur. Mais toujours dans cette perspective analytique du son et de ses propriétés physiques. Meilleur tu es dans l’écoute, meilleur tu seras en tant que producteur musical. Je te remercie d’avoir pris le temps d’écouter cet épisode de bienvenue. N’hésites pas à commenter et à partager ce podcast si cela t’a plu. De me dire ce que tu penses de ce nouveau format par exemple. Ce n’est que le début d’une longue série à venir.',\n",
       "    'score': 10.760814}],\n",
       "  'overall_score': 17.52722},\n",
       " {'article_id': '1c97180b',\n",
       "  'title': 'Comment gérer l’équilibre dynamique de la musique?',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'arrangement, automation de volume, macro-dynamique, micro-dynamique, mise à plat, niveau absolu, niveau relatif, podcast',\n",
       "  'chunks': [{'chunk_id': '1c97180b-5',\n",
       "    'chunk_text': 'En effet, ça dépend toujours des styles musicaux mais bon dans la grande majorité des cas, un morceau va évoluer à travers différentes sections (Couplet, refrains, intro, etc…). Donc là on touche à l’art de l’arrangement, en terme de niveaux des différents instruments, c’est-à-dire, arriver à obtenir un savant dosage entre deux aspects: d’une part une préservation de la dynamique générale du morceau, où de trop grandes variations de volume entre les sections ne sont pas souhaitables. et en même temps, il faut bien créer quelques variations de niveau sonore au cours du morceau pour éviter de tomber dans la monotonie et au contraire susciter l’intérêt et refléter fidèlement l’intensité du morceau. Par exemple, l’arrangement de nombreuses productions signifiera des passages plus calmes pendant le couplet et plus fort pendant le refrain. Ou encore, au fur et à mesure qu’un morceau progresse, l’importance de divers instruments peut changer; comme dans le cas d’un solo de guitare qui devient plus fort à ce moment-là. Sans aucune action de notre part sur les niveaux, le niveau de mixage global peut avoir des sauts de volume assez surprenants. Si je prends cet exemple d’un morceau de K’s Choice: {MUSIC} C’est un exemple de la façon dont une absence d’un tel équilibre peut perturber puisque le morceau explose juste après l’intro et la montée de niveau peut facilement te faire sauter de ton siège. Un autre exemple avec Nirvana et ce morceau que j’ai pas besoin de te présenter: {MUSIC} On a là aussi une intro avec un seul élément, la guitare, avant l’explosion avec les guitares saturées et la batterie.',\n",
       "    'score': 17.1088},\n",
       "   {'chunk_id': '1c97180b-7',\n",
       "    'chunk_text': \"En effet, plus un instrument est fort, plus on l’entendra mieux, donc plus il sera défini. Mais attention à ce genre de procédé car on augmente aussi les risques de masquage. Cela veut dire que le fait d’élever le niveau d’un instrument spécifique peut entraîner une perte de définition pour un autre. Par exemple ici, si j’augmente la musique de fond par rapport à ma voix {SON} On va très vite se retrouver avec ma voix beaucoup moins intelligible! Pour un morceau de musique, c’est pareil. Il est souvent préférable d’ajuster par diminution plutôt que par augmentation du volume. La définition d’un instrument est aussi une affaire de réglage de volume sur des bandes de fréquences spécifiques, donc en utilisant un EQ. Par exemple, en augmentant le gain d’un instrument présentant des déficiences à certaines fréquences, il sera juste plus fort mais toujours autant mal défini. Il existe beaucoup de stratégies en mixage, pas toujours celles qui viennent en premier, pour faire ressortir un élément sans forcément augmenter son volume. Procédés d'ajustement des niveaux pour l'équilibre dynamique Quels sont alors les procédés qui vont nous permettre d’ajuster les niveaux pour avoir le meilleur équilibre dynamique possible tout le long du morceau? 1) Lors de la performance De nombreux instruments acoustiques ont une grande variété de possibilités expressives. Et l’instrumentiste a généralement de nombreuses façons de faire pour que le son de l’instrument soit subtilement modifié tout au long d’une performance. Si on considère le jeu du musicien à l’enregistrement , il se fera tout en nuance pour obtenir cette plage dynamique naturelle . Par exemple, lors du refrain, il joue plus dur et fort alors que pour un couplet ou une section d’ambiance, le jeu sera plus doux.\",\n",
       "    'score': 16.05302}],\n",
       "  'overall_score': 17.1088},\n",
       " {'article_id': 'c3b2f68e',\n",
       "  'title': 'Principes de fonctionnement d’un synthétiseur (7): Contrôles de modulation',\n",
       "  'category': 'LE SOUND DESIGN',\n",
       "  'tags': 'aftertouch, arpeggiateur, enveloppe ADSR, key track, LFO, macro, matrice de modulations, Midi CC, modwheel, pitch bend, vélocité',\n",
       "  'chunks': [{'chunk_id': 'c3b2f68e-2',\n",
       "    'chunk_text': 'On y retrouve la PWM (Pulse Width Modulation), la fonction SYNC ou encore la modulation en anneau (Ring Modulation) ou de phase. 2) Les sections Enveloppe et LFO Ensuite, dans une section séparée du reste, on retrouve les contrôles dédiés aux enveloppes et au LFO. Voir là aussi les articles consacrés à chacun d’eux: Enveloppe , LFO . Par exemple, il est indispensable d’affecter une enveloppe au volume de sortie pour indiquer comment le son doit se comporter en volume à chaque note jouée. Quant au LFO, il fait varier le son de manière cyclique tant qu’on laisse la touche enfoncée (ou la même note jouée). 3) Les contrôles MIDI de la note jouée Cette fois je n’en ai pas encore parlé. Il s’agit de tous les contrôles MIDI, c’est-à-dire liés à l’information MIDI (ou si tu veux, informatique à base de 0 et de 1) de la note jouée. Je n’entrerai pas ici dans les détails du MIDI. Mais saches simplement qu’il s’agit d’un protocole commun à tous les synthétiseurs ou tout autre instrument capable de recevoir des informations MIDI pour en ressortir un signal audio (comme les effets MIDI dans ta DAW). Ces informations qui vont influer le son ont pour origine les actions diverses suivantes: le type de pression exercée sur la touche du clavier; l’enchaînement des notes jouées sur le clavier (donc à des hauteurs différentes); un contrôle manuel additionnel à la note jouée; la création de combinaisons de notes. 3-a) Types de pression exercée sur la touche Le paramètre incontournable lié aux pressions sur les touches est la vélocité . En général, tout contrôleur clavier est sensible à la vélocité. Une autre fonction est l’ aftertouch , mais beaucoup plus optionnel (bien vérifier sur ton clavier s’il est sensible à l’aftertouch).',\n",
       "    'score': 15.158926},\n",
       "   {'chunk_id': 'c3b2f68e-4',\n",
       "    'chunk_text': 'Si elle ne l’est pas, le pitch de l’échantillon reste constant quelque soit la note enclenchée sur le clavier. C’est pourquoi tu peux trouver parfois cette fonction sous la dénomination « Key Follow » (Suivi de clavier) . Section de contrôle du Key Track sur Massive: son comportement est linéaire par défaut. Attention: Le Key tracking est en fait un cas particulier de la fonction KEY assignée au pitch de l’oscillateur. Mais dans un synthétiseur, le modulateur KEY sert plutôt à d’autres paramètres comme par exemple le volume (qui va alors augmenter avec des notes plus aiguës) ou la fréquence du filtre (cohérence dans la brillance des notes). Imagines que tu es en train de créer un son avec un filtre Low Pass et le cut-off réglé à une certaine fréquence, disons 600Hz. Si tu joues des notes graves (< 600 Hz), pas de problèmes. Mais plus les notes jouées sont aiguës, plus elles sont filtrées, et par la même perdent leurs harmoniques supérieures. Si tu as bien lu l’article à propos du timbre , tu sais que si on coupe certaines harmoniques d’un son, celui-ci voit son timbre (sa sonorité) modifiée. Le modulateur KEY (quand il est assigné à la fréquence du filtre) permet donc de garder une cohérence dans le timbre des notes jouées, quelque soit leur position sur le clavier et ce malgré la présence d’un filtre. En d’autres mots, toutes les notes auront le même nombre d’harmoniques quelque soit l’octave joué. > Portamento/Glide (ou glissando) J’en ai parlé brièvement dans l’article sur les voies de polyphonie . C’est un réglage du comportement sonore dans les transitions de note à note. Tu trouveras très souvent cette fonction dans une section séparée, proche des réglages de voies de polyphonie.',\n",
       "    'score': 14.884902}],\n",
       "  'overall_score': 15.158926},\n",
       " {'article_id': 'f0da0852',\n",
       "  'title': '10 logiciels incontournables pour le sound design',\n",
       "  'category': 'LE SOUND DESIGN',\n",
       "  'tags': 'plugin, sound design',\n",
       "  'chunks': [{'chunk_id': 'f0da0852-1',\n",
       "    'chunk_text': 'Le design sonore (ou plus communément appelé sound design ) est un terme un peu passe-partout employé à toutes les sauces. A partir du moment où mon métier consiste à transformer des sons enregistrés ou à en créer de nouveaux de manière synthétique, je suis un designer sonore. Cela se pratique depuis toujours dans le son à l’image et plus récemment dans toute production musicale moderne. D’ailleurs la frontière entre sound design et composition musicale s’est considérablement rétrécie. Musique ou sound design? En effet, si je conçois un son simulant un impact de balle dans une planche de bois, on appellera cela communément du sound design. Et si j’utilise ce même son pour rendre une caisse claire plus percutante, je deviens un producteur musical. Une fois accepté que tout son peut être vu comme possible entité musicale, c’est une démarche naturelle d’utiliser des outils de sound design dans le processus de production. Ces dernières années, les outils numériques de traitement du son ont incroyablement évolués et continuent d’évoluer sans cesse. Si bien qu’ils représentent aujourd’hui les moyens incontournables pour recréer des sons originaux ou leur redonner vie. Pourquoi pas travailler sur une hybridation de son analogique et numérique? Travailler avec des bruits plutôt que des notes? Et pourquoi pas essayer de rendre organique un son ne provenant d’aucune source physique?',\n",
       "    'score': 14.794561},\n",
       "   {'chunk_id': 'f0da0852-11',\n",
       "    'chunk_text': 'Tu utilises leurs algorithmes associés dans toutes les sources audio sans t’en rendre compte (pour la synchronisation du son à l’image à la moindre application audio d’aujourd’hui en passant par l’art du DJing bien entendu). Du côté des studios musicaux, cela a permis de révolutionner le travail (en bien ou en mal) jusqu’à être capable de faire passer n’importe qui chantant comme une casserole à un ténor d’opéra prestigieux (j’exagère à peine). L’outil magique permettant de faire cela c’est l ’autotune , nom originaire du produit phare de chez Antares . Mais depuis peu un autre concurrent sérieux s’est mis sur ce marché; je veux bien sûr parler de Celemony avec son Melodyne . Tous les studios musicaux professionnels du monde entier ont dans leur arsenal au moins l’un ou l’autre (si ce n’est pas les deux). Mais alors qu’est-ce qui fait que je parle de Melodyne dans cet liste d’outils pour le sound design? Contrairement à l’Autotune d’Antares, Melodyne ne fait pas de correction de pitch en temps réel (pendant que le chanteur chante) mais s’utilise en post-production. En revanche, son concept et ses algorithmes sont révolutionnaires. Son concepteur, un luthier et mathématicien allemand de génie , a imaginé la transposition visuelle de l’audio (habituellement sous forme d’onde sonore) note par note, chacune représentée par une forme de “goutte” . Là où jusqu’à maintenant on se contentait de manipuler l’onde sonore, avec Melodyne, on plonge littéralement à l’intérieur du son ! La correction de note en tonalité ou en durée devient un jeu d’enfant. De plus, son éditeur de son (dans la version complète du logiciel) ouvre la voie à des possibilités extraordinaires. Demo: N’hésites surtout pas à parcourir le site officiel car on y retrouve des tutos également disponibles en français (ce qui est très rare)!',\n",
       "    'score': 11.1073065}],\n",
       "  'overall_score': 14.794561},\n",
       " {'article_id': '4615db39',\n",
       "  'title': 'L’intelligence artificielle (IA) dans le studio de production audio (6/6)',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'collaboration IA, intelligence artificielle, producteur audio, production musicale',\n",
       "  'chunks': [{'chunk_id': '4615db39-1',\n",
       "    'chunk_text': 'Suite et fin du tour d’horizon des logiciels et plug-ins IA dans la post-production audio et leur impact sur l’activité de ce secteur. Quel est l’impact de l’IA à venir dans la post-production audio et musicale? Les nouveaux outils et plug-ins audio sur le marché montrent clairement cette tendance: des interfaces épurées pour une utilisation simplifiée à l’extrême, et en même temps une capacité à résoudre efficacement des « problèmes » audio complexes. Ainsi, tout un chacun est de plus en plus capable d’obtenir un résultat audio professionnel sans avoir forcément fait d’études en ingénierie du son ou même sans une énorme expérience. En fait, cette tendance ne date pas d’hier. L’ère du home-studio , du « Do It Yourself » et des outils audio pro démocratisés au plus grand nombre d’amateurs en herbe a fait son chemin. La technologie IA ne fait qu’accélérer le processus. Les effets actuels de l’IA dans le secteur de la post-production audio On peut y distinguer deux points de vue: – celui du créatif/artiste plus ou moins amateur, cherchant une certaine autonomie dans son travail jusqu’à la sortie finale de ses oeuvres; – celui du professionnel du secteur, producteur ou ingénieur mixeur/mastering , au service de ces mêmes artistes. Une aubaine pour les artistes et créateurs Vous êtes musicien, chanteur, compositeur ou beatmaker? Dans ce cas, les prochaines évolutions IA sont de véritables opportunités pour vous, si vous êtes ambitieux! Avec ces nouveaux outils d’assistance IA en post-production, vous pouvez résoudre les problèmes de base de vos enregistrements et mixages en toute autonomie. Même un débutant peut rapidement démarrer et améliorer facilement ses prods grâce à des outils d’assistance automatique en composition et sound design . Ces derniers (dont je n’ai pas parlé dans cette série d’articles) sortent régulièrement sur le marché.',\n",
       "    'score': 14.498567},\n",
       "   {'chunk_id': '4615db39-2',\n",
       "    'chunk_text': 'Avec ces nouveaux outils d’assistance IA en post-production, vous pouvez résoudre les problèmes de base de vos enregistrements et mixages en toute autonomie. Même un débutant peut rapidement démarrer et améliorer facilement ses prods grâce à des outils d’assistance automatique en composition et sound design . Ces derniers (dont je n’ai pas parlé dans cette série d’articles) sortent régulièrement sur le marché. C’est comme mettre vos productions ou mix entre les mains d’un bon ingénieur du son ultra-rapide : il prendra en charge les techniques et les tâches répétitives chronophages pour sortir quelque chose de propre. Néanmoins, cela n’exonère pas d’avoir un minimum de compétences dans les process audio et le sound design. Ne serait-ce que pour communiquer précisément vos attentes avec un professionnel. Je conseille donc de ne pas trop considérer ces outils comme magique . Vous ferez un grand pas dans votre autonomie en restant toujours une personne bien informée. Le secteur professionnel entre incertitude et mutation constante Si vous êtes un professionnel, vous vous posez forcément des questions sur l’avenir dans ce secteur. Oui les métiers du studio de production ne sont plus les mêmes qu’il y a 10 ou 20 ans… et ne seront plus les mêmes qu’aujourd’hui dans 10 ans! Il n’y a pas d’autre choix que d’ embrasser le changement et renouveler sans cesse son offre de service . Cela peut se matérialiser en une collaboration encore plus étroite avec les artistes, voire même comme un véritable partenaire créatif. Mais aussi, comme on l’a vu avec le projet Cloudbounce , la collaboration avec l’IA elle-même aidera à son propre développement. Bien sûr, les ingénieurs du son aiment pouvoir contrôler totalement les sons avec lesquels ils travaillent.',\n",
       "    'score': 10.823139}],\n",
       "  'overall_score': 14.498567},\n",
       " {'article_id': '2da6d6a5',\n",
       "  'title': 'L’intelligence artificielle (IA) dans le studio de production audio (3/6)',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'algorithme FFT, dynamic spectral equalizer, plug-in audio',\n",
       "  'chunks': [{'chunk_id': '2da6d6a5-8',\n",
       "    'chunk_text': \"DSEQ (« Dynamic Spectral EQualizer ») supprime la « harshness » numérique et équilibre un mixage à la volée grâce à des bandes de fréquences auto-ajustables. 3) Remédier au masquage En ce qui concerne les problèmes de masquage et de définition des éléments, on a souvent recours aux techniques classiques de side-chain . LE plugin qui fit grand bruit à sa sortie pour palier à ce genre de problème est le Trackspacer de Wavesfactory . Ce plugin ultra-simple en apparence est tout sauf ordinaire. Il intègre un EQ interne à 32 bandes qui réagit au signal d’entrée du sidechain . Il analyse le spectre du sidechain et applique une courbe d’égalisation inversée. Cela crée instantanément de l’espace pour la piste principale, procédé similaire à ce que ferait un compresseur multibande en sidechain mais de manière beaucoup plus puissante, transparente et précise. Trackspacer crée de l'espace dans un mixage en découpant les fréquences dont une piste a besoin en temps réel. Il applique une courbe d'égalisation inverse après avoir analysé le signal du sidechain. Il est désormais possible d’obtenir des mixages plus propres en tournant un seul bouton! MSpectralDynamics de Melda productions est essentiellement un processeur de dynamique qui fonctionne dans le domaine spectral et permettant de travailler avec des fréquences individuelles. Le processing en Side-Chain en fait une alternative au Trackspacer ou au DSEQ. Le SurferEQ de Sound Radix est intéressant à plus d’un point. Il détecte automatiquement la fondamentale de la note jouée ainsi que ses harmoniques successives. En plus des filtres High-Pass, Low-Pass, Shelf et Bell, un filtre harmonique unique à quatre modes permet de contrôler toute la série harmonique d’un instrument en utilisant une seule bande d’égalisation. Il en résulte un traitement des fréquences et du masquage entre instruments beaucoup plus efficace et musical.\",\n",
       "    'score': 13.691567},\n",
       "   {'chunk_id': '2da6d6a5-11',\n",
       "    'chunk_text': \"Unfilter peut également appliquer une réponse de filtre détectée d’un autre signal ou l'exporter en tant que réponse impulsionnelle! De plus, ces plug-ins sont très efficaces sur des enregistrements qui n’ont pas été effectués dans des conditions optimales. Ils se rapprochent en cela des capacités des logiciels dits de nettoyage et réparation audio. Je parlerai de ce type particulier d’outil dans un prochain article . Je rajouterai que certains de ces plug-ins possèdent également tous les attributs modernes et capacité de filtres d’un EQ traditionnel. Il est alors possible de tout aussi bien les utiliser de manière créative. Par exemple, pour Unfilter, la capacité de remodeler complètement le contour spectral d’un signal, d’extraire la réponse du filtre d’un son et de l’appliquer à un fichier différent, et de mettre en solo les composants bruyants contenus dans un son en fait un excellent outil pour concevoir de nouveaux sons. L’EQ traditionnel est-il en passe d’être ringardisé? Il est étonnant de penser que, il n’y a pas si longtemps, la possibilité d’automatiser les niveaux des faders et les cut sur une table de mixage matérielle représentait une technologie de pointe. L’arrivée des DAW et des plug-ins audio a changé bien des choses. Mais jusqu’à encore très récemment, toute cette flexibilité n’accélérait ou n’améliorait pas nécessairement le processus de production. Ces plugins qui se font appeler « dynamic resonance suppressor », ou encore « dynamic spectral equalizer », franchissent un nouveau palier dans cette optique. Ils sont devenus en quelques mois des « must-have » pour corriger des problèmes techniques ou lisser agréablement le son global. Néanmoins, jusqu’à preuve du contraire, ces outils ne sont pas encore capables de mixer nos pistes pour nous. Des EQ ou compresseurs plus classiques ne sont donc pas à mettre aux oubliettes (du moins pas encore).\",\n",
       "    'score': 12.231892}],\n",
       "  'overall_score': 13.691567},\n",
       " {'article_id': '56324d1b',\n",
       "  'title': 'L’effet de delay avec 3 grands classiques à (re)créer',\n",
       "  'category': 'LE SOUND DESIGN',\n",
       "  'tags': 'delay, dotted eighth note, dub, podcast, slapback',\n",
       "  'chunks': [{'chunk_id': '56324d1b-3',\n",
       "    'chunk_text': 'Ainsi, en live, on mettait un micro supplémentaire à côté, relié à un enregistreur pour créer un écho mixé presque aussi fort que la piste vocale elle-même. Cet effet classique du rock ‘n’ roll/rockabilly est devenu une marque de fabrique du producteur de Sun Records, Sam Phillips. Utilisé par exemple sur les guitares de Scotty Moore et la voix d’Elvis bien sûr, dont on peut entendre un extrait. En pratique Alors pour reproduire cet effet chez vous, rien de plus simple avec n’importe quel plugin de delay à votre disposition 1) Réglage du temps: Slapback doit être rapide, donc vos temps de delay seront courts – entre 70 et 150 millisecondes. 2) Pas de feedback De plus, vous devrez limiter vos répétitions à une seule, sinon vous vous retrouverez avec un son étendu avec trop de chevauchement. Ajustez le contrôle de répétition (le feedback) jusqu’à ce que vous n’entendiez qu’un seul écho 3) Dry/Wet puis équilibrez le niveau de votre son retardé et de votre signal d’origine (dry/wet) afin qu’ils soient assez homogène en volume. Si je met 100% wet je n’entends que la répétition. Utiliser un plugin de delay de simulation analogique ou à bande Mais si vous voulez garder le côté vintage caractéristique des vieux enregistrements, il est préférable d’utiliser un délai à bande ou un délai analogique. Heureusement, avec nos DAW et plugins d’aujourd’hui, c’est un peu plus facile que de se procurer la légendaire Roland Space Echo. Vous pouvez trouver en description quelques références de bons plugins de délai à simulation de bande. Sinon c’est pas très compliqué à reproduire avec un peu de traitement des répétitions en les filtrant et les saturant légèrement.',\n",
       "    'score': 10.036364},\n",
       "   {'chunk_id': '56324d1b-7',\n",
       "    'chunk_text': 'On peut écouter l’effet dans un autre contexte Là je l’applique sur le son de saxophone Là sur le piano Voilà, cela se passe de commentaire sur l’effet apporté en terme de rythmique et de stéréo. Le Dub delay Enfin parlons du delay Dub qui a été inventé pour le style de musique dont il porte le nom, le Dub. Le Dub Delay est un effet quelque peu complexe, composé généralement de plusieurs effets enchaînés pour donner ce son caractéristique, mais il existe quelques paramètres de base communs qui peuvent vous rapprocher de l’effet voulu. La musique Dub a ses racines dans la culture sound system de la Jamaïque à la fin des années 60 et 70. La plupart des artistes dub pionniers utilisaient une console analogique comme un véritable instrument. Le Grand standard de l’époque pour les effets de delay dub et reggae est le delay à bande Roland Space Echo. Pour engendrer les répétitions, on augmente le paramètre de feedback dans nos plugins numériques. Sauf qu’à l’époque on le faisait manuellement sur la console, en ré-injectant la sortie du delay dans sa propre entrée. Généralement, à mesure que le delay est ré-injecté dans son entrée, les répétitions sonnent de plus en plus distordues. C’est différent d’un simple feedback sur un plugin de delay. C’est un effet classique que vous avez sans doute entendu d’innombrables fois. La plupart des effets modernes de type dub delay ont aussi des filtres ou d’autres effets de modulation dans le chemin du feedback pour rendre les choses plus « distantes » et variables à chaque répétition. En pratique Il y a plusieurs manières de faire pour le mettre en pratique chez vous. Le routing choisi du signal audio sera particulièrement décisif dans le rendu du son final.',\n",
       "    'score': 9.720787}],\n",
       "  'overall_score': 10.036364},\n",
       " {'article_id': '7cec1065',\n",
       "  'title': 'Tour d’horizon et fonctionnement des processeurs de dynamique',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'compresseur, downward, ducker, dynamique, expandeur, fonction de transfert, gate, limiteur, non-linéarité, ratio, seuil, side-chain, threshold, upward',\n",
       "  'chunks': [{'chunk_id': '7cec1065-1',\n",
       "    'chunk_text': 'Compresseur, Expandeur, Limiteur, Gate ou encore Ducker ont tous en commun de faire parti de la même famille des processeurs de dynamique . Mais qu’ont-ils en commun et qu’est-ce qui les différencie? Voici donc un tour d’horizon de ces outils particulièrement prisés, autant dans la création sonore que dans le processing en post-production musicale (mixage et mastering). Modifier la plage dynamique Pour bien comprendre l’intérêt de ces outils, il est nécessaire de rappeler ce qu’est la dynamique du son. Je te renvois pour cela à la série d’articles concernant la gestion des niveaux sonores , ainsi que l’article précédent sur l’équilibre dynamique dans la musique . Rappel sur la plage dynamique Reprenons l’exemple d’un morceau orchestral de musique classique . Ce type de musique est très dynamique : du plus faible coup sur un triangle à 10 dBSPL jusqu’au moment où l’orchestre entier joue à son plus fort, admettons à 100 dBSPL, on se retrouve avec une dynamique de 90 dB! Les moyens d’aujourd’hui permettent sans problèmes d’enregistrer et post-produire une musique avec une telle dynamique. Mais que se passe t’il si par exemple on veut graver le morceau sur un vinyle? Réduire la plage dynamique On a vu que le vinyle est un support avec une plage dynamique de 60 dB . Comment contenir 90 dB de dynamique sur un support de 30 dB de moins sans sacrifier les niveaux les plus faibles ou les niveaux les plus forts de la performance? La solution est donc de réduire cette plage dynamique , soit en atténuant les niveaux les plus forts, soit en augmentant les niveaux les plus faibles. Le compresseur était né! Sa première utilisation fut donc de pouvoir adapter la musique à une plage dynamique réduite des supports analogiques de l’époque (bandes analogiques, vinyle, …).',\n",
       "    'score': 9.722772},\n",
       "   {'chunk_id': '7cec1065-4',\n",
       "    'chunk_text': \"Mais il faut bien noter qu’ un « vrai » limiteur n’est pas un compresseur car sa conception doit être adaptée à la détection du moindre pic (transitoire) du signal audio. Un mot sur le 'gate' et le 'ducker' Quant au ‘Gate’ (ou Porte en français, mais personne ne dit ça! ), il est un peu à l’expandeur ce que le limiteur est au compresseur . C’est-à-dire qu’il atténue aussi les niveaux faibles, mais d’une manière fixe et pas suivant un ratio (voir ci-après pour la définition du ratio). Et une atténuation drastique permet de rendre inaudible les niveaux faibles. Enfin, le ‘ducker’ réduit aussi les niveaux d’un certain montant fixe, mais pour des niveaux trop forts. Contrôler les dynamiques du signal En fait, à part au mastering, manipuler la plage dynamique n’a que peu d’intérêt dans le processus de production musicale (partant de l’hypothèse qu’on travaille « in the box » et que la plage dynamique n’est pas un problème ). En revanche, ce qu’il est primordial de maîtriser sont les variations dynamiques du signal audio. En cela, les processeurs de dynamique vont se révéler très utiles pour rendre le son plus ou moins fort, et ce aussi bien à un niveau macro-dynamique que micro-dynamique . Regardons de plus près leurs principes communs de fonctionnement. Schéma de base de fonctionnement des processeurs de dynamique Rappelle-toi de l’importance de l’automation en volume d’une piste vocale pour la rendre plus consistante en niveau. Tu es en train de dire, d’accord, si la voix s’élève trop, je l’abaisse; si la voix se calme, je l’augmente. Cela ressemble à un procédé qui pourrait bien être automatisé par un compresseur, non? C’est, en fait, tout ce que font ces processeurs de dynamique.\",\n",
       "    'score': 7.3266797}],\n",
       "  'overall_score': 9.722772},\n",
       " {'article_id': 'd1d36480',\n",
       "  'title': 'La gestion des niveaux sonores (10): Plugins de mesure LUFS',\n",
       "  'category': 'LE HOME STUDIO',\n",
       "  'tags': '\"Integrated\" LUFS, \"Short-term\" LUFS, facteur de crête, loudness, LRA, PLR, PSR',\n",
       "  'chunks': [{'chunk_id': 'd1d36480-8',\n",
       "    'chunk_text': 'Avec également une mesure True Peak à -1 dBTP. Et de plus, en suivant ces recommandations, dans les genres les plus populaires, le loudness « integrated » se situe souvent dans la plage LUFS de -11 à -14, soit le bon spot pour toutes les plateformes de streaming en ligne. Comment utiliser concrètement la mesure du LRA pour atteindre son objectif? Bien comprendre le LRA peut t’aider à régler certains volumes au mixage. Par exemple, si tu penses que le refrain ne ressort pas assez, et que ton LRA est plutôt faible, cela encourage à appliquer une automation en volume pour créer de plus grandes variations dynamiques. A l’inverse, si tu veux un morceau plutôt massif et constant en vibe, il faudra peut être s’employer à diminuer le LRA. En règle générale, un LRA supérieur à 5 LU est recommandé pour des morceaux tout en tension et relâchement, avec des refrains qui explosent par rapport au reste. Mais c’est une suggestion à prendre avec des pincettes. D’où la nécessité d’utiliser des morceaux de référence afin de mesurer leur LRA et ainsi se baser sur cette valeur cible pour son propre morceau. Exemples de plugins de mesure LUFS Voici une liste de différents plugins de mesure du loudness, conçus par des marques bien connues dans le traitement audio: NuGen Audio VisLM 2 TC Electronic LM1n, LM2n, LM6n iZotope Insight Mastering the Mix Levels Waves WLM Meter Plus RTW Loudness Tools HOFA 4U Suite Hindenburg Meter Klangfreund Meter Melda Production MLoudnessAnalyser N’hésites à inscrire en commentaire si tu connais une autre marque de plugin de mesures. Conclusion Pour conclure sur ces articles concernant les mesures du loudness, il faut bien comprendre qu’il s’agit avant tout d’une décision artistique. Cela ne doit pas se limiter à une histoire de chiffres!',\n",
       "    'score': 8.803167},\n",
       "   {'chunk_id': 'd1d36480-9',\n",
       "    'chunk_text': 'Exemples de plugins de mesure LUFS Voici une liste de différents plugins de mesure du loudness, conçus par des marques bien connues dans le traitement audio: NuGen Audio VisLM 2 TC Electronic LM1n, LM2n, LM6n iZotope Insight Mastering the Mix Levels Waves WLM Meter Plus RTW Loudness Tools HOFA 4U Suite Hindenburg Meter Klangfreund Meter Melda Production MLoudnessAnalyser N’hésites à inscrire en commentaire si tu connais une autre marque de plugin de mesures. Conclusion Pour conclure sur ces articles concernant les mesures du loudness, il faut bien comprendre qu’il s’agit avant tout d’une décision artistique. Cela ne doit pas se limiter à une histoire de chiffres! Et aucune autre propriété de la musique ne le devrait, bien sûr. Les chiffres sont utiles pour vérifier et entraîner nos oreilles. Mais cela ne signifie pas pour autant que tu dois choisir une correction d’égalisation ou le loudness d’un morceau uniquement à partir de mesures: dans un monde idéal, tu choisis simplement ce qui sonne le mieux. Et la bonne nouvelle est que nous nous dirigeons dans cette direction! Étant donné que les niveaux de loudness sont ajustés lors de la lecture, tu es libre de faire ton choix sur ce qui convient vraiment à ta musique, sans avoir à t’inquiéter si « l’autre » le fera plus fort…',\n",
       "    'score': 7.640507}],\n",
       "  'overall_score': 8.803167},\n",
       " {'article_id': 'dd1f7af9',\n",
       "  'title': 'Compression dynamique (1): La réduction de gain',\n",
       "  'category': 'LA POST-PROD',\n",
       "  'tags': 'dynamique, GR, loudness, quantité de compression, réduction de gain',\n",
       "  'chunks': [{'chunk_id': 'dd1f7af9-1',\n",
       "    'chunk_text': \"La fonction première d’un compresseur est bel et bien de réduire la dynamique du son (sauf dans un certain cas précis). On réduit la différence de niveaux entre les sons les plus forts et les plus faibles. Les conséquences directes sont une réduction de gain et une modification du volume subjectif perçu (le loudness). Par exemple, on peut facilement écouter l’effet de la compression sur des coups de caisse claire (snare): Coups de snare déséquilibrés en volume: https://arsonor.com/wp-content/uploads/2020/04/16-061-Snare-HH-Unbalanced.wav Coups de snare plus consistants après compression: https://arsonor.com/wp-content/uploads/2020/04/16-062-Snare-HH-Balanced.wav La compression réduit la dynamique* On ne peut donc pas parler de compression sans comprendre au préalable ce qu’est la dynamique du son et son importance dans la perception de la musique. Comprendre d'abord ce qu'est la dynamique du son Pour cela, je te renvoie à la série d’articles sur la gestion des niveaux sonores de (1) à (11) . J’y explique en détail l’importance et les enjeux de la dynamique dans la DAW et sur le son final. Cela constitue en quelque sorte une large introduction à l’utilisation de la compression dynamique du son pour la musique. Au-delà des avantages évidents à l’utilisation d’un compresseur (augmentation du volume perçu, plus de corps, de punch, etc…), on oublie trop souvent (surtout quand on débute) que sa fonction première est bel et bien de réduire la dynamique du son * . On aura donc une multitude d’intérêts à réduire la dynamique du son. Mais aussi (et surtout) des précautions à prendre quand on fait cela (voir les applications de la compression dynamique dans un article ultérieur). * NB: Il existe une exception à cela: lors d’une configuration du compresseur de manière à agir sur les transitoires pour accentuer leur attaque par rapport au « reste » du son.\",\n",
       "    'score': 8.758351},\n",
       "   {'chunk_id': 'dd1f7af9-6',\n",
       "    'chunk_text': 'Attention tout de même aux chiffres! Il est risqué de traduire les observations en chiffres, car ce qu’un compresseur considère comme fort, un autre peut le considérer comme modéré. On vient de voir que la quantité de compression est beaucoup plus complexe que la lecture de base de cette réduction de gain. De manière générale: – une compression de 8 dB sur le bus stéréo est considérée comme très forte; – pour les instruments, on considère une compression légère comme quelque chose de moins de 4 dB, une forte compression comme quelque chose de plus de 8 dB et une compression modérée entre les deux. Dans le post suivant, je parlerai plus en détails du paramètre essentiel de make-up gain en sortie de compresseur et les bonnes pratiques d’utilisation.',\n",
       "    'score': 5.101967}],\n",
       "  'overall_score': 8.758351}]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_with_diversity(query, category=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a90e3571-822d-457d-815a-38530f98c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're an audio engineer and sound designer instructor for beginners.\n",
      "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
      "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "Finally, recommend the top 3 Arsonor articles (refer to their 'title') that are the best to read for answering this question.\n",
      "\n",
      "QUESTION: De quel matériel ai-je besoin pour créer ma musique dans mon home-studio?\n",
      "\n",
      "CONTEXT:\n",
      "article title: Deviens toi aussi producteur musical depuis ton home studio\n",
      "article keywords: home-studio, ingénieur du son, MAO, production musicale\n",
      "content: Avis à tous les passionnés de musique, c’est avec grand plaisir que j’ouvre ce blog afin de partager ma passion de la MAO (Musique Assistée par Ordinateur) et du home studio , de la création au mixage audio. Alors tu te demandes sûrement… … Qu’est-ce que Arsonor? Contexte De nos jours, la musique est omniprésente. Les médias traditionnels (radio, télé) et surtout maintenant Internet et les réseaux sociaux nous font découvrir de nouveaux artistes tous les jours. Des sites comme Soundcloud ou Bandcamp sont absolument remplis de création de tout bords de façon continue. Quant à Youtube , c’est devenu la plus grande plateforme d’écoute de musique en ligne où il est devenu très facile d’écouter et de publier. Depuis quelques années, le monde de la création et de la production musicale s’est considérablement ouvert grâce à l’évolution ininterrompue et considérable de l’informatique, l’émergence d’internet à haut débit et le développement des échanges de fichier à grande échelle. Par le passé, les premiers home studio pouvaient ressembler à un véritable arsenal où s’enchevêtraient câbles, patchs et racks remplis de matériel, et le tout à un coût exorbitant! Aujourd’hui tout commence avec un simple ordinateur et un casque car le matériel a été remplacé par son équivalent logiciel. De plus en plus d’artistes émergent en composant chez eux, depuis leur home studio avant de finaliser leurs projets dans un studio professionnel (voire toujours depuis chez soi) . On parle alors de plus en plus de création DIY (“Do It Yourself”) et d’un nouveau rôle des amateurs qui sont en mesure de travailler avec des moyens équivalents aux professionnels.\n",
      "\n",
      "article title: Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?\n",
      "article keywords: apprentissage, Audio, composition, DAW, home-studio, MIDI, production musicale\n",
      "content: Si comme moi, tu as décidé un jour de produire et mixer ta propre musique, tu es forcément passé par l’étape d’apprentissage d’une DAW. Oui, ce que j’appelle DAW (« Digital Audio Workstation ») , c’est la station audio-numérique (donc STAN en français), soit Le logiciel audio au centre de toutes les opérations du home-studio. Pour ce premier article de l’année, il me tenait à cœur de revenir aux fondamentaux. A savoir, donner une vision plus claire à destination de tout débutant qui souhaite se lancer dans l’aventure. Car si tu es confronté de près ou de loin à la prise en main d’une DAW tout en ne sachant pas par quel bout commencer , alors cet article est fait pour toi! Je t’y donne des pistes qui m’ont personnellement permis de faire un bond en avant dans mon évolution. Cela tombe bien car cet article fait parti de l’événement inter-blogueurs “quand j’ai compris ça, j’ai fait un bond en avant dans mon évolution !” organisé par Cazimir Costea du blog Libérer Son Piano . Ce blog, dont j ’apprécie beaucoup les conseils et analyses de Cazimir, t’aide à libérer ton potentiel au piano (et tu verras dans la suite de cet article en quoi cela te serait utile). Pour bien comprendre la complexité d’une DAW, il faut d’abord revenir aux origines du home-studio: L'avènement du home-studio et son effet pervers L’apprentissage d’une DAW est donc l’étape incontournable de tout « home-studiste ». On retrouve même la DAW dans tout studio de production musicale professionnel actuel. Elle permet en effet à un seul ordinateur polyvalent d’émuler toutes les fonctions à la fois de routage, d’enregistrement, de traitement et de mixage de l’audio. Toutes ces fonctions étaient autrefois assurées par des unités matérielles ‘hardware’.\n",
      "\n",
      "article title: Comment bien débuter en MAO: le home-studio démystifié\n",
      "article keywords: DAW, hardware, home-studio, MAO, matériel audio, plugin, software\n",
      "content: La MAO (Musique Assistée par Ordinateur) est en vogue depuis l’ère du numérique. Un ordinateur peut devenir facilement un centre de production musicale et audiovisuelle. Si en plus c’est un portable, te voilà à la tête d’un studio d’enregistrement mobile! Il est néanmoins nécessaire de comprendre le cheminement du signal audio et les divers éléments constituant un véritable petit studio. Un ordinateur c’est déjà pas mal mais il ne reste qu’un support. Il faut ensuite les éléments qui vont permettre de faire rentrer l’audio si on veut enregistrer des sons extérieurs, les manipuler puis les ressortir pour finalement pouvoir écouter du mieux possible. Dans l’univers de la MAO, tu découvriras vite une jungle de matériels et de fabricants divers où il sera facile de s’y perdre ou de se décourager. Aussi, je n’aborderai pas ici le détail des marques, prix et caractéristiques de chaque élément, le but de l’article étant surtout de présenter un aperçu global de ce qui constitue un home-studio avant qu’on entre dans le vif du sujet. Le home studio, de l'audio professionnel à domicile Je sais que pour la plupart des novices cet univers de l’audio peut paraître effrayant, surtout à la vue de certains studios suréquipés ou à la lecture d’un article sur la dernière machine en vogue dans un journal spécialisé. C’est sûr tu trouveras toujours quelqu’un pour te montrer ses 50 synthétiseurs analogiques, ses 10 boîtes à rythmes, ses 3 ordinateurs et quelques interfaces audio multi-pistes avec leurs micros, le tout pour plus de 10000€. La vérité : Pour commencer, tu n’as besoin d’aucune machine autre qu’un simple ordinateur. L’autre vérité : Pour créer du grand art, tu n’as toujours pas besoin d’appareil en plus.\n",
      "\n",
      "article title: Comment bien débuter en MAO: le home-studio démystifié\n",
      "article keywords: DAW, hardware, home-studio, MAO, matériel audio, plugin, software\n",
      "content: C’est sûr tu trouveras toujours quelqu’un pour te montrer ses 50 synthétiseurs analogiques, ses 10 boîtes à rythmes, ses 3 ordinateurs et quelques interfaces audio multi-pistes avec leurs micros, le tout pour plus de 10000€. La vérité : Pour commencer, tu n’as besoin d’aucune machine autre qu’un simple ordinateur. L’autre vérité : Pour créer du grand art, tu n’as toujours pas besoin d’appareil en plus. I - Ce qu'il te faut dans ton home studio 1) L'ordinateur Oui celui que tu utilises en ce moment fera sûrement l’affaire. Outre l’éternel débat Mac ou PC, aujourd’hui, si ton ordinateur, quel qu’il soit, est relativement récent, tu ne devrais pas avoir trop de problèmes pour travailler de l’audio au départ. Voici tout de même quelques recommandations importantes : – S’assurer d’avoir un processeur rapide et fiable et une carte mère qui possède suffisamment de place pour y ajouter de la RAM (mémoire vive). Anticipes l’avenir, tes besoins iront crescendo au fur et à mesure que tu seras impliqué dans la musique numérique. – Suivant tes objectifs, il sera préférable de garder ton ordinateur uniquement pour la musique et donc de le configurer spécifiquement pour cela. Sois réaliste et vérifies si ta machine sera capable de supporter tous tes logiciels musicaux en plus d’autres applications que tu possèdes déjà. Attention avec les PC avec notamment l’antivirus qui prend beaucoup de ressources. Personnellement j’ai un macbook avec le strict minimum, par exemple aucun jeu ou autre application gourmande en énergie n’y est installée (à part tout ce qui est lié à la musique bien sûr).\n",
      "\n",
      "article title: Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?\n",
      "article keywords: apprentissage, Audio, composition, DAW, home-studio, MIDI, production musicale\n",
      "content: Un manager, un coach, d’autres musiciens, plusieurs ingénieurs du son à l’enregistrement, au mixage puis au mastering, etc… Les musiques électroniques pionnières du home-studio La réalité du home-studiste est qu’il fait généralement tout cela! C’est ce que j’appelle le producteur musical moderne: son rôle est polyvalent, de la proposition d’idées musicales à leur organisation, finalisation puis distribution. Ce rôle multi-casquettes et du DIY (« Do It Yourself », fais tout par toi-même) s’est d’ailleurs initialement développé avec l’avènement des musiques électroniques. Le travail énorme que représentait la production d’un morceau de house, techno, etc…, fut au début largement incompris par les médias de masse et les musiciens traditionnels. Ce sont tous ces producteurs qui ont pourtant contribué à l’émergence du home-studio et la démocratisation de la production musicale. Voir d’ailleurs cet excellent documentaire à ce sujet: Aujourd’hui, on ne compte plus toutes les productions à succès et hits commerciaux qui se sont conçus de A à Z dans une chambre à coucher ou une cave aménagée. Et ceci plus seulement pour des musiques électroniques mais pour tout autre style, du jazz au rock, en passant par le son à l’image et les musiques de film! Obstacles à l'apprentissage d'une DAW Alors rempli d’enthousiasme et de motivation, comme toute personne normale, tu vas sur Google pour savoir comment commencer et ce dont tu as besoin. Malheureusement, cela ne se passe pas comme prévu, tu finis par télécharger un programme obscur sans aucune idée de ce que c’est ni comment l’utiliser. La confusion s’installe… Et comme moi, tu t’es peut être aperçu rapidement à quel point le chemin allait être long et tortueux avant d’arriver à quelque chose de potable. Jusqu’à même se décourager et passer finalement à autre chose tellement la montagne que représente le vaste monde de l’audio-numérique semblait insurmontable.\n",
      "\n",
      "article title: Deviens toi aussi producteur musical depuis ton home studio\n",
      "article keywords: home-studio, ingénieur du son, MAO, production musicale\n",
      "content: De plus en plus d’artistes émergent en composant chez eux, depuis leur home studio avant de finaliser leurs projets dans un studio professionnel (voire toujours depuis chez soi) . On parle alors de plus en plus de création DIY (“Do It Yourself”) et d’un nouveau rôle des amateurs qui sont en mesure de travailler avec des moyens équivalents aux professionnels. Exemple de home studio à ses débuts plus minimaliste et actuel Souvent téléchargés de manière illégale, les développeurs de logiciels ont rapidement saisi le potentiel grand public de ces outils qui existaient pour la plupart depuis des années. Le logiciel Logic Pro d’Apple passe autour de 200 Euros en téléchargement direct (il coûtait près de 1000 Euros à l’origine). Et Ableton Live , un des logiciels les plus dynamiques du marché, se pare de nouvelles interfaces colorées et mise avant tout sur une plus grande accessibilité (pour 600 Euros la version complète). A côté de ces logiciels, un véritable écosystème se crée de lui-même: communauté et forums s’échangent des conseils et des “tips” pour mieux produire, tandis que des milliers de tutoriels pour débutant ou niveau plus avancé sont disponibles sur des plateformes de vidéos. Cette nouvelle ère du monde de la musique post-crise du disque remplace peu à peu notre rôle de simple auditeur à un rôle de créateur: avec l’accessibilité de la musique moderne, n’importe quel passionné de musique devient créateur! Développes l'artiste qui est en toi! Mais est-ce suffisant pour obtenir des résultats en home studio? Non! Encore faut-il acquérir les connaissances théoriques et pratiques du musicien/ingénieur du son. Pour cela, plusieurs obstacles viendront entraver ta route. En voici deux exemples: 1) Technologie VS Créativité En tant qu’artiste, tu te rendras compte que la créativité l’emporte toujours sur la technologie .\n",
      "\n",
      "article title: La gestion des niveaux sonores (9): Les normes de mesure du loudness\n",
      "article keywords: Calm Act, EBU R128, loudness normalization, loudness unit, loudness war, LUFS, streaming\n",
      "content: L’algorithme « Sound Check » d’Apple est également basé sur ce standard. le « K-system » conçu et proposé par le célèbre ingénieur en mastering Bob Katz pour normaliser le rapport entre dBFS et dBSPL. Cela se présente comme un système de calibration d’enceintes de studio combiné à une échelle spécifique de mesure des niveaux pour atteindre une plage dynamique satisfaisante. Le système proposé par Bob Katz consiste à calibrer ses enceintes de manière à ce que le 0 dB VU corresponde à 83 dB SPL. Et ceci suivant trois domaines d'application exigeant une plage dynamique différente: K-12 (Broadcast), K-14 (Pop music, home-studio) et K-20 (grands studios, musique classique). La norme EBU de mesure du loudness s'impose peu à peu... Ceci étant dit, à mon avis, il est inutile de s’embrouiller encore plus avec ce « système K » de Bob Katz. Je l’ai mentionné uniquement pour ton information et cas où tu tombes sur des plugins de mesure qui en font encore référence. Etant donné que de nombreux fabricants de plugins et de périphériques audio faisaient partie du groupe qui a rédigé la norme EBU, c’est donc le système LUFS qui finit par s’imposer, même aux Etats-Unis! On trouve de plus en plus de plugins « EBU-compliant », des gratuits jusqu’aux professionnels confirmés comme Izotope ou NuGen Audio (voir prochain article). Il semble en effet que le « système K » de Bob Katz tombe peu à peu en désuétude. Et c’est pas plus mal car le système LUFS a le mérite de donner une mesure universelle, commune à tout le monde, tout en se désolidarisant de la dualité entre valeur Peak et RMS. ... mais pour quelle valeur cible? A quoi correspond vraiment -23 LUFS recommandé par l'EBU?\n",
      "\n",
      "article title: Deviens toi aussi producteur musical depuis ton home studio\n",
      "article keywords: home-studio, ingénieur du son, MAO, production musicale\n",
      "content: Mais est-ce suffisant pour obtenir des résultats en home studio? Non! Encore faut-il acquérir les connaissances théoriques et pratiques du musicien/ingénieur du son. Pour cela, plusieurs obstacles viendront entraver ta route. En voici deux exemples: 1) Technologie VS Créativité En tant qu’artiste, tu te rendras compte que la créativité l’emporte toujours sur la technologie . Il est néanmoins important de comprendre la technologie et la science qui se cache derrière, de manière à produire de la musique innovante et de qualité. L’accès à la musique s’est certes démocratisé mais la technologie et l’apparente complexité des logiciels de création ont vite fait de décourager les amateurs en herbe. L’évolution est tellement rapide qu’on est arrivé à un point où l’artiste est submergé de tas d’outils à sa disposition, ce qui peut être un frein à sa créativité. Une bonne production musicale en ces temps est de surtout décider quoi ne pas utiliser, afin de rester concentrer et créatif dans nos propres limitations. 2) Musicien VS Ingénieur du son En donnant des cours particuliers en MAO, de plus en plus de musiciens me contactent parce qu’ils veulent produire et finaliser leur morceau eux-mêmes depuis chez eux. Pour cela, ils veulent donc être formé aux outils modernes de production en quelques cours sur un logiciel. Malheureusement, la réalité est toute autre. En général, ma réponse à ceci en décourage plus d’un. Il leur faut en effet réapprendre un nouveau langage, une nouvelle façon d’appréhender la musique d’une manière “moderne”. Et ce langage s’accompagne également d’une nouvelle paire d’oreille à acquérir. Il faut réapprendre à écouter d’une autre manière. Musique moderne? L’extrait qui suit résume bien le concept de Musique moderne.\n",
      "\n",
      "article title: Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?\n",
      "article keywords: apprentissage, Audio, composition, DAW, home-studio, MIDI, production musicale\n",
      "content: On retrouve même la DAW dans tout studio de production musicale professionnel actuel. Elle permet en effet à un seul ordinateur polyvalent d’émuler toutes les fonctions à la fois de routage, d’enregistrement, de traitement et de mixage de l’audio. Toutes ces fonctions étaient autrefois assurées par des unités matérielles ‘hardware’. La constante amélioration dans la fiabilité et les fonctionnalités des traitements numériques et du stockage des données informatiques au cours des 20 dernières années a permis à la DAW de largement les remplacer. Si nécessaire, la connexion au monde analogique intervient via une interface audio : un appareil comportant des prises d’entrée/sortie (E/S) audio et les convertisseurs du signal analogique vers numérique (ADC) et vice-versa (DAC). Tout cela conjugué aux prix en baisse, la production musicale est devenue beaucoup plus accessible . Une musique de qualité peut se créer sur un ordinateur portable standard, sans hardware coûteux. Vue de la DAW Protools sur lécran d'ordinateur Rôle(s) du producteur musical moderne Mais cette tendance vers une « simplification » des traitements audio a en même temps engendré un effet pervers: la polyvalence nécessaire dans les tâches à accomplir. Selon la définition traditionnelle, le producteur supervise, gère et guide le processus d’enregistrement et de production d’une chanson. Pour des productions de haut calibre (pense Top 40, musique commerciale…), on retrouve normalement un certains nombres de personnes à la production en plus de l’artiste et du producteur. Un manager, un coach, d’autres musiciens, plusieurs ingénieurs du son à l’enregistrement, au mixage puis au mastering, etc… Les musiques électroniques pionnières du home-studio La réalité du home-studiste est qu’il fait généralement tout cela! C’est ce que j’appelle le producteur musical moderne: son rôle est polyvalent, de la proposition d’idées musicales à leur organisation, finalisation puis distribution.\n",
      "\n",
      "article title: Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?\n",
      "article keywords: apprentissage, Audio, composition, DAW, home-studio, MIDI, production musicale\n",
      "content: Ce qui permet de produire entièrement dans un environnement logiciel. Dans la pratique, cependant, la plupart des studios occupent un juste milieu entre les extrêmes tout analogique et tout numérique. La mode est à l’hybride, combinant ancien et nouveau, matériel et logiciel, en fonction des priorités de production, des restrictions d’espace/budget et des préférences personnelles. Prise en main rapide d'un synthétiseur Dès qu’on a assimilé tous les concepts et le vocabulaire sous-jacents à la synthèse sonore, il est possible de rapidement prendre en main n’importe quel synthétiseur. Voir à ce propos ma série d’article sur les principes de fonctionnement d’un synthé qui vont grandement t’éclaircir les idées si tu n’y connais rien à la base. Une fois devant le synthé, une méthode très efficace pour apprendre est de décortiquer des presets, des sons complexes déjà à disposition, pour savoir comment ils ont été conçus. C’est ce qu’on appelle faire du « Reverse engineering » en anglais. Concrètement, cela consiste donc à prendre le processus de conception à l’envers: à partir du son fini, commence par désactiver les effets car tu verras que ces derniers prennent souvent une grande part dans la sonorité finale. Continue de même (activer/désactiver) section par section (oscillateurs, filtres puis modulations) pour constater l’effet sur le son de tel ou tel paramètre. Ensuite, amuse-toi à façonner tes propres sons en considérant ces trois concepts: la sonorité générale (avec les oscillateurs, filtres et effets), l’enveloppe (bref ou long? stable ou évolutif? ), l’espacement (centré, large, en mouvement?). Lien entre design sonore et composition dans la DAW Comme je le disais, il existe une connexion profonde entre sonorité et composition. Le son émis par l’instrument virtuel est le résultat de la conversion par ce même instrument des informations de note MIDI en données audio.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a54c74a-78fa-4684-b19b-f6bba6273cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200a1d40-a113-4737-99ec-ac7e1c6114d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, category=None, model='gpt-4o-mini'):\n",
    "    article_search_results, chunk_search_results = elastic_search2(query, category)\n",
    "    prompt = build_prompt(query, chunk_search_results, article_search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58469b47-a3ee-4941-9466-d944c82d7265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour créer ta musique dans un home-studio, tu auras besoin des éléments suivants :\n",
      "\n",
      "1. **Ordinateur** : Un ordinateur récent, que ce soit un Mac ou un PC, capable de gérer des applications audio. Il doit avoir un processeur rapide, une carte mère avec de la capacité pour ajouter de la RAM, et suffisamment d'espace de disque.\n",
      "\n",
      "2. **DAW (Digital Audio Workstation)** : C'est le logiciel principal que tu utiliseras pour enregistrer, jouer et créer ta musique. Les options populaires incluent Ableton Live, ProTools, Logic Pro, et bien d'autres. La DAW te permet d'éditer des fichiers audio et de manipuler les sons en suivant une ligne de temps.\n",
      "\n",
      "3. **Casque audio** : Un casque de bonne qualité est essentiel pour commencer à écouter et affiner ton son, sans nécessiter tout de suite des enceintes de monitoring.\n",
      "\n",
      "4. **Interface audio (optionnelle mais recommandée à long terme)** : Bien que la plupart des ordinateurs aient une carte son intégrée, une interface audio externe rendra l'enregistrement avec des micros et des instruments plus facile et de meilleure qualité.\n",
      "\n",
      "5. **Enceintes de monitoring (optionnelles)** : Si tu prévois de faire du mixage de manière plus sérieuse, des enceintes conçues pour cela t'aideront à obtenir une réponse en fréquence plus fidèle.\n",
      "\n",
      "6. **Micro (optionnel, selon tes besoins)** : Si tu souhaites enregistrer des voix ou des instruments acoustiques, tu auras besoin d'un micro.\n",
      "\n",
      "Ces équipements de base te permettront de lancer ta création musicale. Avec le temps et l'expérience, tu pourras évaluer des matériels supplémentaires selon tes besoins spécifiques.\n",
      "\n",
      "Les trois articles recommandés pour approfondir ce sujet sont :\n",
      "1. **Comment bien débuter en MAO: le home-studio démystifié**\n",
      "2. **Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?**\n",
      "3. **Deviens toi aussi producteur musical depuis ton home studio**\n"
     ]
    }
   ],
   "source": [
    "category = 'LE HOME STUDIO'\n",
    "question = 'De quel matériel ai-je besoin pour créer ma musique dans mon home-studio?'\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be4d02-5d0f-465b-9b75-26dac1b1cbb7",
   "metadata": {},
   "source": [
    "# Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "286045b2-a6a9-4120-9d75-8bdf4318f18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>chunk</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quel est l'impact de l'IA sur la post-producti...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment les outils IA simplifient-ils le trava...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels avantages l'IA apporte-t-elle aux artist...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment un débutant peut-il améliorer ses prod...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quelle est l'évolution des outils audio pour l...</td>\n",
       "      <td>LA POST-PROD</td>\n",
       "      <td>4615db39-1</td>\n",
       "      <td>4615db39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question      category  \\\n",
       "0  Quel est l'impact de l'IA sur la post-producti...  LA POST-PROD   \n",
       "1  Comment les outils IA simplifient-ils le trava...  LA POST-PROD   \n",
       "2  Quels avantages l'IA apporte-t-elle aux artist...  LA POST-PROD   \n",
       "3  Comment un débutant peut-il améliorer ses prod...  LA POST-PROD   \n",
       "4  Quelle est l'évolution des outils audio pour l...  LA POST-PROD   \n",
       "\n",
       "        chunk   article  \n",
       "0  4615db39-1  4615db39  \n",
       "1  4615db39-1  4615db39  \n",
       "2  4615db39-1  4615db39  \n",
       "3  4615db39-1  4615db39  \n",
       "4  4615db39-1  4615db39  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question = pd.read_csv('../data/ground-truth-300.csv')\n",
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2d0a4048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Quel est l'impact de l'IA sur la post-production audio et musicale\",\n",
       " 'category': 'LA POST-PROD',\n",
       " 'chunk': '4615db39-1',\n",
       " 'article': '4615db39'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')\n",
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bd63de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d1a27",
   "metadata": {},
   "source": [
    "### 1) Basic chunking, Minsearch based on the chunk_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eea453c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "957baa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['chunk']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['chunk_id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63794ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ff8948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e1cb3a46d7470dbaf545a17a8f5793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2945 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5297113752122241, 'mrr': 0.3079710027757569}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3edab1",
   "metadata": {},
   "source": [
    "### 2) Basic chunking, Minsearch based on the article_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61acd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['article']\n",
    "        results = search_function(q)\n",
    "        \n",
    "        # Ensure that only the first relevant result counts for the MRR\n",
    "        relevance = []\n",
    "        seen_article = False\n",
    "        for d in results:\n",
    "            if d['article_id'] == doc_id and not seen_article:\n",
    "                relevance.append(True)\n",
    "                seen_article = True\n",
    "            else:\n",
    "                relevance.append(False)\n",
    "\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc1b265f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41faac58623540c1abaca06f09984894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2945 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5911714770797962, 'mrr': 0.4871826070552721}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283be245",
   "metadata": {},
   "source": [
    "### 3) Find the best boost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30da8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_question[:100]\n",
    "df_test = df_question[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c06ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "        \n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "        \n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "    \n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "425ac4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4797e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "775ffd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'title': (0.0, 3.0),\n",
    "    'tags': (0.0, 3.0),\n",
    "    'chunk_text': (0.0, 3.0)\n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q['question'], boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "beaecfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c301601353fc4e7898d39df0a723e907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35c94a11d4b4d83beaaa2679132c978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6fbbd2f5a264866be11d15eb4cae01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a77961c4314a83a007a11d16f546ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb20888f0e644ecb2c7ae09a75b0897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58286f51fef14098af64f138292d0087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d84c7f64ab46d38b0740a123851bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41eee40bb1a94b109c2ecd1de24ef0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181749fde20943aabda2be14b6fd2f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceccb8bf6e354cdca575ac209315b452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52214a6700f94f7eafe53e7c7166862b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b390f6838b3402bb9fd52189a33b70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f12ae004a7458f8b0b302b8d869a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c833d537b44e3d9a210f5aa010c5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd91410204c447f1a889d1e56616912b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f56ce90df5a42429aaa4bd14a22248c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739d72d032b54479a6ca99bcc2a5eb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b984da68e244a5daf726139b8c990f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c607f24ce24705a816cbed141ea7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ae11c42eb9421380f8c13150336c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'title': 0.3144003830483091,\n",
       "  'tags': 0.21750500549018636,\n",
       "  'chunk_text': 1.55775214448781},\n",
       " 0.8056071428571429)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_optimize(param_ranges, objective, n_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d7efeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_improved(query):\n",
    "    boost = {\n",
    "        'title': 0.31,\n",
    "        'tags': 0.22,\n",
    "        'chunk_text': 1.56\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5176186f",
   "metadata": {},
   "source": [
    "### 4) Dynamic chunking size 300, overlap 50 - Minsearch, text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6e104209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4080aecc6d478d8b68e50b60e1d795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.5814685314685315, 'mrr': 0.47083888333888235}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "43c66696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8ccb4f3b554632aaf8eb566954d198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9545454545454546, 'mrr': 0.7798329448329442}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02d98b",
   "metadata": {},
   "source": [
    "### 5) Dynamic chunking size 350, overlap 30 - Minsearch, text search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04bd16b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b07004c0e4c4d1b9598ca7dbb2ad455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.6045146726862303, 'mrr': 0.4794655845784513}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f78ca9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceecb3eebfde4d7abcc5991170409eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8939051918735892, 'mrr': 0.7163696298685003}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_improved(q['question']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7639da",
   "metadata": {},
   "source": [
    "### 6) Dynamic chunking - Elasticsearch, text search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38608d2f",
   "metadata": {},
   "source": [
    "chunk size 300, overlap 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7cd8ff1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29be6a5fddc94dc7bc8a35fd72b3a065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2860 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9629370629370629, 'mrr': 0.8279434454434451}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search(q['question'], q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba24db6",
   "metadata": {},
   "source": [
    "chunk size 350, overlap 30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6261f23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7957464682fa46208a27353f34239f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9616252821670429, 'mrr': 0.7977245691354039}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: elastic_search(q['question'], q['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1ba4f",
   "metadata": {},
   "source": [
    "### 7) Two-level retrieval mechanism (article-level followed by chunk-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0e9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19281969-db02-42ae-a1a9-59c3caf86798",
   "metadata": {},
   "source": [
    "# RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "015c6999-12d3-41f2-ade9-9841722e5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90986137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2945"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5306095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Quel est l'impact de l'intelligence artificielle dans la post-production audio?\",\n",
       " 'category': 'LA POST-PROD',\n",
       " 'chunk': '4615db39-1',\n",
       " 'article': '4615db39'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = ground_truth[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7d82575b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L\\'impact de l\\'intelligence artificielle (IA) dans la post-production audio est considérable et se manifeste par une amélioration des outils et processus disponibles pour les artistes, producteurs et ingénieurs du son. La démocratisation de l\\'accès à des technologies avancées permet à un plus grand nombre de créateurs de produire des œuvres de qualité professionnelle sans nécessiter une formation approfondie en ingénierie du son.\\n\\nPremièrement, l\\'IA facilite la réalisation des tâches complexes et répétitives, permettant ainsi aux artistes et producteurs de se concentrer sur les aspects créatifs de leur travail. Par exemple, des plugins d\\'IA peuvent s\\'occuper de tâches telles que le nettoyage et la séparation des pistes audio de manière rapide et efficace, ce qui allège la charge de travail des ingénieurs du son. Des technologies avancées comme le dé-mixage, où une piste audio est décomposée en différentes stems (voix, batterie, etc.), sont déjà courantes et en constante amélioration grâce à l\\'IA.\\n\\nDeuxièmement, l\\'IA modifie la manière dont les professionnels interagissent avec la technologie. Plutôt que de se concentrer seulement sur les réglages techniques, les utilisateurs peuvent donner des directives qualitatives, comme \"je veux une voix plus forte et consistante\", et laisser l\\'IA optimiser les paramètres pour obtenir le résultat souhaité. Cela marque une évolution vers des outils plus intuitifs et adaptés aux besoins individuels.\\n\\nCependant, il est essentiel de ne pas considérer ces outils comme des solutions magiques. Une compréhension basique des processus audio est toujours nécessaire pour communiquer efficacement et pour exploiter au mieux ces nouvelles technologies.\\n\\nLes trois articles les plus pertinents pour approfondir ce sujet sont :\\n1. *L’intelligence artificielle (IA) dans le studio de production audio (6/6)* - Cet article offre un aperçu détaillé de l\\'impact de l\\'IA sur la production audio et les opportunités qu\\'elle crée pour les artistes et les producteurs.\\n2. *L’intelligence artificielle (IA) dans le studio de production audio (5/6)* - Il traite spécifiquement des applications de l\\'IA en restauration audio et dé-mixage, illustrant les avancées technologiques dans ce domaine.\\n3. *L’intelligence artificielle (IA) dans le studio de production audio (1/6)* - Cet article pose les bases en définissant ce qu\\'est l\\'IA et comment elle commence à transformer les processus de production audio.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = record['question']\n",
    "answer_llm = rag(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bcd7bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'impact de l'intelligence artificielle (IA) dans la post-production audio est considérable et se manifeste par une amélioration des outils et processus disponibles pour les artistes, producteurs et ingénieurs du son. La démocratisation de l'accès à des technologies avancées permet à un plus grand nombre de créateurs de produire des œuvres de qualité professionnelle sans nécessiter une formation approfondie en ingénierie du son.\n",
      "\n",
      "Premièrement, l'IA facilite la réalisation des tâches complexes et répétitives, permettant ainsi aux artistes et producteurs de se concentrer sur les aspects créatifs de leur travail. Par exemple, des plugins d'IA peuvent s'occuper de tâches telles que le nettoyage et la séparation des pistes audio de manière rapide et efficace, ce qui allège la charge de travail des ingénieurs du son. Des technologies avancées comme le dé-mixage, où une piste audio est décomposée en différentes stems (voix, batterie, etc.), sont déjà courantes et en constante amélioration grâce à l'IA.\n",
      "\n",
      "Deuxièmement, l'IA modifie la manière dont les professionnels interagissent avec la technologie. Plutôt que de se concentrer seulement sur les réglages techniques, les utilisateurs peuvent donner des directives qualitatives, comme \"je veux une voix plus forte et consistante\", et laisser l'IA optimiser les paramètres pour obtenir le résultat souhaité. Cela marque une évolution vers des outils plus intuitifs et adaptés aux besoins individuels.\n",
      "\n",
      "Cependant, il est essentiel de ne pas considérer ces outils comme des solutions magiques. Une compréhension basique des processus audio est toujours nécessaire pour communiquer efficacement et pour exploiter au mieux ces nouvelles technologies.\n",
      "\n",
      "Les trois articles les plus pertinents pour approfondir ce sujet sont :\n",
      "1. *L’intelligence artificielle (IA) dans le studio de production audio (6/6)* - Cet article offre un aperçu détaillé de l'impact de l'IA sur la production audio et les opportunités qu'elle crée pour les artistes et les producteurs.\n",
      "2. *L’intelligence artificielle (IA) dans le studio de production audio (5/6)* - Il traite spécifiquement des applications de l'IA en restauration audio et dé-mixage, illustrant les avancées technologiques dans ce domaine.\n",
      "3. *L’intelligence artificielle (IA) dans le studio de production audio (1/6)* - Cet article pose les bases en définissant ce qu'est l'IA et comment elle commence à transformer les processus de production audio.\n"
     ]
    }
   ],
   "source": [
    "print(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "566e8de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: Quel est l'impact de l'intelligence artificielle dans la post-production audio?\n",
      "Generated Answer: L'impact de l'intelligence artificielle (IA) dans la post-production audio est considérable et se manifeste par une amélioration des outils et processus disponibles pour les artistes, producteurs et ingénieurs du son. La démocratisation de l'accès à des technologies avancées permet à un plus grand nombre de créateurs de produire des œuvres de qualité professionnelle sans nécessiter une formation approfondie en ingénierie du son.\n",
      "\n",
      "Premièrement, l'IA facilite la réalisation des tâches complexes et répétitives, permettant ainsi aux artistes et producteurs de se concentrer sur les aspects créatifs de leur travail. Par exemple, des plugins d'IA peuvent s'occuper de tâches telles que le nettoyage et la séparation des pistes audio de manière rapide et efficace, ce qui allège la charge de travail des ingénieurs du son. Des technologies avancées comme le dé-mixage, où une piste audio est décomposée en différentes stems (voix, batterie, etc.), sont déjà courantes et en constante amélioration grâce à l'IA.\n",
      "\n",
      "Deuxièmement, l'IA modifie la manière dont les professionnels interagissent avec la technologie. Plutôt que de se concentrer seulement sur les réglages techniques, les utilisateurs peuvent donner des directives qualitatives, comme \"je veux une voix plus forte et consistante\", et laisser l'IA optimiser les paramètres pour obtenir le résultat souhaité. Cela marque une évolution vers des outils plus intuitifs et adaptés aux besoins individuels.\n",
      "\n",
      "Cependant, il est essentiel de ne pas considérer ces outils comme des solutions magiques. Une compréhension basique des processus audio est toujours nécessaire pour communiquer efficacement et pour exploiter au mieux ces nouvelles technologies.\n",
      "\n",
      "Les trois articles les plus pertinents pour approfondir ce sujet sont :\n",
      "1. *L’intelligence artificielle (IA) dans le studio de production audio (6/6)* - Cet article offre un aperçu détaillé de l'impact de l'IA sur la production audio et les opportunités qu'elle crée pour les artistes et les producteurs.\n",
      "2. *L’intelligence artificielle (IA) dans le studio de production audio (5/6)* - Il traite spécifiquement des applications de l'IA en restauration audio et dé-mixage, illustrant les avancées technologiques dans ce domaine.\n",
      "3. *L’intelligence artificielle (IA) dans le studio de production audio (1/6)* - Cet article pose les bases en définissant ce qu'est l'IA et comment elle commence à transformer les processus de production audio.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "006933b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b0302ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b5a16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a0a09bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d51df44fae44848b51ae3901d37aaa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question) \n",
    "\n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation = llm(prompt)\n",
    "    evaluation = json.loads(evaluation)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fdfa8313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'question': \"Pourquoi le 32 bits float ne suffit pas avant l'enregistrement dans la DAW ?\",\n",
       "  'category': 'LE HOME STUDIO',\n",
       "  'chunk': 'e55c4a41-6',\n",
       "  'article': 'e55c4a41'},\n",
       " 'Le format 32 bits float est très utile pour le traitement audio au sein d\\'une station de travail audionumérique (DAW) car il offre une large plage dynamique et permet d’éviter le clipping pendant les manipulations internes. Cependant, il ne suffit pas avant l\\'enregistrement dans la DAW pour plusieurs raisons.\\n\\nTout d\\'abord, l\\'avantage du 32 bits float ne s\\'applique pas à la phase de l\\'enregistrement, qui se déroule encore dans le domaine analogique. Pendant cette étape, il est crucial de s\\'assurer que le signal audio ne dépasse pas le 0 dBFS pour éviter la saturation. De plus, une gestion rigoureuse des niveaux est essentielle dès le moment de l\\'enregistrement pour maintenir une bonne qualité audio et éviter des problèmes de bruit de quantification lors des conversions numériques.\\n\\nEnsuite, une fois que le signal audio est exporté hors de la DAW, l\\'avantage des 32 bits float disparaît totalement. Lors de l\\'exportation ou de tout \"bounce\", le signal est converti, ce qui peut entraîner une détérioration de la qualité si la résolution des fichiers de sortie est inférieure (par exemple, 16 ou 24 bits). \\n\\nEn résumé, bien qu\\'un DAW en 32 bits float facilite certains aspects du traitement audio, une vigilance continue sur les niveaux est nécessaire tout au long du processus de production, depuis l\\'enregistrement jusqu\\'à l\\'exportation.\\n\\nPour approfondir ce sujet, je recommande les trois articles suivants :\\n\\n1. **La gestion des niveaux (5): ta DAW en 32 bits float**\\n2. **La gestion des niveaux (6): Maîtriser la dynamique sonore**\\n3. **Par où commencer dans l’apprentissage d’une DAW pour produire sa musique?**',\n",
       " {'Relevance': 'RELEVANT',\n",
       "  'Explanation': 'The generated answer clearly explains why the 32 bits float format is not sufficient before recording in a DAW, discussing the importance of managing audio levels during the analog recording phase and addressing issues that arise when exporting the signal. It provides relevant information that directly answers the question.'})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc247327",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['chunk'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1891ce2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.985\n",
       "PARTLY_RELEVANT    0.015\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "187aa368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../data/rag-eval-gpt-4o-mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b4af5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pour changer le pitch naturellement dans Ablet...</td>\n",
       "      <td>173567a9-2</td>\n",
       "      <td>Quelle méthode peut-on utiliser pour changer l...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer discusses changing pitch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pour éviter les pièges du make-up gain lors de...</td>\n",
       "      <td>584d0437-3</td>\n",
       "      <td>Quels conseils professionnels peut on suivre p...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer discusses make-up gain an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>La question concernant l'activation du mode Th...</td>\n",
       "      <td>173567a9-11</td>\n",
       "      <td>Quelles sont les étapes pour activer le mode T...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer acknowledges the question...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                answer           id  \\\n",
       "18   Pour changer le pitch naturellement dans Ablet...   173567a9-2   \n",
       "31   Pour éviter les pièges du make-up gain lors de...   584d0437-3   \n",
       "146  La question concernant l'activation du mode Th...  173567a9-11   \n",
       "\n",
       "                                              question        relevance  \\\n",
       "18   Quelle méthode peut-on utiliser pour changer l...  PARTLY_RELEVANT   \n",
       "31   Quels conseils professionnels peut on suivre p...  PARTLY_RELEVANT   \n",
       "146  Quelles sont les étapes pour activer le mode T...  PARTLY_RELEVANT   \n",
       "\n",
       "                                           explanation  \n",
       "18   The generated answer discusses changing pitch ...  \n",
       "31   The generated answer discusses make-up gain an...  \n",
       "146  The generated answer acknowledges the question...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_eval[df_eval.relevance == 'PARTLY_RELEVANT']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
