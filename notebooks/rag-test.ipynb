{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fbd7bbe-145f-4e58-a874-b005dbed225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import minsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454e399-424c-422e-9c60-8a83cf54b729",
   "metadata": {},
   "source": [
    "# Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21c60918-87b5-4156-88b7-291eb26ed85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/arsonor_data.json', 'r', encoding='utf-8') as file:\n",
    "    documents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46d3d15f-2c46-47ed-a0ac-1df6d3f56159",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=['title', 'text', 'tags'],\n",
    "    keyword_fields=['category']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "376cc4c0-efd8-4437-ba79-2de0a7a02265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x28caf0ad7f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4c969-765d-4ad2-b773-30cd5a790bf9",
   "metadata": {},
   "source": [
    "# RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1079a01c-d246-4f30-9912-8b97aefdc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62f684d0-f0d5-46fd-8d0a-5e5fbfe7c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dd6789d-dbcd-4bb8-a19c-70213e286f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How to create a good, punchy beat for my productions?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c73c08c8-ce03-43ec-ad67-f9cad23e0d23",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1259\u001b[0m     )\n\u001b[1;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_base_client.py:1026\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1025\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_base_client.py:1075\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\AI-Powered-Knowledge-Assistant-for-Audio-P-kOHx9R9c\\Lib\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[0;32m   1050\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": query}]\n",
    "    )\n",
    "    \n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "297ea691-22dd-4982-abd3-4104f6467a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "460e2c4b-d2b5-416a-aeb8-b2a503f8c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're an audio engineer and sound designer instructor for beginners.\n",
    "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
    "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "Finally add in your response the top 5 articles of arsonor that are the best to read for answering this question.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "article_title: {title}\n",
    "article_content: {text}\n",
    "article_keywords: {tags}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6383065f-7541-4718-8c05-b577ade7d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search(query)\n",
    "prompt = build_prompt(query, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a90e3571-822d-457d-815a-38530f98c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're an audio engineer and sound designer instructor for beginners.\n",
      "You're particularly specialized in audio home-studio set-up, computer music production and audio post-production in general (editing, mixing and mastering). \n",
      "Answer the QUESTION based on the CONTEXT from our arsonor knowledge database (articles).\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "Finally add in your response the top 5 articles of arsonor that are the best to read for answering this question.\n",
      "\n",
      "QUESTION: How to create a good, punchy beat for my productions?\n",
      "\n",
      "CONTEXT:\n",
      "article_title: Ecouter les sons du quotidien pour amÃ©liorer vos productions\n",
      "article_content: Voici le premier Ã©pisode du podcast Arsonor! Je t â€˜y explique notamment: lâ€™importance de savoir Ã©couter les subtilitÃ©s du son pour amÃ©liorer tes compÃ©tences en sound design et mixage audio. en quoi consiste lâ€™Ã©coute analytique/active et les bonnes questions quâ€™il faut se poser quand on Ã©coute une musique. la relation entre ces questions et le processing audio pour retranscrire au mieux nos intentions de production, le tout avec un exemple concret. Pour Ã©couter cet Ã©pisode, lance tout simplement le lecteur ci-dessus. Tu peux aussi accÃ©der Ã  la page officielle du podcast . Et bien sÃ»r le tÃ©lÃ©charger en qualitÃ© audio optimale par le lien suivant . Contenu de l'Ã©pisode #1: Pour ceux qui tomberaient ici par hasard, ce blog parle de crÃ©ation et de production musicale, de A Ã  Z depuis son home-studio, et plus particuliÃ¨rement Â« in the box Â», câ€™est-Ã -dire tous les processing directement dans son ordinateur. Câ€™est un gros programme tout Ã§a, qui exige beaucoup de savoir-faire, dâ€™expÃ©rience engrangÃ©e jour aprÃ¨s jour, voire annÃ©e aprÃ¨s annÃ©e. On en apprend tous les jours! Il faut se mettre Ã  la fois dans la peau dâ€™un compositeur et dâ€™un ingÃ©nieur du son . Câ€™est ce que jâ€™appelle le producteur moderne , qui fait tout depuis chez lui. De lâ€™idÃ©e du morceau jusquâ€™Ã  sa diffusion. Alors, lâ€™une des clÃ©s de lâ€™apprentissage, Ã§a va Ãªtre dâ€™ apprendre Ã  Ã©couter les sons . Cela a lâ€™air trivial dis comme Ã§a, mais en fait, quand par exemple tu Ã©coutes de la musique, tu ne fais pas que Ã§a. Tu ne lâ€™Ã©coutes pas forcÃ©ment de maniÃ¨re trÃ¨s attentive, Ã  faire attention jusquâ€™aux moindres dÃ©tails. Mais si tu veux devenir producteur musical, lâ€™un des savoir-faire les plus importants, câ€™est de savoir Ã©couter les sons, se concentrer uniquement sur le son, pour ce quâ€™il est. Tu vas me dire câ€™est bien joli tout Ã§a mais Ã§a veut dire quoi? Comment je dois Ã©couter? Et bien câ€™est justement le fil rouge de cet Ã©pisode et de tous ceux Ã  venir , lâ€™Ã©coute analytique (active) des sons dans ce qui font leur forme pour mieux savoir les reproduire avec les technologies numÃ©riques actuelles. Et quoi de mieux que le format podcast pour se concentrer uniquement sur lâ€™Ã©coute et devenir ainsi un meilleur producteur? Dâ€™oÃ¹ le Nom de ce podcast: Ecouter les sons pour vos productions . L'importance de l'Ã©coute analytique en production musicale Par analogie avec le film par exemple, un Ã©tudiant en cinÃ©ma qui regarde un film va analyser tous ses aspects techniques, faire attention aux mouvements de la camÃ©ra, lâ€™Ã©clairage, le type de plan, le dÃ©coupage, la synchronisation des lÃ¨vres des acteurs, etcâ€¦ Bien quâ€™il soit beaucoup moins agrÃ©able dâ€™analyser les aspects techniques dâ€™un film en le regardant, cela peut faire des Ã©tudiants en cinÃ©ma de bien meilleurs cinÃ©astes. Et bien en musique, en production musicale, câ€™est exactement pareil! Lâ€™apprentissage consiste simplement Ã  appuyer sur lecture et Ã  Ã©couter activement ce qui se passe et cela fera de toi un bien meilleur producteur musical. Chaque morceau, quâ€™il soit bon ou mauvais, est une leÃ§on de production et de mixage . Il y a toujours quelque chose Ã  en retirer. Alors assis-toi, ferme les yeux et Ã©coute attentivement ce que les pros ont rÃ©alisÃ©, simple non? OK, non en fait câ€™est pas si simple que Ã§a ðŸ™‚ Comment Ã©couter activement la musique ? Lors de lâ€™Ã©coute, il est bon de prendre lâ€™habitude de se poser un certain nombres de question dans quatre catÃ©gories de la crÃ©ation musicale: La composition Lâ€™arrangement et lâ€™instrumentation La production et le sound design Le mixage Ces questions permettent de se focaliser sur un aspect spÃ©cifique dans le processus de crÃ©ation musicale. 1) Composition Quelle est la tonalitÃ© du morceau? Est-ce que je peux remarquer certains intervalles entre les notes? Yâ€™a tâ€™il une progression dâ€™accord particuliÃ¨re? Quelle est la signature rythmique du morceau? Est-ce que je peux remarquer un certain groove (lÃ©gers dÃ©calages de notes)? etcâ€¦ Par ces questions, je fais ici intervenir mon oreille musicale, celle du musicien. 2) Arrangement et instrumentation Combien dâ€™instruments sont prÃ©sents? Quels sont-ils? Quelle est la structure du morceau, si tentÃ© quâ€™il yâ€™en ait une? Quâ€™est-ce qui diffÃ©rencie le couplet du refrain? Peut-on remarquer dâ€™autres sections (Break, etcâ€¦) et que sâ€™y passe tâ€™il? 3) Production/sound design Câ€™est maintenant lâ€™oreille de lâ€™ingÃ©nieur du son que je vais solliciter pour me demander ce qui fait le timbre du son ? Quelle est lâ€™Ã©volution du son dâ€™un Ã©lÃ©ment en particulier au cours du temps au niveau de son enveloppe ? Est-il soutenu ou instantanÃ©/percussif avec beaucoup de transitoires? Observe-tâ€™on une variation cyclique en volume, en pitch ou dans lâ€™espace stÃ©rÃ©o? Yâ€™a tâ€™il des effets de distorsions? des filtrages particuliers? des delay, reverb, effet autotune, etcâ€¦ 4) Mixage Cette fois, il sâ€™agit de prÃªter attention au comportement des divers instruments/Ã©lÃ©ments entre eux, Ã  la fois sur le plan dynamique, frÃ©quentiel, et de gestion de lâ€™espace: Quelle est le niveau des instruments les uns par rapport aux autres? Comment les instruments sont-ils pannÃ©s (positionnÃ©s dans lâ€™espace stÃ©rÃ©o)? Comment les diffÃ©rents instruments sont-ils disposÃ©s sur le spectre des frÃ©quences (des basses au plus hautes)? Dans quelle mesure les instruments sont-ils reliÃ©s les uns aux autres? Y a-t-il une automation? sur quel paramÃ¨tre en particulier? Quelle est la durÃ©e des rÃ©verbÃ©rations? Quelle est la dÃ©finition des instruments? Ce ne sont que quelques exemple dâ€™interrogations parmi les innombrables choses Ã  rechercher lors de lâ€™analyse de mixages. PremiÃ¨re difficultÃ© de l'apprenti producteur musical Quand on dÃ©bute en production musicale, il est en effet difficile de faire le lien entre nos interrogations et les processeurs et outils de la production. Comment alors rÃ©pondre Ã  toutes ces questions? Par exemple, des questionnements comme Â« je veux faire avancer ce son vers moi Â», Â« je nâ€™entends pas cet Ã©lÃ©ment par dessus lâ€™autre Â», Â« je veux cet instrument plus sombre et plus diffus Â», etcâ€¦, nâ€™ont pas de relation immÃ©diate avec des termes comme Â« cutoff Â», Â« LFO Â», Â« seuil Â», Â« dry/wet Â», Â« decay Â», etcâ€¦ Solution: Pratiquer en permanence l'Ã©coute active = comprendre les effets sur le son des outils de traitements Ã  la disposition du producteur/mixeur musical Lâ€™Ã©coute active permet de faire le lien entre ton action dans le processing dâ€™un traitement audio et son effet sur lâ€™Ã©lÃ©ment sonore. Tu augmenteras tes compÃ©tences en production musicale en tâ€™entraÃ®nant rÃ©guliÃ¨rement. Et câ€™est bien lâ€™objectif de ce podcast! Dâ€™ailleurs, lâ€™un des avantages du traitement analogique du son par rapport au numÃ©rique est quâ€™il permet de se concentrer uniquement sur lâ€™Ã©coute, sans aucune distraction visuelle! Souvent, dans ces dÃ©bats entre analogique et numÃ©rique, câ€™est devenu lâ€™un des principaux arguments de lâ€™analogique. On peut traiter le son en bougeant des potards, faders ou autres boutons, sans la distraction de lâ€™Ã©cran qui vient perturber notre Ã©coute. Il faut toujours avoir conscience de cela quand tu produis dans ton ordinateur. La finalitÃ© câ€™est bel et bien ce quâ€™on Ã©coute et pas ce quâ€™on voit! PrÃ©cision sur l'Ã©coute de ce podcast Petite prÃ©cision avant de continuer: Les sujets abordÃ©s portant autour des traitements audio et du sound design, ce podcast sera dâ€™autant plus enrichissant pour toi si tu peux lâ€™Ã©couter avec la meilleure qualitÃ© sonore possible. Tu en retireras une meilleure expÃ©rience en Ã©coutant de maniÃ¨re concentrÃ©e et avec un bon casque ou tout autre systÃ¨me audio stÃ©rÃ©o de bonne qualitÃ©. Alors, je sais bien que la plupart du temps, les gens Ã©coutent les Ã©pisodes en faisant autre chose, et Ã  lâ€™aide des simples Ã©couteurs du tÃ©lÃ©phone. Mais sache simplement que ce nâ€™est pas lâ€™idÃ©al. Surtout quand jâ€™aborderai des notions plus pointues en mixage audio. De plus, quelque soit le diffuseur que tu utilises pour Ã©couter ce podcast, le fichier audio est compressÃ© pour des raisons dâ€™optimisation de flux et de dÃ©bit, ce qui nâ€™est pas lâ€™idÃ©al non plus! Câ€™est pourquoi, je mets toujours Ã  disposition lâ€™Ã©pisode dans sa qualitÃ© audio optimale, non compressÃ©e. Donc, pour les plus intÃ©ressÃ©s et motivÃ©s dâ€™entre vous, rendez-vous sur Arsonor.com dans lâ€™article correspondant Ã  lâ€™Ã©pisode afin de le tÃ©lÃ©charger (tu peux tÃ©lÃ©charger lâ€™Ã©pisode en question par le lien au dÃ©but de cet article). Exemple concret: Design sonore d'un effet de montÃ©e (\"Riser\") Ã  partir de l'analyse d'un son du quotidien ConsidÃ©rons un effet de montÃ©e (riser) â€“ un classique en pop et Ã©lectro. {SON} On a ici un simple bruit blanc filtrÃ© de maniÃ¨re assez basique et qui nâ€™a pas vraiment dâ€™impact â€¦ Lâ€™objectif est dâ€™amÃ©liorer ce son pour quâ€™il sâ€™insÃ¨re au mieux dans une production. Pour ce faire, je vais prendre lâ€™analogie avec le son dâ€™une voiture qui se rapproche. Si tu ne comprends pas oÃ¹ je veux en venir, pas de panique, tu vas comprendre Ã  la fin. Lâ€™idÃ©e est de montrer comment un son du rÃ©el, de notre quotidien quand il est bien analysÃ©, sâ€™apparente en tout point Ã  nos dÃ©cisions en production musicale. Etapes de traitement d'un son de voiture qui se rapproche ConsidÃ©rons ce son dâ€™une voiture: {SON} On peut traiter ce son pour simuler le fait quâ€™elle se dÃ©place vers nous: Etape 1: Sensation de dÃ©placement de la gauche vers la droite PremiÃ¨re chose, pour donner la sensation de mouvement du son, de son dÃ©placement de la gauche vers la droite, je fais varier le paramÃ¨tre Â« Panoramique Â». â†’ automation du panoramique de la gauche vers la droite (33L Ã  7R par exemple). Etape 2: Sensation du volume perÃ§u Ensuite le plus Ã©vident est que le niveau perÃ§u augmente Ã  mesure que lâ€™objet se rapproche. On entend le moteur plus clairement Ã  la fin: cela se traduit par augmentation du volume, faible au dÃ©but puis rapidement Ã  son maximum Ã  la fin). â†’ automation dâ€™augmentation de gain (-12 Ã  +6 dB). Dâ€™une maniÃ¨re gÃ©nÃ©rale, les sons subtils qui ne peuvent pas Ãªtre entendus de loin, peuvent Ãªtre mis en Ã©vidence en utilisant ces variations de volume, et particuliÃ¨rement un outil qui sâ€™appelle la compression, ou peut-Ãªtre une compression multibande. Notions quâ€™on aura le temps dâ€™aborder plus tard dans dâ€™autres Ã©pisodes. Etape 3: Sensation du contenu en hautes frÃ©quences Dâ€™un point de vue frÃ©quentiel, plus un objet sonore est Ã©loignÃ©, moins son contenu hautes frÃ©quences est important (absorbÃ©es plus facilement par lâ€™air) par rapport aux basses qui se propagent sur de plus longues distances. Quand elle est loin, on entend un grondement flou Ã  basse frÃ©quence. Donc pour retranscrire cela, on peut utiliser un filtre Low-pass qui sâ€™ouvre progressivement vers les hautes frÃ©quences au fur et Ã  mesure que lâ€™objet se rapproche. Ou alors, plus subtilement, un high shelf que je fais augmenter en gain (cutoff Ã  4 kHz et gain de -5 Ã  +13 dB). Voir la sÃ©rie articles sur les EQ si tu ne comprends pas tous ces termes. Etape 4: Sensation de la rÃ©verbÃ©ration Et enfin, une derniÃ¨re Ã©tape oÃ¹ jâ€™ajoute une reverb pour la sensation dâ€™un espace particulier. La rÃ©ponse en rÃ©verbÃ©ration sera Ã©galement radicalement diffÃ©rente pour les objets Ã©loignÃ©s et rapprochÃ©s. Plus un objet est Ã©loignÃ©, plus le son direct nous parvenant (ligne droite sans rÃ©flexions) arrive en mÃªme temps que les autres ondes rÃ©flÃ©chies (la reverb). Alors que quand il est plus proche, le son direct et les premiÃ¨res rÃ©flexions de la reverb sont plus distincts et sÃ©parables, lÃ  oÃ¹ avant tout Ã©tait encore mÃ©langÃ© en un seul son rÃ©verbÃ©rÃ© plus flou. Sur les rÃ©glages dâ€™un plugin de reverb, cela se traduit par la modification de lâ€™Ã©cart entre les premiÃ¨res rÃ©flexions et la queue de rÃ©verb. Un paramÃ¨tre clÃ© pour cela est le prÃ©-delai. Il se rÃ¨gle en ms, de 0 Ã  plusieurs 100taines (de 15 Ã  400 ms dans notre exemple). Ecoute A/B du son final obtenu VoilÃ  le son final que jâ€™obtiens: {SON} Et en comparant avec le son initial, sans traitements: {SON} On constate bien la diffÃ©rence entre les deux. On a bien cet effet de mouvement. Lorsque la voiture commence Ã  nous dÃ©passer, elle est Ã  son plus fort. On entend mieux les sons Ã  la fin. Application en contexte musical sur le \"Riser\" Maintenant je vais te montrer ce que cela donne sur un exemple plus musical. Il me suffit alors de remplacer le son de voiture par mon bruit blanc, le riser Ã©coutÃ© tout Ã  lâ€™heure (ils font la mÃªme longueur). Du coup, en appliquant exactement tous les traitements prÃ©cÃ©dents, mais cette fois ci sur ce riser Ã  la place du bruit de voiture, voilÃ  ce que cela donne: {SON} Ecoute la diffÃ©rence lorsque je bypass les traitements (dÃ©sactivation): {SON} Et en activant les traitements, {SON} , le son devient dÃ©jÃ  bien plus intÃ©ressant, il commence bas et lent, devient plus grand et plus proche, jusquâ€™Ã  occuper tout lâ€™espace des haut-parleurs. Ecoutons maintenant en contexte avec un rythme House: Sans les effets: {SON} .Et Avec: {SON} En mettant toutes ces considÃ©rations en pratique, je tâ€™ai montrÃ© Ã  quel point ces techniques peuvent grandement amÃ©liorer un son. Bon il existe beaucoup dâ€™autres techniques de production et je pourrais encore largement amÃ©liorer tout Ã§a, mais câ€™est pas le sujet de cet Ã©pisode aujourdâ€™hui! Conclusion de l'Ã©pisode Sâ€™l y a une chose Ã  retenir de cet Ã©pisode, lâ€™Ã©quipement le plus important, câ€™est tes oreilles. Prends-en soin. Nâ€™oublie pas dâ€™Ã©couter. Toujours. Ã‰coute le monde, Ã©coute le film, Ã©coute ton interlocuteur. Mais toujours dans cette perspective analytique du son et de ses propriÃ©tÃ©s physiques. Meilleur tu es dans lâ€™Ã©coute, meilleur tu seras en tant que producteur musical. Je te remercie dâ€™avoir pris le temps dâ€™Ã©couter cet Ã©pisode de bienvenue. Nâ€™hÃ©sites pas Ã  commenter et Ã  partager ce podcast si cela tâ€™a plu. De me dire ce que tu penses de ce nouveau format par exemple. Ce nâ€™est que le dÃ©but dâ€™une longue sÃ©rie Ã  venir. Je te rappelle que tu peux tÃ©lÃ©charger lâ€™Ã©pisode en qualitÃ© audio optimale, non compressÃ©e dans lâ€™article correspondant sur le blog Arsonor. VoilÃ , je te dis Ã  trÃ¨s trÃ¨s bientÃ´t, dâ€™ici lÃ , bonne Ã©coute, bonne prod!\n",
      "article_keywords: Ã©coute analytique, podcast, riser\n",
      "\n",
      "article_title: Lâ€™intelligence artificielle (IA) dans le studio de production audio (1/6)\n",
      "article_content: Qu'est-ce que la technologie IA dans les outils de production audio? Lâ€™intelligence artificielle (IA ou AI en anglais) nâ€™est plus une caractÃ©ristique spÃ©culative de la science-fiction. Elle a un effet transformateur sur une vaste gamme dâ€™industries* et lâ€™audio ne fait pas exception. * Selon une Ã©tude (Source: Mckinsey Global Institute), lâ€™IA devrait gÃ©nÃ©rer 13 billions (mille milliards!) de dollars supplÃ©mentaires de revenus dâ€™ici 2030. Cette technologie rÃ©volutionnaire devrait crÃ©er 58 millions de nouveaux emplois dâ€™ici 2022 (dont la grande majoritÃ© sont des emplois que lâ€™on ne connaÃ®t pas Ã  lâ€™heure actuelle) (Source: https://www.forbes.com/sites/amitchowdhry/2018/09/18/artificial-intelligence-to-create-58-million-new-jobs-by-2022-says-report/?sh=3f393ff74d4b) Jâ€™ai repÃ©rÃ© trois grands domaines de lâ€™audio oÃ¹ lâ€™IA sâ€™est bien implantÃ©e et fait dÃ©jÃ  ses preuves: 1) Lâ€™IA au service de lâ€™Ã©coute personnalisÃ©e Cela inclut tout le domaine de la reconnaissance musicale et la recommandation personnelle (Smart Speaker, Droits dâ€™auteur, MIR: Music Information Retrievalâ€¦) en plein boom sous lâ€™impulsion des diverses plateformes de streaming . Câ€™est aussi le domaine de la synthÃ¨se vocale (TTS: Text To Speech recognition) et du traitement de la parole, de dialecte ou de langue. Et enfin, cela inclut aussi le choix individuel dâ€™un mode dâ€™Ã©coute au casque (Ã©mulation de sources ou dâ€™espaces rÃ©els et spatialisation 3D). 2) Lâ€™IA comme assistant de composition et de sound design On retrouve ici tout ce qui concerne les services ou outils de gÃ©nÃ©ration de musique automatique (Generative Music) . Cela concerne aussi tous les nouveaux plugins dâ€™assistance au Beatmaking (Beats machine, GÃ©nÃ©rateur automatique de pattern MIDI, dâ€™accords dans la tonalitÃ©â€¦) , Ã  la synthÃ¨se sonore et au son Ã  lâ€™image. 3) Lâ€™IA comme assistant en post-production audio On y retrouve tous ces nouveaux plugins Â« intelligents Â» dans le mixage assistÃ© , ainsi que dans la rÃ©paration, nettoyage et sÃ©paration des sources audio. Mais aussi et enfin, cela concerne tous les services en ligne de Mastering assistÃ© . Sommaire de la sÃ©rie d'articles Ã  venir Ce qui suit dans cette sÃ©rie de 6 articles ne concerne que le point nÂ°3 (je me restreint Ã  ce thÃ¨me pour ne pas faire trop long, peut Ãªtre que dâ€™autres articles suivront). A travers un tour dâ€™horizon des outils audio actuels et en dÃ©veloppement, ce dossier en six parties sâ€™attache Ã  montrer lâ€™impact et le rÃ´le de lâ€™IA dans le studio de production audio: Dans cet article, jâ€™illustre ce que reprÃ©sente la technologie Ã  intelligence artificielle et montre notamment en quoi elle diffÃ¨re dâ€™un algorithme classique. Le prochain article traitera des services en ligne en Mastering audio qui est le domaine oÃ¹ lâ€™IA a dâ€™abord fait ses preuves; Le troisiÃ¨me article commence un Ã©tat des lieux des logiciels ou plugins audio innovants sortis ces derniÃ¨res annÃ©es. Jâ€™aborde dâ€™abord lâ€™exemple de ces nouveaux Â« EQ intelligents Â» qui nâ€™intÃ¨grent pas forcÃ©ment encore de lâ€™intelligence artificielle mais en prennent le chemin et la philosophie; La quatriÃ¨me partie fera un tour dâ€™horizon des bundles de plugins intÃ©grant de lâ€™IA pour le mixage et le mastering assistÃ© , comme par exemple ceux dâ€™iZotope ou les Smart de Sonible; La cinquiÃ¨me partie traitera dâ€™un domaine particuliÃ¨rement propice Ã  lâ€™utilisation de lâ€™IA en post-production audio: la restauration sonore, la rÃ©duction de bruit et la sÃ©paration des sources audio . Enfin, dans le dernier article, je conclue le dossier en mâ€™interrogeant sur lâ€™impact de lâ€™IA sur les mÃ©tiers de la production audio et musicale , et comment je vois le secteur Ã©voluer Ã  plus long terme. Mais dâ€™abord, pour bien comprendre la tendance prÃ©sente et Ã  venir, intÃ©ressons-nous Ã  dÃ©finir exactement ce quâ€™est une IA et son rÃ´le dans nos outils numÃ©riques de production musicale (logiciels MAO, plugins, â€¦). Lâ€™intÃ©gration progressive de lâ€™IA dans nos outils audio contribue grandement Ã  faciliter le travail du producteur/ingÃ©nieur du son. Câ€™est du moins un objectif clair de remplacer les tÃ¢ches ennuyeuses et rÃ©pÃ©titives par un logiciel qui ferait tout le Â« sale boulot Â» Ã  la place de lâ€™homme. Comme un assistant dÃ©vouÃ© sur des tÃ¢ches qui peuvent Ãªtre automatisÃ©es. NÃ©anmoins lâ€™Ã©volution du studio de production jusquâ€™Ã  lâ€™Ã¨re du numÃ©rique montre dÃ©jÃ  cette tendance: De lâ€™automatisation mÃ©canique des tÃ¢ches Ã  lâ€™arrivÃ©e du numÃ©rique Mis Ã  part lâ€™Ã©volution de la qualitÃ© sonore, beaucoup dâ€™innovations majeures ont eu aussi pour but de faciliter le travail dâ€™enregistrement et de traitement audio. Si on remonte aux annÃ©es 50-60, lâ€™Ã©quilibrage des diffÃ©rentes sources sonores devait se faire dÃ¨s la prise de son! Il faut attendre les annÃ©es 70 pour que le mÃ©tier dâ€™ingÃ©nieur de mixage devienne un nouveau concept. Ceci sera facilitÃ© dans les annÃ©es 80 par lâ€™intÃ©gration dâ€™outils de traitement audio (dynamique dÃ©diÃ©e compresseur/expandeur/gate + EQ full paramÃ©trique) sur chaque tranche dâ€™une console analogique. La fonction Â« Total Recall Â» Automation sur les consoles SSL est une vÃ©ritable rÃ©volution. On est dÃ©sormais capables de sauver et restituer entiÃ¨rement un mixage, autant par ses rÃ©glages fixes que par ses Ã©volutions en cours de morceau! Les faders motorisÃ©s deviendront un Ã©lÃ©ment central de lâ€™enregistrement musical, permettant aux rÃ©glages dâ€™Ã©galisation et aux positions des faders dâ€™Ãªtre chargÃ©s dans un systÃ¨me ou un ordinateur directement connectÃ© Ã  la station de travail audio de mixage et appelÃ©s plus tard sur la ligne lorsque cela est nÃ©cessaire. Les consoles de plus en plus riches en fonctionnalitÃ©s ont permis aux producteurs dâ€™explorer de nouvelles techniques crÃ©atives et de donner naissance Ã  des productions toujours plus modernes et sophistiquÃ©es. A la fin des annÃ©es 90â€™s, le DAW (Digital Audio Workstation) , devient le centre nÃ©vralgique numÃ©rique du studio. Le nombre de pistes et de traitements illimitÃ©s permet alors Ã  lâ€™ingÃ©nieur de mix de prendre de plus en plus de pouvoir et agir directement sur la performance de lâ€™artiste. Puis les annÃ©es 2000 et 2010 verront la tendance croissante Ã  rÃ©duire les machines au simple ordinateur. Lâ€™Ã¨re du home-studio, du Â« mix in the box Â» et de la dÃ©mocratisation des outils Ã  tout un chacun interrogent dÃ©jÃ  sur le vÃ©ritable rÃ´le de lâ€™ingÃ©nieur du son aujourdâ€™hui. En quoi lâ€™IA diffÃ¨re-tâ€™elle dâ€™un simple algorithme: lâ€™exemple du compresseur de la dynamique Si on prend lâ€™exemple du compresseur , son invention a dâ€™abord permis lâ€™automatisation mÃ©canique pour le contrÃ´le des volumes . Avec cet outil, lâ€™ingÃ©nieur du son nâ€™avait plus besoin de suivre et rÃ©gler manuellement le volume dâ€™une source audio Ã  la dynamique trop changeante. Depuis, lâ€™Ã©volution du compresseur en plugin numÃ©rique lui permet dâ€™Ãªtre un outil omniprÃ©sent et dÃ©mocratisÃ© dans le traitement de la dynamique, de lâ€™enregistrement jusquâ€™au mastering audio. Pourtant, encore aujourdâ€™hui, son utilisation reste complexe et largement incomprise par tout amateur ou novice des traitements audio. Par exemple, lorsque nous utilisons un plug-in de compression pour traiter un enregistrement vocal, le plug-in rÃ©pond Ã  nos rÃ©glages et Ã  la dynamique du matÃ©riau de maniÃ¨re prÃ©visible. Cela peut Ãªtre trÃ¨s utile, mais son efficacitÃ© dÃ©pend entiÃ¨rement de la faÃ§on dont nous configurons les paramÃ¨tres de compression et notre capacitÃ© Ã  Ã©couter finement les diffÃ©rences. Un enregistrement vocal diffÃ©rent peut nÃ©cessiter un ratio de compression diffÃ©rent, voire une chaÃ®ne de traitement complÃ¨tement diffÃ©rente. Au-delÃ  des presets fournis que nous pouvons essayer, les plugins conventionnels ne peuvent pas nous aider Ã  prendre cette dÃ©cision. Au lieu de cela, nous nous appuyons sur nos propres expÃ©riences passÃ©es et nos compÃ©tences acquises pour dÃ©cider des paramÃ¨tres du nouvel enregistrement vocal. LÃ  oÃ¹ lâ€™intelligence artificielle intervient câ€™est quâ€™elle va supprimer le besoin dâ€™un individu, ou plutÃ´t, le besoin dâ€™un cerveau humain Ã  acquÃ©rir cette expÃ©rience. Potentiellement, un algorithme de compresseur IA pourrait analyser la performance dâ€™un chanteur particulier, la comparer avec une bibliothÃ¨que dâ€™autres performances et gÃ©nÃ©rer des paramÃ¨tres de compression appropriÃ©s. Un logiciel IA pourrait Ã©muler ces compÃ©tences cognitives . PlutÃ´t que dâ€™offrir simplement un rÃ©glage nÃ©cessitant des compÃ©tences, un compresseur basÃ© sur lâ€™IA pourrait dÃ©terminer par lui-mÃªme quel pourrait Ãªtre le meilleur rÃ©glage. GrÃ¢ce Ã  lâ€™analyse dâ€™un grand nombre dâ€™enregistrements vocaux existants, le logiciel construirait un modÃ¨le mathÃ©matique de ce Ã  quoi ressemble une Â« bonne compression vocale Â». Il appliquerait ce modÃ¨le Ã  de nouveaux enregistrements en les comparant aux modÃ¨les de rÃ©glages quâ€™il a appris, sur la base de sa propre expÃ©rience acquise, plutÃ´t que de la nÃ´tre. Par exemple, un musicien nâ€™ayant pas les compÃ©tences nÃ©cessaires pour mixer une chanson pourrait compter sur un mixage assistÃ© par lâ€™IA ; plutÃ´t que dâ€™avoir Ã  apprendre Ã  utiliser les commandes de compresseur telles que le ratio, le seuil, lâ€™attack et le release, il pourrait simplement dire quâ€™il veut Â« les voix plus fortes et plus consistantes Â», ou que Â« la guitare doit Ãªtre plus proÃ©minente que le piano Â». La technologie IA dans les studios aujourdâ€™hui Le contrÃ´le de la plage dynamique et lâ€™utilisation de compresseurs est une modeste illustration thÃ©orique , dans une certaine mesure, de ce que peut apporter lâ€™intelligence artificielle. Car pour que des algorithmes fassent le travail Ã  notre place, lâ€™IA est basÃ©e sur lâ€™analyse de donnÃ©es, le Big Data . On entendra souvent les termes de Â« Machine learning Â» ou Â« Deep learning Â» et on parlera dâ€™architectures de code DNN (Deep Neural Networks) ou encore C/RNN (Convolutional / Recurrent Neural Networks) . Ces concepts informatiques sont Ã©galement applicables Ã  de nombreux autres scÃ©narios de production musicale et pourraient profondÃ©ment changer la faÃ§on dont nous produisons de la musique. En fait, lâ€™IA a dÃ©jÃ  un impact significatif dans des domaines tels que le mastering et la composition. A mesure que lâ€™assistance IA prend de lâ€™ampleur , les crÃ©ateurs et les machines continuent de sâ€™entremÃªler de plus en plus, les flux de travail crÃ©atifs prenant de nouvelles formes. DÃ¨s lors, cela nous amÃ¨ne Ã  sâ€™interroger sur lâ€™avenir du mÃ©tier de producteur/ingÃ©nieur du son . Comment la technologie IA lâ€™impacte tâ€™elle et comment est-elle susceptible de se dÃ©velopper Ã  plus long terme? Nos chers DAW vont-ils tomber en dÃ©suÃ©tude? Sont-ils dÃ©jÃ  has been? Quel avenir pour les mÃ©tiers de la production musicale, Ã  la fois sur le plan technique et crÃ©atif? Rendez-vous la semaine prochaine pour la suite ðŸ˜‰\n",
      "article_keywords: algorithme, deep learning, IA, logiciel audio, machine learning, plugin, post-production\n",
      "\n",
      "article_title: 10 logiciels incontournables pour le sound design\n",
      "article_content: Le design sonore (ou plus communÃ©ment appelÃ© sound design ) est un terme un peu passe-partout employÃ© Ã  toutes les sauces. A partir du moment oÃ¹ mon mÃ©tier consiste Ã  transformer des sons enregistrÃ©s ou Ã  en crÃ©er de nouveaux de maniÃ¨re synthÃ©tique, je suis un designer sonore. Cela se pratique depuis toujours dans le son Ã  lâ€™image et plus rÃ©cemment dans toute production musicale moderne. Dâ€™ailleurs la frontiÃ¨re entre sound design et composition musicale sâ€™est considÃ©rablement rÃ©trÃ©cie. Musique ou sound design? En effet, si je conÃ§ois un son simulant un impact de balle dans une planche de bois, on appellera cela communÃ©ment du sound design. Et si jâ€™utilise ce mÃªme son pour rendre une caisse claire plus percutante, je deviens un producteur musical. Une fois acceptÃ© que tout son peut Ãªtre vu comme possible entitÃ© musicale, câ€™est une dÃ©marche naturelle dâ€™utiliser des outils de sound design dans le processus de production. Ces derniÃ¨res annÃ©es, les outils numÃ©riques de traitement du son ont incroyablement Ã©voluÃ©s et continuent dâ€™Ã©voluer sans cesse. Si bien quâ€™ils reprÃ©sentent aujourdâ€™hui les moyens incontournables pour recrÃ©er des sons originaux ou leur redonner vie. Pourquoi pas travailler sur une hybridation de son analogique et numÃ©rique? Travailler avec des bruits plutÃ´t que des notes? Et pourquoi pas essayer de rendre organique un son ne provenant dâ€™aucune source physique? Mode de sÃ©lection des logiciels de sound design Pour faire face au choix plÃ©thorique parmi les sociÃ©tÃ©s fabriquant ces outils, jâ€™ai crÃ©Ã© cette liste des 10 logiciels incontournables en me basant sur les catÃ©gories (â€œtypeâ€ de logiciel) suivantes: les DAW : ta station audio-numÃ©rique est bien sÃ»r ton premier et principal outil de crÃ©ation sonore, la base multi-fonctionnelle; les synthÃ©tiseurs virtuels (VSTi) , parmi les mastodontes du marchÃ© (y intÃ©grant des techniques de synthÃ¨se sonore diverses); les â€œpluginsâ€ dâ€™effets divers sur le traitement du son. Ces derniers ont dâ€™ailleurs souvent pour vocation premiÃ¨re dâ€™Ãªtre utilisÃ©s en production ou mixage audio. Mais le principe du sound design est justement de les dÃ©tourner de leur fonction premiÃ¨re. Utiliser les outils de production musicale dâ€™une maniÃ¨re â€œnon musicaleâ€ ou non intentionnelle peut mener Ã  des rÃ©sultats rÃ©jouissants et surprenants. Puis, parmi ces catÃ©gories, jâ€™ai appuyÃ© mes choix suivant ces critÃ¨res : algorithme parmi les plus innovants et bluffants de ces derniÃ¨res annÃ©es; accÃ¨s Ã  des banques de son de haute qualitÃ©; dans lâ€™air du temps, ainsi que bÃ©nÃ©ficiant dâ€™une popularitÃ© et dâ€™une communautÃ© dâ€™utilisateurs trÃ¨s forte; dotÃ© dâ€™une interface agrÃ©able et un rapport dâ€™apparente complexitÃ©/simplicitÃ© dâ€™utilisation optimal. Câ€™est parti! 1) Station audio-numÃ©rique (DAW) Ableton Live Est-il vraiment nÃ©cessaire de le prÃ©senter? VÃ©ritable rÃ©volution Ã  sa sortie parce quâ€™il dÃ©portait le sÃ©quenceur traditionnellement dÃ©diÃ© au studio dans lâ€™univers du live (dâ€™oÃ¹ son nom), Ableton est devenu une institution et Live le logiciel favori de quantitÃ©s de DJ et musiciens Ã©lectroniques qui lâ€™utilisent sur scÃ¨ne ou en studio, seul ou en complÃ©ment de leur setup. Ses effets tels que le Beat Repeat, lâ€™ Autofilter ou lâ€™ Autopan , ses instruments Simpler ou Operator ont Ã©tÃ© plÃ©biscitÃ©s dans la crÃ©ation dâ€™un nombre incalculables de morceaux de ces derniÃ¨res annÃ©es. En matiÃ¨re de DAW, comme je le disais dans lâ€™article La MAO dÃ©mystifiÃ©e , on a toutefois lâ€™embarras du choix: il en existe une multitude avec plus ou moins dâ€™anciennetÃ©, chacun a ses atouts et sa spÃ©cialitÃ©. Et bien lÃ  oÃ¹ la majoritÃ© des DAW se dÃ©die traditionnellement Ã  la prod et au mixage en studio, sorte de pendant logiciel Ã  nos bonnes vieilles consoles analogiques, Ableton prend le contre-pied en le dÃ©diant, dâ€™abord au live, mais aussi et surtout (et par consÃ©quent) aux expÃ©rimentations sonores les plus folles . Car ce qui sÃ©pare Live dâ€™une autre DAW, outre ses effets et instruments natifs, câ€™est bel et bien son fameux mode Session : â€œune page dâ€™idÃ©esâ€, une matrice de pads, interface unique pour improviser, jouer et performer avec des idÃ©es musicales, sans les contraintes de la ligne de temps. Quasiment tout dans Live travaille en temps rÃ©el et en synchro; ajoute, rÃ©ordonne ou enlÃ¨ve divers effets, joue avec le routage flexible et bien plus encore, le tout sans interrompre ton flow crÃ©atif. Tu lâ€™as compris, Live est un incontournable pour la crÃ©ativitÃ© musicale et le sound design. Demo: Et enfin une vidÃ©o datant de 2006! Eh oui mÃªme si beaucoup de choses ont Ã©voluÃ©es entre temps, les principes de base restent toujours les mÃªmes: Autres recommandations: Une autre DAW trÃ¨s populaire pour tous les utilisateurs dâ€™un Macbook Pro puisque rachetÃ©e par Apple, je veux bien sÃ»r parler de Logic Pro . En matiÃ¨re de sound design, il y a aussi de quoi faire avec des outils intÃ©grÃ©s de choix comme les synthÃ©tiseurs Alchemy ou Sculpture , et sa reverb Ã  convolution Space Designer. 2) SynthÃ¨se hybride (tout en un) Spectrasonics Omnisphere Depuis 2008, la rÃ©putation de la firme Spectrasonics nâ€™est plus Ã  faire dans le monde du sound design et des instruments virtuels. Et leur produit phare, le synthÃ©tiseur virtuel mastodonte (ou â€œPower Synthâ€), Omnisphere le dÃ©montre bien: en plus de possÃ©der tous les atouts dâ€™un synthÃ© classique Ã  synthÃ¨se soustractive, son moteur puissant intÃ¨gre (liste non exhaustive) des fonctions de synthÃ¨se FM et granulaire, un arpÃ©giateur et des effets de haute facture . Tout ceci au sein dâ€™une interface simple et Ã©purÃ©e. Et câ€™est sans compter lâ€™importation possible de ses propres sons en plus de sa bibliothÃ¨que interne tout simplement monstrueuse . Tu peux y reconnaÃ®tre dâ€™ailleurs la plupart des sons â€œhollywoodiensâ€ que les designers sonores pour les films utilisent abondamment. Eric Persing, le boss de Spectrasonics, a su en effet sâ€™entourer dâ€™une ribambelle de sound designers de gÃ©nie (Diego Stocco, Ignacio Longo, Richard Devine pour ne citer quâ€™eux) pour te fournir des Ã©chantillons sonores dâ€™une qualitÃ© incomparable. Ce joujou a dâ€™ailleurs le dÃ©faut de ses qualitÃ©s car il tâ€™en coÃ»tera pas moins dâ€™un espace de 64GB de sons Ã  rÃ©server sur ton disque dur si tu veux en faire lâ€™acquisition. Et les sons incorporÃ©s sont tellement de qualitÃ© et utilisables tels quels que tu en oublierais presque quâ€™il est aussi possible dâ€™utiliser ses fonctions pourtant infinies de synthÃ¨se sonore. Demo: Un des sound designer de renom Ã  avoir grandement participÃ© Ã  lâ€™Ã©laboration des sons dâ€™Omnisphere nâ€™est autre que Diego Stocco. Qui mieux que lui pour prÃ©senter ce que le synthÃ© a dans le ventre: Autres recommandations: â€“ Alchemy (anciennement produit de chez Camel Audio, il a Ã©tÃ© rachetÃ© par Apple et totalement intÃ©grÃ© dans Logic Pro! Une raison majeure de se procurer Logic si tâ€™hÃ©sites encore) â€“ KV331 Audio Synthmaster â€“ Synapse Audio Dune 3 3) SynthÃ¨se Ã  tables d'onde (wavetable) Xfer Records Serum Si jâ€™en parle dans une section Ã  part, câ€™est que ce type de synthÃ¨se a le vent en poupe. Depuis le Wave de PPG (crÃ©Ã© en 1981 par Wolfgang Palm) et de Waldorf , la synthÃ¨se Ã  table dâ€™ondes sâ€™est peu Ã  peu popularisÃ©e sous forme numÃ©rique, notamment par lâ€™intermÃ©diaire de Native Instruments avec Massive . Mais câ€™est surtout Steve Duda et son instrument Serum qui sâ€™est dÃ©finitivement imposÃ© comme LE synthÃ©tiseur virtuel Ã  tables dâ€™ondes . Ce type de synthÃ¨se a conquis depuis bon nombre de producteurs de musiques Ã©lectroniques. Mais pas que. Car mÃªme si cela peut sembler destinÃ© Ã  des sons froids et synthÃ©tiques câ€™est que tu nâ€™as pas bien saisi toutes les possibilitÃ©s offertes par le logiciel. Cette faÃ§on de pouvoir importer et â€œsculpterâ€ le son Ã  sa source, câ€™est-Ã -dire dans sa forme dâ€™onde, a un potentiel crÃ©atif Ã©norme et original. Demo: Un exemple avec lâ€™utilisation avancÃ©e des tables dâ€™ondes: Autres recommandations: â€“ Ableton Live Wavetable (Dans sa version 10, Live intÃ¨gre son nouvel instrument Ã  table dâ€™ondes. Lâ€™idÃ©e de concurrencer Serum sur ce terrain est Ã©vidente et il ne sâ€™en cache pas). â€“ Arturia Pigments (La firme franÃ§aise Arturia sâ€™y met aussi avec son nouveau bÃ©bÃ©) â€“ Native Instruments Massive X : Jusquâ€™Ã  aujourdâ€™hui, Massive est toujours lâ€™un des synthÃ©s virtuels de rÃ©fÃ©rence sur le marchÃ©, malgrÃ© son interface vieillotte et quasi-inchangÃ©e depuis sa sortie. Sauf quâ€™en 2019, NI sâ€™est enfin dÃ©cidÃ© Ã  le relifter avec une mise Ã  jour majeure sous le nom de Massive X (qui est en fait un nouveau synthÃ©tiseur Ã  part entiÃ¨re quâ€™une simple mise Ã  jour). 4) Sampling Native Instruments Kontakt Le sampling est une technique de production maintenant connue depuis plus de 30 ans, ayant dÃ©fini beaucoup de tendances musicales et mÃªme faÃ§onnÃ© des genres entiers. AprÃ¨s la rÃ©volution des machines hardware Akai , le sampler dâ€™aujourdâ€™hui est un instrument virtuel permettant dâ€™y charger des bouts dâ€™audio (samples) et les jouer Ã  lâ€™envie Ã  diffÃ©rents pitchs et vÃ©locitÃ©s . Jâ€™arrÃªte lÃ  pour la partie â€œtechniqueâ€ car câ€™est pas le sujet de lâ€™article. Les Ã©volutions techniques du sampling permettent de nos jours de pouvoir recrÃ©er (ou plutÃ´t Ã©muler) nâ€™importe quel instrument de maniÃ¨re trÃ¨s rÃ©aliste, mais aussi de manipuler les Ã©chantillons sonores dans tous les sens, ce qui en fait un outil de choix pour le sound design . Et la particularitÃ© de Kontakt, câ€™est que nombre plÃ©thorique de marques dâ€™Ã©mulation dâ€™instruments rÃ©els et leur librairie dâ€™Ã©chantillons sonores sâ€™intÃ¨gre directement dans le logiciel. Le â€œplayerâ€ gratuit Kontakt peut Ãªtre utilisÃ© pour pleins dâ€™instruments. Mais la plupart des instruments provenant de sociÃ©tÃ©s tierces exigent la version complÃ¨te. Si tu es intÃ©ressÃ© par le sampling en tant que producteur ou compositeur, Kontakt est un â€œmust haveâ€ puisquâ€™il permet dâ€™accÃ©der Ã  la majoritÃ© des librairies disponibles sur le marchÃ©. Câ€™est ce qui en fait le sampler le plus utilisÃ© au monde et un statut de quasi indispensable dans le monde de la production musicale numÃ©rique. Demo: Lâ€™utilisation de Kontakt Ã©tant plus connue en jouant sur des instruments venant de sociÃ©tÃ© tierces, voilÃ  un tuto montrant les fonctions avancÃ©es du sampler en lui-mÃªme afin de crÃ©er son propre instrument: Autres recommandations: Il y a des tonnes dâ€™autres choix en matiÃ¨re de sampler dont bien Ã©videmment: â€“ Celui de ta DAW pourrait aussi trÃ¨s bien faire lâ€™affaire ( Steinberg Cubase Halion, Ableton Live Simpler + Sampler, Logic EXS24 â€¦) â€“ UVI Falcon : le constructeur franÃ§ais, responsable de beaucoup dâ€™innovations dans le domaine, mÃ©rite dâ€™Ãªtre mentionnÃ©. 5) Programmation modulaire Native Instruments Reaktor Ne tâ€™y trompe pas, on ne parle pas ici dâ€™un simple instrument mais plutÃ´t dâ€™une sorte de mÃ©ga interface dont tu es le hÃ©ros ! Comme Kontakt, Reaktor a en commun ce concept de script ou programmation sonore personnalisÃ©e : des dÃ©veloppeurs tiers (ou toi-mÃªme!) peuvent y crÃ©er des interfaces et instruments uniques. Si tout cela te rebute car tu nâ€™es pas programmeur, rassure toi, la derniÃ¨re version intÃ¨gre un systÃ¨me de â€œblocksâ€ trÃ¨s facile Ã  utiliser. Et si cela tâ€™effraies toujours, tu peux simplement tâ€™en servir en chargeant lâ€™un des innombrables modules Ã  ta disposition. Tu tâ€™apercevras assez tÃ´t que les journÃ©es dÃ©filent trÃ¨s vite pendant que tu tritures les boutons de maniÃ¨re alÃ©atoire, tout en te rÃ©galant les oreilles. Car mÃªme remarque ici que pour Omnisphere prÃ©cÃ©demment : Reaktor intÃ¨gre dÃ©jÃ  un large choix dâ€™instruments utilisables tels quels qui sont dâ€™une telle qualitÃ© et originalitÃ© quâ€™il est facile de sâ€™en contenter! Cela va du synthÃ©, gÃ©nÃ©rateur de sons aux boÃ®tes Ã  rythme et autres sÃ©quenceurs et effets. Lâ€™autre gros point fort de Reaktor est sa communautÃ© dâ€™utilisateurs trÃ¨s active oÃ¹ chacun peut y aller de son propre instrument et le partager dans une sorte de librairie accessible ici: https://www.native-instruments.com/fr/reaktor-community/reaktor-user-library/ . Bref, un MUST! Demo: Et un exemple de ce quâ€™il est possible dâ€™y faire entre autres choses: Autres recommandations: â€“ Max/MSP : DÃ©veloppÃ© par lâ€™Ircam dans les annÃ©es 80, il est commercialisÃ© aujourdâ€™hui par la sociÃ©tÃ© Cyclingâ€™74 et surtout, il est complÃ¨tement intÃ©grÃ© dans Ableton Live (voir prÃ©cÃ©demment)! Comme pour Reaktor (qui en est donc un concurrent direct), la communautÃ© dâ€™utilisateurs trÃ¨s active peut crÃ©er des â€œMax for Live Devicesâ€ (M4L) ; ce qui dÃ©cuple encore les possibilitÃ©s sur Ableton et en font dÃ©finitivement le logiciel nÂ°1 en sound design (voir point 1)). Voir ici pour un aperÃ§u de toutes les extensions Max for Live: https://www.ableton.com/en/packs/#?item_type=max_for_live . â€“ Pure data : DÃ©veloppÃ© en parallÃ¨le Ã  Max/MSP, le code est en Open source et gratuit. Câ€™est donc un logiciel de programmation graphique trÃ¨s populaire pour la crÃ©ation musicale et multimÃ©dia en temps rÃ©el. 6) Correction tonale, Pitch-Shift et Time-Stretch Celemony Melodyne Le â€œpitch-shiftâ€ (changer la tonalitÃ© dâ€™un son sans en altÃ©rer sa vitesse) et son corollaire le â€œtime-stretchâ€ (changer la longueur dâ€™un son sans en altÃ©rer sa tonalitÃ©) sont des procÃ©dÃ©s Ã  la base de lâ€™Ã©volution des technologies audio-numÃ©riques. Tu utilises leurs algorithmes associÃ©s dans toutes les sources audio sans tâ€™en rendre compte (pour la synchronisation du son Ã  lâ€™image Ã  la moindre application audio dâ€™aujourdâ€™hui en passant par lâ€™art du DJing bien entendu). Du cÃ´tÃ© des studios musicaux, cela a permis de rÃ©volutionner le travail (en bien ou en mal) jusquâ€™Ã  Ãªtre capable de faire passer nâ€™importe qui chantant comme une casserole Ã  un tÃ©nor dâ€™opÃ©ra prestigieux (jâ€™exagÃ¨re Ã  peine). Lâ€™outil magique permettant de faire cela câ€™est l â€™autotune , nom originaire du produit phare de chez Antares . Mais depuis peu un autre concurrent sÃ©rieux sâ€™est mis sur ce marchÃ©; je veux bien sÃ»r parler de Celemony avec son Melodyne . Tous les studios musicaux professionnels du monde entier ont dans leur arsenal au moins lâ€™un ou lâ€™autre (si ce nâ€™est pas les deux). Mais alors quâ€™est-ce qui fait que je parle de Melodyne dans cet liste dâ€™outils pour le sound design? Contrairement Ã  lâ€™Autotune dâ€™Antares, Melodyne ne fait pas de correction de pitch en temps rÃ©el (pendant que le chanteur chante) mais sâ€™utilise en post-production. En revanche, son concept et ses algorithmes sont rÃ©volutionnaires. Son concepteur, un luthier et mathÃ©maticien allemand de gÃ©nie , a imaginÃ© la transposition visuelle de lâ€™audio (habituellement sous forme dâ€™onde sonore) note par note, chacune reprÃ©sentÃ©e par une forme de â€œgoutteâ€ . LÃ  oÃ¹ jusquâ€™Ã  maintenant on se contentait de manipuler lâ€™onde sonore, avec Melodyne, on plonge littÃ©ralement Ã  lâ€™intÃ©rieur du son ! La correction de note en tonalitÃ© ou en durÃ©e devient un jeu dâ€™enfant. De plus, son Ã©diteur de son (dans la version complÃ¨te du logiciel) ouvre la voie Ã  des possibilitÃ©s extraordinaires. Demo: Nâ€™hÃ©sites surtout pas Ã  parcourir le site officiel car on y retrouve des tutos Ã©galement disponibles en franÃ§ais (ce qui est trÃ¨s rare)! En voilÃ  un parlant justement de lâ€™Ã©diteur de son: PrÃ©sentation de lâ€™Ã©diteur par le Maestro himself (mais en anglais seulement): Et enfin, un bon exemple de ce quâ€™il est possible de faire avec une voix chantÃ©e: Autres recommandations: â€“ Antares Autotune : Si tu nâ€™as encore jamais entendu parlÃ© dâ€™Autotune, câ€™est que le rap/Hip Hop et toi, Ã§a fait deux! LE concurrent de Melodyne, tout simplement. Il nâ€™est pas aussi poussÃ© dans le traitement note par note mais il se diffÃ©rencie par son traitement du pitch en temp rÃ©el! â€“ Serato Pitchâ€™nâ€™time : Peut-Ãªtre le meilleur pitch-shift du marchÃ©. â€“ PaulXStretch : En voilÃ  un logiciel de time-stretch bien original, Ã  lâ€™algorithme rÃ©volutionnaire et surtout gratuit! Si je devais garder un seul coup de coeur de toutes ces listes de plugins ce serait celui-lÃ . Il avait fait le buzz Ã  lâ€™Ã©poque de sa sortie grÃ¢ce Ã  son utilisation sur une chanson de Justin Bieber qui la transforma dâ€™une longueur de 3 min 21 en une voix de fantÃ´me sous amphÃ©tamines de 35 minutes! (1.8 millions de vues sur Youtube en une semaine). Il est devenu depuis un outil original pour crÃ©er ou transformer nâ€™importe quel son en nappe ambient bien planante. Voici un extrait du morceau: Et voici un exemple dâ€™utilisation Ã©difiante (le plugin a depuis Ã©voluÃ© avec une interface plus moderne): 7) Restauration sonore Izotope RX AprÃ¨s un logiciel de correction tonale, voilÃ  maintenant un logiciel de restauration sonore? Oh que oui! En quelques annÃ©es, lâ€™ensemble de plugins RX de Izotope sâ€™est imposÃ© comme LA rÃ©fÃ©rence dans le domaine de la rÃ©paration audio (enlever les clics, le clipping, les bruits de fonds intempestifs, et bien plus maintenantâ€¦). Au point de dÃ©trÃ´ner peu Ã  peu lâ€™outil phare qui Ã©tait spÃ©cialement dÃ©diÃ© Ã  cela jusque lÃ : lâ€™ensemble Cedar . Mais ce qui fait la spÃ©cificitÃ© de RX, câ€™est son interface (en â€œstandaloneâ€, câ€™est-Ã -dire en utilisant le logiciel seul, pas sous forme de plugin) visuelle sous la forme cette fois dâ€™un spectrogramme . Un quoi? Outre la forme dâ€™onde ou le spectre, le spectrogramme est la reprÃ©sentation visuelle du son permettant dâ€™analyser Ã  la fois son contenu frÃ©quentiel et dynamique en fonction du temps (temps en abscisse, frÃ©quences en ordonnÃ©e et intensitÃ© du son en surbrillance colorÃ©e). Et les outils remarquables de RX permettant de modifier ce spectrogramme, ajoutÃ© aux nombreux modules disponibles pour altÃ©rer le son, en font un outil en or pour tout sound designer. La derniÃ¨re mouture de RX est LE logiciel, avec Melodyne, permettant notamment de sâ€™approcher de plus en plus vers la possibilitÃ© de sÃ©parer les Ã©lÃ©ments audio dâ€™un morceau (sÃ©parer lâ€™acapella de lâ€™instrumental par exemple). Demo: Autres recommandations: â€“ Accusonus Era Bundle â€“ Zynaptiq Un-Series 8) Reverb/Delay Zynaptiq Adaptiverb Dans la catÃ©gorie des plugins dÃ©tournÃ©s de leur fonction premiÃ¨re dans le mixage audio, il faut bien sÃ»r parler des reverbs et delays. Les algorithmes de ces outils ont bien Ã©voluÃ©s et certains plugins permettent un rendu dans lâ€™espace de grande qualitÃ©. Dans le domaine du sound design, le travail dans lâ€™ espace sonore est primordial. Ici lâ€™objectif nâ€™est pas le rÃ©alisme mais plutÃ´t la recherche d â€™ambiances Ã©thÃ©rÃ©es et irrÃ©elles . Pour cela, lâ€™Adaptiverb fait fabuleusement le job. Ce nâ€™est dâ€™ailleurs pas exactement un plugin de reverb Ã  proprement parlÃ©, mais plutÃ´t une sorte dâ€™hybride synthÃ©tiseur/reverb sâ€™adaptant automatiquement au contexte audio. Demo: Dans cette catÃ©gorie des â€œreverbs Ã  effets spÃ©ciauxâ€ , jâ€™aurais pu tout aussi bien citer celles-ci: â€“ Eventide Blackhole â€“ 2CAudio Aether â€“ Valhalla Shimmer â€“ Surreal Machines Diffuse Il faut bien sÃ»r aussi parler de la catÃ©gorie des Reverbs Ã  convolution : car mÃªme si leur objectif premier est un rendu le plus rÃ©aliste possible, on peut y importer ses propres IR (impulsions audio), et alors tout devient possible. â€“ AudioEase Altiverb : la Rolls Royce des reverbs Ã  convo â€“ Ou celle de ta DAW si elle en a une ( Space Designer sur Logic, Convolution Reverb Pro avec Max for Live, etc, etcâ€¦) Enfin, on peut mentionner dans cette section la catÃ©gorie des Delays extrÃªmement crÃ©atifs et originaux : â€“ Fabfilter Timeless â€“ Soundtoys Echoboy â€“ Boz Digital Labs Imperial Delay â€“ MeldaProduction MSpectralDelay 9) Saturation Izotope Trash A lâ€™instar de la Reverb, la saturation est Ã  priori un procÃ©dÃ© utilisÃ© en mixage audio. La saturation a diffÃ©rents effets sur le son: en plus dâ€™ajouter diffÃ©rentes types de couleur et dâ€™harmoniques, cela va aussi influer sur lâ€™Ã©quilibre spectral et dynamique. Trash de chez Izotope est lâ€™un de ceux qui Ã©lÃ¨ve lâ€™effet de saturation et de distortion Ã  un nouveau niveau de destruction sonore. Mais surtout câ€™est lâ€™un des rares Ã  pouvoir sâ€™utiliser presque plus comme un instrument que comme un simple effet. Demo: Autres recommandations: Autres plugins forts recommandables aux doux noms Ã©vocateurs: â€“ Soundtoys Filterfreak / Decapitator â€“ Fabfilter Saturn â€“ D16 Devastor â€“ Ohm Force Ohmicide 10) Transformation vocale Krotos Reformer Pro Et lâ€™algorithme le plus innovant de ces derniers temps nous vient de la sociÃ©tÃ© Ã©cossaise Krotos Audio . GrÃ¢ce Ã  sa technologie dâ€™entrÃ©e audio dynamique , Reformer Pro te permet de performer avec ta voix nâ€™importe quel type de son en temps rÃ©el. Par exemple, tu veux un rugissement de lion fÃ©roce pendant quâ€™on voit le lion rugir Ã  lâ€™image? eh bien il te suffit de grogner toi-mÃªme dans un micro, et le son en sortie (Ã  lâ€™aide dâ€™une librairie de sons bien confectionnÃ©e) rendra le rugissement hyper rÃ©aliste et suivant en temps rÃ©el les mouvements de tes cordes vocales. Lâ€™outil rÃªvÃ© pour concevoir des sons Ã  lâ€™image! Reformer Pro rÃ©volutionne le travail de lâ€™artiste â€œFoleyâ€ . Ce sont ces bruiteurs du cinÃ©ma qui performent en temps rÃ©el tous les sons des objets et personnages en mouvement Ã  lâ€™aide dâ€™une multitudes dâ€™objets divers Ã  leur disposition. Avec Reformer Pro, câ€™est la mÃªme idÃ©e sauf quâ€™il te suffit maintenant dâ€™un bon micro et de banques de son bien construites. De multiples banques sont dâ€™ailleurs en vente sur le site du constructeur mais tu peux aussi importer tes propres sons (en suivant quelques rÃ¨gles). Alors tu me diras, wow câ€™est super pour le son Ã  lâ€™image, mais pour le sound design en crÃ©ation musicale? Eh bien câ€™est pareil! Les banques de sons peuvent aussi rÃ©agir Ã  lâ€™audio enregistrÃ© sur ta DAW (pour des percussions ou autre) mais Ã©galement Ãªtre contrÃ´lÃ©es par Midi. Dans la crÃ©ation musicale moderne, beaucoup dâ€™effets sonores (Foley ou FX) sâ€™adaptent magnifiquement dans un contexte rythmique ou musical. La richesse spectrale et la complexitÃ© rythmique inhÃ©rente Ã  ces sons est souvent sous-estimÃ©e. En plus de Reformer pro, Krotos a Ã©galement dans sa palette les outils Dehumanizer et Weaponizer qui sont dans la mÃªme veine et valent aussi le coup. Demo: Autres recommandations: Sous le terme â€œtransformation vocaleâ€, on peut y retrouver dâ€™autres types de technologie audio: â€“ AudioEase Speakerphone : Comment ne pas penser aux maÃ®tres de la convolution avec la sociÃ©tÃ© hollandaise AudioEase . TrÃ¨s connus pour leur reverb phare Altiverb , Speakerphone est aussi un outil trÃ¨s utile pour transformer une voix â€œnormaleâ€ en une voix sortant de nâ€™importe quel endroit (appareils Ã©lectroniques, mÃ©gaphone, etc, etcâ€¦) â€“ Zynaptiq Wormhole : GrÃ¢ce Ã  une combinaison de â€œwarpingâ€ spectral, dâ€™algorithmes de reverb riche, de pitch-shifting et de morphing , Zynaptiq (encore eux) permet avec Wormhole dâ€™obtenir rapidement des ambiences surrÃ©alistes ou des voix dâ€™aliens, monstres et robots en tout genre. â€“ Celemony Melodyne : voir plus haut â€“ Flux Ircam Trax : Ce plugin est absolument Ã©poustouflant! Il permet, par exemple, de passer dâ€™une voix dâ€™homme (ou femme) Ã  une voix dâ€™enfant ou de personne Ã¢gÃ©e avec un rÃ©alisme rare! â€“ Izotope Vocalsynth : Izotope nâ€™est aussi pas en reste avec son vocoder du futur. 11) En bonus: Les bundles Si tu ne devais choisir quâ€™un seul pack de plugins pour le sound design venant dâ€™un seul fabriquant, alors tu peux te tourner vers ce que les marques appellent un Bundle. A savoir, plusieurs plugins regroupÃ©s sous forme de â€œPackâ€ pour un prix plus avantageux quâ€™Ã  lâ€™unitÃ©. â€“ Native Instruments Komplete : Câ€™est le pack ultime avec (quasi) tout NI Ã  lâ€™intÃ©rieur. Attention toutefois Ã  lâ€™indigestion! â€“ Fabfilter : trÃ¨s connu pour ses plugins de mixage et notamment son EQ Pro-Q, il nâ€™est pas en reste comme on lâ€™a vu dans des outils de choix pour le sound design (Timeless, Saturn, Volcanoâ€¦) â€“ Soundtoys : idem quâ€™au-dessus avec entre autres son delay quâ€™on ne prÃ©sente plus Echoboy, son saturateur Decapitator, Crystalliser, â€¦ â€“ Izotope : idem quâ€™au dessus, outre ceux dÃ©jÃ  citÃ©s dans lâ€™article, Iris, Stutter Edit et Breaktweaker mÃ©ritent le coup dâ€™oeil. â€“ Sugarbytes : Cette marque est lâ€™une des plus intÃ©ressantes en matiÃ¨re de plugins dâ€™effets en tout genre (Turnado, Wow, Effectrixâ€¦) VoilÃ , jâ€™ai essayÃ© dâ€™Ãªtre le plus exhaustif possible sur le sujet. Toutefois, le marchÃ© est tellement vaste! De nouveaux constructeurs dÃ©barquent en permanence avec des outils tous plus passionnants et innovants les uns que les autres. Toi aussi tu as sÃ»rement tes prÃ©fÃ©rences alors nâ€™hÃ©site pas Ã  Ã©crire dans les commentaires ce que je nâ€™aurais pas mentionnÃ© ici! Attention! Remarque importante si tu es dÃ©butant : comme je lâ€™avais mentionnÃ© dans cet article , il devient vite contre-productif de se laisser tenter dans la course aux plugins. Contente toi dâ€™abord de maÃ®triser ta DAW de fond en comble; elle possÃ¨de dÃ©jÃ  une foule dâ€™outils largement recommandables. A bon entendeur!\n",
      "article_keywords: plugin, sound design\n",
      "\n",
      "article_title: Amen Break Beatmaking: mise en pratique dans Ableton Live\n",
      "article_content: Je fais la dÃ©monstration pratique dans Ableton Live de techniques de sampling et de Breakbeat Ã  partir du Amen Break original. Cet article fait suite Ã  lâ€™Ã©pisode de podcast Â« Amen Break (Part 1): Les bases du Breakbeat avec la boucle la plus samplÃ©e de lâ€™histoire Â» Ã  Ã©couter sur le lien suivant ou ici, en vous abonnant sur la plateforme de votre choix . Jâ€™y explique notamment: deux mÃ©thodes radicalement diffÃ©rentes pour exploiter une boucle audio Ã  divers tempo ; la partie du Amen Break avec ses coups les plus caractÃ©ristiques et les multiples patterns rythmiques qui en dÃ©coulent; deux mÃ©thodes de sampling dans Ableton; les traitements audio additionnels couramment utilisÃ©s. Retrouvez cet article en vidÃ©o pour une meilleure illustration du process: Et aussi en podcast! Pour Ã©couter cet Ã©pisode, lance tout simplement le lecteur ci-dessous. Tu peux aussi accÃ©der Ã  la page du podcast . Contenu de l'Ã©pisode #4/VidÃ©o: Les DAW modernes dâ€™aujourdâ€™hui comme Ableton Live nous permettent de facilement se rÃ©-approprier ce type de Break en le modifiant Ã  notre guise pour en obtenir une rythmique toute neuve. On va voir maintenant comment on procÃ¨de dans Ableton. Voici le sample Amen Break , brut de dÃ©coffrage et dâ€™une longueur dâ€™un peu moins de 8 secondes: CrÃ©ation d'une boucle de deux mesures Lâ€™Ã©chantillon nâ€™est pas encore mis sous forme dâ€™une boucle. Son tempo original est Ã  137.63 BPM pour Ãªtre prÃ©cis. Donc si je mets le tempo du projet (arrondissons) Ã  138, on voit que la longueur de lâ€™Ã©chantillon change. Ce nâ€™est pas lâ€™Ã©chantillon qui a changÃ© de vitesse mais bien la grille qui sâ€™est adaptÃ©e. Il est cette fois bien calÃ© Ã  la grille. On peut le vÃ©rifier en enclenchant le mÃ©tronome et en prenant ce premier coup de grosse caisse au tout dÃ©but dâ€™une mesure. Pour crÃ©er la boucle de deux mesures, je dÃ©cide de le faire dÃ©marrer Ã  cette mesure-lÃ  et la finir lÃ . Puis jâ€™enclenche le mode boucle en cliquant sur le clip puis Ctrl L (ou CMD L). MÃ©thode 1: Changement naturel du Pitch avec le tempo De maniÃ¨re naturelle (câ€™est-Ã -dire sans appliquer dâ€™algorithme de time-stretch ou ce quâ€™on appelle le mode Warp dans Ableton ), la hauteur (le pitch) de cette boucle est directement dÃ©pendant de la longueur de celle-ci (comme on lâ€™a vu) et donc du tempo de mon projet. Par exemple, si je dÃ©cide de faire un morceau Ã  138 BPM qui est le mÃªme tempo que le Amen break original, je garde donc la boucle Ã  son tempo original et donc son pitch naturel. Maintenant, si je dÃ©cide de la jouer Ã  un tempo plus lent, par exemple parce que je veux produire un morceau de Hip Hop avec, ce que je peux faire alors câ€™est diminuer son pitch ici, par exemple de 3 demi-tons. On remarque immÃ©diatement que la longueur de boucle augmente: Et on entend deux choses: 1) elle joue plus lentement et bien sÃ»r Ã  une tonalitÃ© plus grave. Dans le cas du Amen Break, cela donne une meilleure assise du Kick, de maniÃ¨re naturelle. 2) elle nâ€™est plus du tout calÃ©e Ã  la grille. Pour y remÃ©dier, je rÃ©ajuste le tempo du projet de maniÃ¨re Ã  ce que la boucle dure Ã  nouveau deux mesures exactement. â€”> On constate donc quâ€™une diminution de 3 demi-tons ramÃ¨ne le tempo Ã  116 BPM , comparÃ© aux 138 BPM de la boucle originale. On peut faire le test de diminuer dâ€™un octave ou 12 demi-tons , ce qui donne un tempo de 69 BPM. Soit la moitiÃ© de 138 BPM. Donc il y a bien cette rÃ¨gle dâ€™un rapport de 2 du tempo correspondant Ã  un octave. A lâ€™inverse, en augmentant de 3 demi-tons, sa longueur diminue et joue donc plus rapidement: En rÃ©ajustant la boucle sur deux mesures, on voit quâ€™on joue Ã  un tempo de 164 BPM, plus conforme au style Jungle/Drum&Bass. Et bien Ã©videmment le Amen break joue plus aigÃ¼e et donc aussi avec une perte dans les basses frÃ©quences que je devrai compenser par lâ€™ajout dâ€™une sub bass. On peut vÃ©rifier la correspondance du tempo x2 (276 BPM) en augmentant dâ€™un octave (+12 st). Ce quâ€™on vient de voir est une premiÃ¨re option de travail avec ce genre de boucle audio. Elle a ses avantages mais aussi des inconvÃ©nients. Avantages de la mÃ©thode 1 Pas de dÃ©gradation du signal audio En effet, je nâ€™ai fait aucun changements dans lâ€™audio original. Quand je change le tempo, je change la longueur de lâ€™Ã©chantillon mais en aucun cas je dÃ©grade le signal audio qui reste parfaitement le mÃªme. On verra que câ€™est pas du tout le cas en appliquant du time-stretch (le Warp dans Ableton) pour faire en sorte que lâ€™audio ne change plus de longueur avec le tempo. Et donc le deuxiÃ¨me avantage qui en dÃ©coule, câ€™est quâ€™on conserve le groove naturel de la boucle . Le groove câ€™est-Ã -dire le timing exact de tous les coups de batterie qui composent ce break. On peut voit par exemple ici, le dÃ©but de la deuxiÃ¨me mesure nâ€™est pas exactement calÃ© sur la transitoire. Et ce quelque soit le pitch auquel je vais le jouer. Câ€™est en effet ce qui peut donner envie dâ€™utiliser dÃ¨s le dÃ©part un break en particulier, le fait quâ€™il apporte un certain swing Ã  la rythmique. Câ€™est bien dans les cas oÃ¹ je ne veux pas modifier lâ€™essence-mÃªme de cette boucle, son groove. Que je peux dâ€™ailleurs extraire, et lâ€™appliquer ensuite sur dâ€™autres parties programmÃ©es de mon projet. Clic droit â€”> Extract Groove Cela inclut les informations de timing et de vÃ©locitÃ©s de chaque coup de batterie. InconvÃ©nients de la mÃ©thode 1 Tempo du projet fixÃ© dÃ©finitivement Comme la boucle change de longueur avec le tempo, je suis obligÃ© de fixer le tempo de mon projet dÃ¨s le dÃ©part et ne plus y toucher. Avec cette mÃ©thode, je fais de ma boucle le maÃ®tre de la rythmique. Mais si je veux quâ€™elle joue plus lentement et donc plus grave, je change en consÃ©quence le tempo de mon projet. Suppose de connaÃ®tre son tempo dâ€™origine Je savais que le Amen Break original joue Ã  138 BPM, ce qui mâ€™a permis de caler immÃ©diatement la boucle Ã  la grille en indiquant le mÃªme tempo pour le projet. Editing complexe et chronophage pour changer le groove Si jamais, je veux changer ce groove et recaler certaines transitoires, je dois passer par de lâ€™editing fastidieux dans la vue arrangement. VoilÃ  pour la premiÃ¨re option de ce quâ€™on peut faire avec une boucle rythmique dans un projet musical. Maintenant on va voir une autre maniÃ¨re de travailler avec cette boucle pour pouvoir lâ€™utiliser autrement: â€“ Cela peut Ãªtre parce que jâ€™ai dÃ©jÃ  une rythmique en place, basÃ©e sur dâ€™autres parties MIDI programmÃ©es. Auquel cas je veux parfaitement synchroniser ma boucle avec le reste et pas lâ€™inverse. â€“ Câ€™est aussi dans le cas frÃ©quent oÃ¹ je veux modifier complÃ¨tement la rythmique et crÃ©er dâ€™autres modÃ¨les plus personnalisÃ©s. Ceci dit, rien nâ€™interdit aussi de tirer parti du meilleur des deux mondes en quantifiant ma boucle Ã  la rythmique imposÃ©e puis de la laisser libre et intacte dans des parties du morceau plus Ã©purÃ©es, lorsquâ€™elle joue seule par exemple. MÃ©thode 2: Calage de la boucle et dÃ©termination de son tempo (mode Warp enclenchÃ©) Dans cette deuxiÃ¨me mÃ©thode, je vais vouloir dÃ¨s le dÃ©part synchroniser et quantifier ma boucle Ã  une grille bien prÃ©cise. Donc en gros je fais lâ€™inverse: jâ€™adapte la boucle Ã  une grille existante plutÃ´t que dâ€™adapter la grille Ã  ma boucle. Admettons aussi que je ne connaisse pas le tempo de mon Ã©chantillon. Mon audio joue Ã  un certain BPM (qui est en fait 138) mais je commence avec le tempo du projet Ã  120 par dÃ©faut. Maintenant, jâ€™enclenche le mode Warp du clip audio. Cela aura un autre nom si vous utilisez un autre DAW quâ€™Ableton mais le principe est le mÃªme: câ€™est de synchroniser lâ€™audio Ã  un tempo maÃ®tre par lâ€™intermÃ©diaire dâ€™un algorithme de time-stretch permettant de modifier le moins possible le timbre de lâ€™audio dâ€™origine quelque soit le tempo maÃ®tre choisi. On remarque tout de suite que le clip audio ne change plus de longueur et la lecture sâ€™adapte parfaitement aux changements de tempo. La deuxiÃ¨me chose câ€™est que maintenant, dans la vue du clip audio, Ableton a analysÃ© automatiquement oÃ¹ se trouvent les transitoires (chaque coup de percussion). En double-cliquant dessus, je crÃ©e un marqueur Warp . Cela me permet de dÃ©placer lâ€™audio exactement Ã  partir de ce point-lÃ . Faites-vous lâ€™image de la forme dâ€™onde audio comme un Ã©lastique et le marqueur Warp comme une Ã©pingle que lâ€™on vient planter dans lâ€™Ã©lastique pour le fixer exactement Ã  ce point lÃ . Ou alors je peux dÃ©placer ce point exactement oÃ¹ je veux avec lâ€™audio de part et dâ€™autre qui sâ€™Ã©tire ou se compresse en consÃ©quence. CrÃ©ons maintenant une boucle de deux mesures, la mÃªme que tout Ã  lâ€™heure. Et par la mÃªme occasion, cela va nous permettre de dÃ©terminer le tempo rÃ©el de lâ€™audio qui est pour lâ€™instant Ã  120 par dÃ©faut. On se rappelle que le point dâ€™origine reprÃ©sentant le premier beat de la premiÃ¨re mesure , se situe sur ce Kick. Jâ€™enclenche aussi le mÃ©tronome . Pour cela, je crÃ©e le marqueur Warp Ã  ce point-lÃ . En zoomant je peux voir quâ€™il nâ€™est pas exactement alignÃ© au dÃ©but de la transitoire. AprÃ¨s lâ€™analyse par Ableton, il faut parfois repasser derriÃ¨re manuellement et rÃ©ajuster les points Warp plus prÃ©cisÃ©ment. en cliquant sur le marqueur et en maintenant Shift appuyÃ© A ce marqueur Warp, je fais Clic droit â€”> Set 1.1.1 here pour indiquer que câ€™est bien lÃ  le premier temps du dÃ©but de ma boucle. Le 1 de la grille sâ€™est bien calÃ© Ã  ce point. Maintenant je dÃ©termine le dÃ©but de la deuxiÃ¨me mesure, qui se trouve en fait Ã  ce Kick-lÃ  (compter les temps) . Je crÃ©e donc la marqueur Warp Ã  ce point et je le dÃ©place sur le 2 de la grille. Enfin, je dÃ©termine la fin de la deuxiÃ¨me mesure de la boucle en tÃ¢tonnant un peu et en mâ€™aidant dâ€™un mÃ©tronome. Jâ€™obtiens par exemple une boucle de deux mesures prise au milieu du Break: elle sonne comme ceci: Ensuite, pour faire de mon break une boucle qui peut tourner en continu, jâ€™enclenche le mode Loop . Je peux ensuite isoler la boucle du reste de lâ€™Ã©chantillon (dans Ableton, cela sâ€™appelle Â« Crop sample Â» ): cela me crÃ©e un nouveau fichier audio de la boucle seule. Mais câ€™est bien sÃ»r un procÃ©dÃ© non-destructif car le break original entier est conservÃ© dans mon dossier. Tests Ã  diffÃ©rents tempos et algorithmes de Warp A 138 BPM qui est le mÃªme tempo que la boucle originale, il nâ€™y a aucune dÃ©gradation du son quelque soit le mode de warping (ou algorithme de time-stretch) choisi. En testant comment sonne la boucle Ã  diffÃ©rents tempos, je dÃ©termine lâ€™algorithme de time-stretch le plus appropriÃ©. â€”> Jâ€™ai constatÃ© que le Mode Complex dans Ableton semble le meilleur pour les tempos plus lents ( Boucle Ã  110 BPM) â€”> Et le mode Beats pour les tempos plus rapides ( Boucle Ã  160 BPM) CrÃ©ation dâ€™une deuxiÃ¨me boucle extraite du Amen Break Toutefois, je vais prendre une autre boucle, plus intÃ©ressante pour la suite de la dÃ©monstration. Elle se situe dans la partie finale du Break, lÃ  oÃ¹ se situent tous les coups de batterie les plus uniques: le Kick suivi de la cymbale Ride la cymbale crash suivie de la snare et ce double roulement de snare entre les deux. Câ€™est de loin la partie du Amen Break la plus samplÃ©e dans les genres Jungle/Drumâ€™nâ€™Bass. En suivant la mÃªme mÃ©thode que prÃ©cÃ©demment, je finis par isoler la boucle aprÃ¨s avoir quantifier les principaux coups sur la grille. Cela donne une boucle longue dâ€™un peu moins dâ€™une mesure et demi: Elle convient bien Ã  un tempo rapide. Je passe donc mon projet Ã  170 BPM . Une fois que notre boucle est prÃªte, on va passer au sampling proprement dit. Lâ€™idÃ©e est de pouvoir jouer chaque coup de batterie composant la boucle individuellement, chacun assignÃ© Ã  un pad. On va donc passer la boucle audio en piste MIDI oÃ¹ il sera alors facile de jouer chaque coup Ã  volontÃ© et dans lâ€™ordre que lâ€™on veut. Pour cela, il y a deux faÃ§ons de faire dans Ableton: Echantillonnage de la boucle avec lâ€™instrument Â« Simpler Â» dâ€™Ableton La premiÃ¨re mÃ©thode est de charger directement la boucle dans lâ€™instrument Â« Simpler Â» qui est lâ€™Ã©quivalent dâ€™un sampler qui va intÃ©grer un seul sample ou boucle audio. Puis le mode Slice permet de dÃ©couper automatiquement lâ€™audio suivant ses transitoires. Sinon il y a aussi possibilitÃ© de le faire manuellement. Maintenant, si vous jouez des notes MIDI Ã  partir dâ€™un clavier ou des pads, les notes Ã  partir de C1 dÃ©clencheront les diffÃ©rents Slices. Cela permet facilement de se crÃ©er un nouveau rythme tout en conservant les caractÃ©ristiques sonores de lâ€™original, et Ã  nâ€™importe quel tempo. Activez Poly dans Simpler pour pouvoir dÃ©clencher plusieurs coups de batterie en mÃªme temps. Câ€™est un moyen rapide dâ€™obtenir un rythme dâ€™un Ã©chantillon Ã  lâ€™autre, prÃªt Ã  Ãªtre utilisÃ© dans votre musique. Une autre astuce est de dÃ©couper par Beat (1/8: Ã  la croche) et dâ€™activer le mode Thru . Avec ce mode, lâ€™Ã©chantillon continue de jouer aprÃ¨s avoir dÃ©clencher un slice, jusquâ€™Ã  ce quâ€™on enclenche un nouveau slice. On peut alors se prÃ©parer un clip Midi jouant dâ€™abord la boucle normalement. Pour cela, chaque slice correspondant Ã  une longueur de 1/8 (Ã  la croche) est disposÃ© lâ€™un Ã  la suite de lâ€™autre (quantifiez la grille Ã  1/8). ExpÃ©rimentez diffÃ©rents patterns rythmiques en dÃ©plaÃ§ant les slices verticalement sur la grille (avec la quantification Ã  1/8, puis tester aussi Ã  1/16). Echantillonnage de la boucle par le dÃ©coupage en une nouvelle piste MIDI La deuxiÃ¨me mÃ©thode est de dÃ©couper la boucle en la transformant en Drum Rack. Avec un Clic droit sur le clip, je choisis de Â« dÃ©couper vers une nouvelle piste MIDI Â» Option de longueur de dÃ©coupe â€“ suivant les transitoires â€“ suivant les markers â€“ suivant une longueur de note Tout Ã  lâ€™heure, Ã§a marchait bien par beat division 1/8, mais cette fois je vais tenter de dÃ©couper par toute les transitoires prÃ©sentes. Une nouvelle piste Midi est crÃ©Ã©e automatiquement Ã  cÃ´tÃ©: avec un clip qui contient une note pour chaque slice et un Drum Rack avec cette fois un Simpler pour chacun des Slices. On enclenche les diffÃ©rents slices Ã  partir de C1 comme tout Ã  lâ€™heure. Quand on lance le clip, je vÃ©rifie quâ€™il est bien lu correctement. Si ce nâ€™est pas le cas, il faut sÃ»rement ajuster les positions de lecture de chaque slice. Macros du Drum Rack Utilisez les macros du Drum Rack incluant des commandes pour Â« Start Offset Â» et Â« Loop Length Â». Si on entend des clics intempestifs, câ€™est que le mode Loop est enclenchÃ© â€”> dÃ©sactivez-le. Cliquez sur le bouton Afficher/Masquer Ã  gauche du rack, ou double-cliquez sur le pad de batterie concernÃ©, si vous ne voyez pas les Simplers. Ensuite, il est parfois nÃ©cessaire dâ€™affiner lâ€™alignement des notes sur une prÃ©cision dâ€™une croche (1/8) ou dâ€™une double-croche (1/16) pour les roulements de la snare. CrÃ©ation de Pattern rythmiques Comme avant, on peut re-sÃ©quencer ce rythme, tout en gardant le son dâ€™origine. â€“ En dÃ©plaÃ§ant les notes horizontalement, je dÃ©clenche le son Ã  dâ€™autres positions. â€“ En dÃ©plaÃ§ant les notes verticalement, je change le type de son Ã  cette mÃªme position. Je peux bien sÃ»r changer la longueur de mon clip. Je le mets sur deux mesures pour commencer. Je vous fais Ã©couter finalement des rÃ©-arrangements possibles sur 2 ou 4 mesures: Traitements audio additionnels Ensuite, plusieurs traitements sâ€™imposent, Ã  commencer par un EQ. 1) Traitement EQ a) High Pass Ã  environ 100Hz, Q 0,6 car le low end sera apportÃ© par dâ€™autres Ã©lÃ©ments plus tard (voir Ã©tape du Kick layering). b) boost du High end pour lâ€™air, crisp: +3dB Ã  3000 Hz c) boost des frÃ©quences de la snare parfois avec un Q Ã©levÃ©, pour se restreindre Ã  une frÃ©quence prÃ©cise Ã  mettre en valeur +3 dB Ã  1800 Hz + 2,5 dB Ã  300 Hz d) creuser lÃ©gÃ¨rement le low-mid ( -5dB Ã  700 Hz , son boxy boÃ®te creuse) e) A/B de lâ€™ensemble du traitement EQ 2) Jouer avec l'enveloppe d'amplitude Ajuster le sustain et le decay de lâ€™enveloppe dâ€™amplitude permet de mieux dÃ©finir chaque coup percussif. â€“ Tester de mettre le Sustain Ã  -inf. â€“ Puis faire varier le Decay du minimum juquâ€™Ã  une valeur suffisante (ici Ã  550-600 ms). â€“ Enfin, remonter un peu le sustain. 3) Modifier le pitch Si vous voulez retrouvez une vibe un peu vintage, Ã§a peut Ãªtre pas mal de changer le pitch original, selon le tempo du projet. a) Changer la transposition dâ€™un slice et clic droit â€”> copy value to siblings Faire Ã©couter avec le Pitch de chaque slice +3st ou -3st b) Attention il faut peut Ãªtre revenir aux rÃ©glages de lâ€™EQ aprÃ¨s le changement de pitch! 4) Layering du Kick a) Choisir un Kick avec plus de sub b) lâ€™aligner avec les coups de Kick de ma boucle samplÃ©e c) ajuster les niveaux 5) Distorsion De la disorsion ajoute du caractÃ¨re ou remet en avant certains coups de HiHats. a) parcourir les presets de votre plugin de disto favori pour un changement total de caractÃ¨re. b) tester dâ€™activer lâ€™EQ avant ou aprÃ¨s la distorsion dans la chaÃ®ne du signal. c) choisir un preset et ajuster le Dry/Wet du plugin pour un effet plus subtil. 6) Compression Enfin, un traitement de compression sur lâ€™ensemble Kick/Break permet dâ€™unifier le tout et modifier lÃ©gÃ¨rement le timbre et loudness final voulu. a) seuil Ã  -18 dB pour ne prendre que les pics (Percussive Â« Pah Â», Â« Keuh Â» du Kick, Snare, Charley) b) ratio Ã  tester Ã  fond si on veut cet effet squash ou pompage (en baissant aussi le seuil et lâ€™attaque Ã  0). Sinon ramener Ã  un niveau intermÃ©diaire c) Attack: laisser passer les transitoires pour le punch (jusquâ€™Ã  30 ms environ) d) Release: lâ€™augmenter un peu pour laisser respirer le son en rythme e) enlever le makeup (car souvent trop fort) et ajuster lâ€™output manuellement RÃ©sultat et comparaison finale â€”> Faire une comparaison entre la boucle brute et le rÃ©sultat final. et ajout dâ€™une basse pour le contexte. Les possibilitÃ©s de traitement sont illimitÃ©es! Et ce que jâ€™ai montrÃ© sur lâ€™ensemble des Â« slices Â» peut aussi bien Ãªtre effectuÃ© sur un seul Â« slice Â» en particulier. Avec des effets de filtre ou de reverse, particuliÃ¨rement efficaces Ã©galement. Outro de l'Ã©pisode\n",
      "article_keywords: ableton live, amen break, boucle audio, breakbeat, pitch, sampling, time-stretch, warp\n",
      "\n",
      "article_title: Les bases du Breakbeat avec le Amen Break\n",
      "article_content: Voici lâ€™Ã©pisode 3 de la saison 2 du podcast Arsonor! Cet Ã©pisode raconte les origines et Ã©volutions du Breakbeat en tant que technique de Sampling. Le fil rouge de lâ€™Ã©pisode est le Amen Break , une boucle de batterie la plus samplÃ©e dans lâ€™histoire de la musique. A travers lâ€™Ã©coute de nombreux extraits, dÃ©couvrez Ã  quel point le Amen Break est la source de courants musicaux comme le Hip Hop et la Jungle , ainsi que dâ€™innombrables morceaux de tous styles des annÃ©es 80 Ã  aujourdâ€™hui. En analysant de plus prÃ¨s cette boucle rythmique, cherchons Ã  comprendre pourquoi elle est devenue la plus populaire dâ€™entre toute. La partie 2 dans le prochain Ã©pisode fera la dÃ©monstration pratique dans Ableton Live de la technique du Breakbeat Ã  partir du Amen Break original. Pour Ã©couter cet Ã©pisode, lance tout simplement le lecteur ci-dessus. Tu peux aussi accÃ©der Ã  la page du podcast . Contenu de l'Ã©pisode #3: Savez-vous quel est le point commun entre Ã§a: NWA â€“ Straight Outta Compton Et Ã§a: Terrorist â€“ Renegade La rÃ©ponse est le Amen Break ! Mais dâ€™oÃ¹ cela vient-il? A la fin des annÃ©es 60, un groupe nommÃ© The Winstons a enregistrÃ© une chanson appelÃ©e Â« Amen Brother Â» . Au milieu du morceau, Ã  environ 1â€™26â€™â€™, le batteur joue seul. Il ne se doute pas Ã  ce moment-lÃ  quâ€™il allait influencer une bonne partie de la crÃ©ation musicale Ã  venir. 1 - Le Breakbeat en tant que technique de sampling: Origines et Ã©volutions Dans cet Ã©pisode, on va sâ€™intÃ©resser Ã  une technique courante du beatmaking et plus que jamais pratiquÃ©e aujourdâ€™hui dans tout style de musique rythmique, Ã  savoir le Â« breakbeat Â» en tant que technique de sampling . Mais quâ€™est-ce quâ€™on appelle un Â« breakbeat Â» exactement? Pour le dire simplement, câ€™est un extrait rythmique dâ€™un morceau de musique, oÃ¹ la batterie ou autre Ã©lÃ©ment de percussion jouent en solo . Le terme Â«breakÂ» fait rÃ©fÃ©rence Ã  ces sections de batterie jouÃ©es pendant le break du morceau; Ã  savoir ces pauses dans lâ€™arrangement mettant en valeur la rythmique seule. La technique du Â« breakbeat Â» est donc de sâ€™approprier un extrait rythmique en lâ€™extrayant dâ€™anciens morceaux existants. En gÃ©nÃ©ral, les morceaux en question sont de vieux enregistrements funk, soul, jazz ou R &B . La plupart sont centrÃ©s sur des arrangements vocaux et une instrumentation variÃ©e. Cependant, de nombreux morceaux comportent des segments de quatre ou huit mesures, souvent trouvÃ©s dans la transition entre couplet et refrain, dans lequel la batterie joue un certain groove en solo. Les Ã©lÃ©ments de la batterie (drums) Souvent, dans lâ€™enregistrement rÃ©cupÃ©rÃ© sont extraits les Ã©lÃ©ments typiques de la batterie: Le Kick (grosse caisse), Snare (caisse claire), Clap, HiHat (charleys), Tom, Cymbale , etcâ€¦ ainsi que des enchaÃ®nement particuliers de ceux-ci. Mais aussi dâ€™autres percussions comme le Rim Shot, Bongo, Conga , ou autre tambourin . Ou encore dâ€™autres Ã©lÃ©ments musicaux qui peuvent sâ€™intÃ©grer dans la rythmique comme: sample de Voix one shot, un riff de guitare, un jeu de cuivres Les origines du Hip Hop Alors cette technique du sampling ne date pas dâ€™hier. Pour les producteurs de hip-hop et les DJ entreprenants des annÃ©es 70, la dÃ©couverte de ces breaks sur des disques vinyles a Ã©tÃ© lâ€™occasion de rÃ©utiliser des rythmes existants Ã  leurs propres fins musicales. Câ€™Ã©tait un moyen pour les jeunes musiciens Ã  court dâ€™argent de travailler avec de grands batteurs sans avoir besoin de trouver des musiciens de session ou de payer des frais de studio. Ce simple acte dâ€™ingÃ©niositÃ© musicale a changÃ© le cours de lâ€™histoire de la musique. Pensez Ã  lâ€™Ã¢ge dâ€™or de la musique hip hop du milieu Ã  la fin des annÃ©es 80 et au dÃ©but des annÃ©es 90. Toute cette pÃ©riode de 10, 12 ans est principalement une pÃ©riode au cours de laquelle la musique hip hop, en particulier, rÃ©cupÃ¨re ces vieux Ã©chantillons de batterie. Les sampleurs sont devenus populaires Ã  peu prÃ¨s au mÃªme moment oÃ¹ les musiciens ont commencÃ© Ã  utiliser des boÃ®tes Ã  rythmes et des synthÃ©tiseurs . Au dÃ©but, câ€™Ã©tait une sorte de nouveautÃ©. Le sampling permettait Ã  nouveau de produire des sons plus organiques contrairement au type de sons artificiels synthÃ©tisÃ©s. Les premiÃ¨res musiques Ã©lectro, les premiÃ¨res musiques de breakdance, avaient un son trÃ¨s robotique, trÃ¨s futuriste. Y introduire le sampling, câ€™Ã©tait en quelque sorte retrouver lâ€™esthÃ©tique dâ€™une pÃ©riode passÃ©e. Contrairement Ã  aujourdâ€™hui oÃ¹ on pratique essentiellement dans un logiciel dÃ©diÃ©, les samplers Ã  lâ€™Ã©poque Ã©taient uniquement des machines bien physiques, les fameuses MPC dâ€™AKAI notamment, de la taille dâ€™un lecteur DVD Ã  peu prÃ¨s. Avec leur 16 Pads jouables avec les doigts (ce quâ€™on appelle du Â« finger drumming Â» ), ces samplers ont permis le dÃ©coupage et rÃ©-assemblage des breakbeats de faÃ§on trÃ¨s simple et rapide. Il y a aussi un cÃ´tÃ© nostalgique qui rend le sampling dÃ©sirable. Lorsque les producteurs de lâ€™Ã©poque mettent la main sur des sampleurs, ils rÃ©alisent quâ€™ils peuvent commencer Ã  emprunter les sons des disques quâ€™ils ont Ã©coutÃ©s en grandissant. Des compilations regroupant des vieux morceaux commenÃ§aient Ã  apparaÃ®tre. Des morceaux rigoureusement sÃ©lectionnÃ©s pour en retirer des breaks, des Ã©chantillons sonores Ã  rÃ©utiliser. Dont le Amen Break en faisait Ã©videmment parti. 2 - Exemples de reprise du Â« Amen Break Â» et autres breaks connus On en arrive donc Ã  lâ€™objet de cet Ã©pisode: le lÃ©gendaire Amen Break . A la fin des annÃ©es 60, un groupe nommÃ© The Winstons a enregistrÃ© une chanson appelÃ©e Â« Amen Brother Â». Au milieu du morceau, Ã  environ 1â€™26â€™â€™, le batteur joue seul. Ce que vous venez dâ€™entendre sâ€™appelle depuis le Â« Amen Break Â», qui est donc ce solo de batterie jouÃ©e par GC Coleman le batteur du groupe. Alors pourquoi jâ€™en parle? Car câ€™est tout simplement la boucle audio de batterie de loin la plus rÃ©utilisÃ©e de lâ€™histoire de la musique . Ces quatre mesures de batterie jouÃ©es pendant sept secondes auront suffi Ã  inspirer des milliers de futurs producteurs pour la reprendre et la remodeler Ã  leur sauce dans leurs morceaux. Vous lâ€™avez certainement entendu un million de fois, mais vous aurez peut-Ãªtre du mal Ã  vous souvenir dans quoi. Alors, Ã©coutons Ã  nouveau ces six secondes. Cette fois, voyez si vous pouvez vous rappeler oÃ¹ vous lâ€™avez entendu. [Amen break Ã  vitesse normale â€“ 138 BPM] Amen break au ralenti: les dÃ©buts du Hip Hop On peut le retrouver jouÃ© au ralenti dans les dÃ©buts du Hip Hop : [I Desire â€“ Salt-N-Pepa ] [Feel Alright Yâ€™all â€“ 2 Live Crew] [King of Beats â€“ Mantronix ] Plus dâ€™une dÃ©cennie sâ€™est Ã©coulÃ©e depuis la sortie du morceau Â« Amen Brother Â» avant que le break ne commence Ã  apparaÃ®tre dans ces morceaux de hip hop. Câ€™est principalement parce que le sampling ne devient une pratique Ã  la mode quâ€™Ã  partir des annÃ©es 80. Puis dans du Hip Hop plus rÃ©cent : [Streets on Fire â€“ Lupe Fiasco] [Straight Outta Compton (radio edit)] [Red Eye â€“ Big K.R.I.T.] [Compton â€“ The Game feat. Will.i.am] [Pigs â€“ Tyler, The Creator ] [Mindfields â€“ Prodigy] Le Amen Break en accÃ©lÃ©rÃ© dans la Jungle et Drum'n'Bass En ralentissant le Amen Break, il Ã©tait trÃ¨s employÃ© dans le hip hop, puis arriva la dÃ©ferlante Jungle et la drum and bass avec le mÃªme break mais cette fois en accÃ©lÃ©rÃ©. On ne compte plus le nombre de tracks de ce style crÃ©es Ã  partir de ce break dans les annÃ©es 90: [ Renegade â€“ Terrorist ] [Tundra â€“ Squarepusher] [ Canâ€™t Knock The Hustle (Desired State Remix) â€“ Jay-Z feat. Mary J Blige ] [ Ainâ€™t Talkinâ€™ Bout Dub â€“ Apollo 440 ] La longueur et la polyvalence de lâ€™Amen Break lâ€™ont rendu si prolifique que trouver de nouvelles faÃ§ons de lâ€™utiliser Ã©tait devenu une quÃªte intellectuelle. [Fear â€“ Amen Andrews (Luke Vibert)] [Creatures â€“ Amon Tobin] [Nightlife â€“ Amon Tobin] Polyvalence et diversitÃ© du Amen Break Ecoutons-le enfin dans des tracks plus rÃ©centes et dans des styles musicaux aussi divers quâ€™Ã©clectiques: [ In for the Kill (Skreamâ€™s Letâ€™s Get Ravey Remix) â€“ La Roux ] [ Eyeless â€“ Slipknot ] [Scary Monsters and Nice Sprites (The juggernaut remix) â€“ Skrillex] [One Kiss (Oliver Helgens remix) â€“ Calvin Harris and Dua Lipa] Câ€™est mÃªme utilisÃ© dans les pubs ou gÃ©nÃ©riques comme ici avec le thÃ¨me de Futurama: [Futurama Theme â€“ Christopher Tyng ] Si vous allez sur lâ€™application WhoSampled qui recense tous les samples de tous les morceaux du monde, on peut voir que plus de 5800 morceaux utilisent cette boucle Amen Break. Ce qui est absolument Ã©norme! Dâ€™ailleurs je vous recommande cette application WhoSampled qui permet de vous rendre compte Ã  quel point la musique, quelque soit le genre et lâ€™origine, emprunte quasi toujours Ã  ce qui a dÃ©jÃ  existÃ© dans le passÃ©. Lâ€™ironie de lâ€™histoire câ€™est que le batteur du Amen Break, GC Coleman ne touchera jamais un seul centime de son vivant de tout ce sampling. Autres breaks intÃ©ressants Bien sÃ»r il y a des milliers dâ€™autres breaks rÃ©cupÃ©rÃ©s dans des vieux disques, tout comme le Amen break. Mais contrairement Ã  aujourdâ€™hui, oÃ¹ on peut simplement taper les mots Â« drum solo Â» dans un moteur de recherche et trouver une liste interminable dâ€™enregistrements et de vidÃ©os, il faut savoir que dans les annÃ©es 80 et 90, les nombreux producteurs sâ€™appuyaient sur la mÃªme sÃ©rie de collections de breaks disponibles dans le commerce ou des recommandations de bouche Ã  oreille. A part le Amen Break, en voici quelques-uns devenus cultes: Incredible Bongo Band - Apache Ces premiÃ¨res mesures sont du morceau nommÃ© Apache du Incredible Bongo Band. Apache est un incontournable du hip-hop grÃ¢ce au lÃ©gendaire Â« Merry-Go-Round Â» de DJ Kool Herc crÃ©ant une boucle indÃ©finie du Break. Grandmaster Flash, DJ Shadow, Switch and The Sugarhill Gang (mÃªme sâ€™il sâ€™agit dâ€™une reprise) ont tous connu le succÃ¨s avec ce qui est connu depuis comme le Apache Break . James Brown - Funky Drummer, Tighten Up, ... Comme autre grand pourvoyeur de breaks, on retrouve bien sÃ»r James Brown. Le son du kit de batterie Â« Funky Drummer Â» est aussi incomparable que le groove jouÃ©, ce qui en fait un grand classique Ã  travers tous les Ã¢ges. Public Enemy lâ€™a utilisÃ© plusieurs fois (jusquâ€™Ã  mÃªme le nommer dans Fight The Power), tandis quâ€™il a Ã©galement fait des apparitions sur des morceaux de LL Cool J, Run-DMC et NWA. Skull Snaps - Itâ€™s a new day Allez pour finir, je citerai Skull Snaps â€“ Itâ€™s a new day qui a Ã©tÃ© repris entre autres par Prodigy, et Rob Dougan dans la BO de Matrix: â€”> Prodigy â€“ Poison â€”> Rob Dougan â€“ Clubbed to death (The Matrix) 3 - Le Amen Break dÃ©cortiquÃ©: pourquoi a tâ€™il Ã©tÃ© si souvent utilisÃ©? Maintenant voyons plus en dÃ©tail pourquoi le Amen Break est devenu le breakbeat le plus populaire dâ€™entre tous? Quâ€™est-ce qui fait que les artistes de tout genre musical lâ€™utilisent tant? 1) La longueur du Amen break La premiÃ¨re explication est la longueur de ce break. Câ€™est en effet un Ã©chantillon de six-sept secondes, donc il y a beaucoup de matiÃ¨re Ã  piocher dedans. Alors, bien sÃ»r vous vous dites, six secondes cela semble peu. Mais il faut savoir que dans la pratique du sampling Ã  ses dÃ©buts, six secondes, cela reprÃ©sentait une tonne de temps. Quand les gens fouillent dans les caisses de disques vinyles des magasins de disques dâ€™occasion Ã  la recherche du sample idÃ©al, et quâ€™ils arrivent Ã  trouver une seule mesure dâ€™un Ã©chantillon de batterie, câ€™est une victoire. Câ€™est pourquoi le Amen Break reprÃ©sente le Graal! 2) La variations des coups de batterie La deuxiÃ¨me explication est quâ€™en plus de sa longueur, le Amen Break est trÃ¨s variÃ© dans ses coups de batterie. Le batteur , GC Coleman, fait son truc pendant 5 ou 6 secondes. Et il le fait suivant un certain groove bien Ã  lui. Ce nâ€™est pas suivant un rythme standard 4/4 four to the floor comme celui-ci: Mais au contraire on y entend un rythme syncopÃ© oÃ¹ des temps normalement plus faibles sont mis en avant, notamment par les coups de la caisse claire . Cela a pour effet de disrupter le rythme naturel et crÃ©er une certaine tension rythmique, une vibe plus funky. 3) Les coups de la caisse claire dans la troisiÃ¨me mesure Par exemple, tous les coups de la caisse claire sont diffÃ©rents. La clÃ© du succÃ¨s rythmique est le dÃ©calage de cette caisse claire dans la troisiÃ¨me mesure. Coleman faisant presque allusion Ã  la faÃ§on dont les producteurs de DnB pourraient lâ€™utiliser plus tard. On peut alors dÃ©couper le Amen break et rÃ©organiser les divers coups individuels dans dâ€™autres configurations. On peut trÃ¨s vite se lancer dans des motifs et des textures vraiment intÃ©ressants. Les transformations possibles du Amen Break En plus de rÃ©arranger le break, on peut lâ€™accÃ©lÃ©rerâ€¦ Le ralentirâ€¦ ou mÃªme le jouer Ã  lâ€™envers (ce quâ€™on appelle faire un Reverse). Dâ€™autres effets comme le filtrage de frÃ©quences, le changements de pitch, la distorsion, le stretching, etcâ€¦ sont encore autant de traitements pour transformer le break en quelque chose de nouveau et dâ€™unique. A bientÃ´t pour la deuxiÃ¨me partie de cet Ã©pisode, oÃ¹ je ferai une dÃ©monstration pratique de transformation du Amen Break dans Ableton Live. Outro de l'Ã©pisode\n",
      "article_keywords: break, breakbeat, hip hop, jungle, loop, sampling\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54c74a-78fa-4684-b19b-f6bba6273cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a1d40-a113-4737-99ec-ac7e1c6114d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model='gpt-4o-mini'):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    #print(prompt)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58469b47-a3ee-4941-9466-d944c82d7265",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'De quel matÃ©riel ai-je besoin pour mon home studio?'\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be4d02-5d0f-465b-9b75-26dac1b1cbb7",
   "metadata": {},
   "source": [
    "# Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286045b2-a6a9-4120-9d75-8bdf4318f18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19281969-db02-42ae-a1a9-59c3caf86798",
   "metadata": {},
   "source": [
    "# RAG evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c6999-12d3-41f2-ade9-9841722e5be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
